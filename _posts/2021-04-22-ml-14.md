---
layout: post
title: å†™ç»™ç¨‹åºå‘˜çš„æœºå™¨å­¦ä¹ å…¥é—¨ (åå››) - å¯¹æŠ—ç”Ÿæˆç½‘ç»œ å¦‚ä½•é€ å‡è„¸
tag: å†™ç»™ç¨‹åºå‘˜çš„æœºå™¨å­¦ä¹ å…¥é—¨
---

è¿™ç¯‡æ–‡ç« å°†ä¼šæ•™ä½ æ€æ ·ç”¨æœºå™¨å­¦ä¹ æ¥ä¼ªé€ å‡æ•°æ®ï¼Œé¢˜æè¿˜æ˜¯äººè„¸ï¼Œä»¥ä¸‹å…­å¼ äººè„¸é‡Œé¢ï¼Œæœ‰ä¸¤å¼ æ˜¯å‡çš„ï¼ŒçŒœçŒœæ˜¯å“ªä¸¤å¼ ğŸ˜ï¼Ÿ

![01](./01.png)

ç”Ÿæˆå‡äººè„¸ä½¿ç”¨çš„ç½‘ç»œæ˜¯å¯¹æŠ—ç”Ÿæˆç½‘ç»œ (GAN - Generative adversarial network)ï¼Œè¿™ä¸ªç½‘ç»œä¸ä¹‹å‰ä»‹ç»çš„æ¯”èµ·æ¥ç›¸å½“ç‰¹æ®Šï¼Œè™½ç„¶çœ‹èµ·æ¥ä¸ç®—å¤æ‚ï¼Œä½†è®­ç»ƒèµ·æ¥æå…¶å›°éš¾ï¼Œä»¥ä¸‹å°†ä»åŸºç¡€åŸç†å¼€å§‹ä¸€ç›´è®²åˆ°å…·ä½“ä»£ç ï¼Œè¿˜ä¼šå¼•å…¥ä¸€äº›ä¹‹å‰æ²¡æœ‰è®²è¿‡çš„ç»„ä»¶å’Œè®­ç»ƒæ–¹æ³•ğŸ˜¨ã€‚

## å¯¹æŠ—ç”Ÿæˆç½‘ç»œ (GAN) çš„åŸç†

æ‰€è°“ç”Ÿæˆç½‘ç»œå°±æ˜¯ç”¨äºç”Ÿæˆæ–‡ç« ï¼ŒéŸ³é¢‘ï¼Œå›¾ç‰‡ï¼Œç”šè‡³ä»£ç ç­‰æ•°æ®çš„æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œä¾‹å¦‚æˆ‘ä»¬å¯ä»¥ç»™å‡ºä¸€ä¸ªéœ€æ±‚è®©ç½‘ç»œç”Ÿæˆä¸€ä»½ä»£ç ï¼Œå¦‚æœç½‘ç»œè¶³å¤Ÿå¼ºå¤§ï¼Œç”Ÿæˆçš„ä»£ç è´¨é‡è¶³å¤Ÿå¥½å¹¶ä¸”èƒ½æ»¡è¶³éœ€æ±‚ï¼Œé‚£ç å†œä»¬å°±è¦é¢ä¸´å¤±ä¸šäº†ğŸ˜±ã€‚å½“ç„¶ï¼Œç›®å‰æœºå™¨å­¦ä¹ æ¨¡å‹å¯ä»¥ç”Ÿæˆçš„æ•°æ®æ¯”è¾ƒæœ‰é™å¹¶ä¸”è´¨é‡éƒ½å¾ˆä¸€èˆ¬ï¼Œç å†œä»¬çš„é¥­ç¢—è¿˜æ˜¯èƒ½ä¿ä½ä¸€æ®µæ—¶é—´çš„ã€‚

ç”Ÿæˆç½‘ç»œå’Œæ™®é€šçš„æ¨¡å‹ä¸€æ ·ï¼Œè¦æ±‚æœ‰è¾“å…¥å’Œè¾“å‡ºï¼Œå‡è®¾æˆ‘ä»¬å¯ä»¥ä¼ å…¥ä¸€äº›æ¡ä»¶è®©ç½‘ç»œç”Ÿæˆç¬¦åˆæ¡ä»¶çš„å›¾ç‰‡ï¼š

![02](./02.png)

çœ‹èµ·æ¥éå¸¸å¥½ç”¨ï¼Œä½†è®­ç»ƒè¿™æ ·çš„æ¨¡å‹éœ€è¦ä¸€ä¸ªåºå¤§çš„æ•°æ®é›†ï¼Œå¹¶ä¸”å¾—ä¸€å¼ å¼ å›¾ç‰‡å»æ ‡è®°å®ƒä»¬çš„å±æ€§ï¼Œå®ç°èµ·æ¥ä¼šç´¯æ­»äººã€‚è¿™ç¯‡æ–‡ç« ä»‹ç»çš„å¯¹æŠ—ç”Ÿæˆç½‘ç»œå±äºæ— ç›‘ç£å­¦ä¹ ï¼Œå¯ä»¥å®Œå…¨ä¸éœ€è¦ç»™æ•°æ®æ‰“æ ‡ç­¾ï¼Œä½ åªéœ€è¦ç»™æ¨¡å‹è®¤è¯†ä¸€äº›çœŸå®æ•°æ®ï¼Œå°±å¯ä»¥è®©æ¨¡å‹è¾“å‡ºç±»ä¼¼çœŸå®æ•°æ®çš„å‡æ•°æ®ã€‚å¯¹æŠ—ç”Ÿæˆç½‘ç»œåˆ†ä¸ºä¸¤éƒ¨åˆ†ï¼Œç¬¬ä¸€éƒ¨åˆ†æ˜¯ç”Ÿæˆå™¨ (Generator)ï¼Œç¬¬äºŒéƒ¨åˆ†æ˜¯è¯†åˆ«å™¨ (Discriminator)ï¼Œç”Ÿæˆå™¨è´Ÿè´£æ ¹æ®**éšæœºæ¡ä»¶**ç”Ÿæˆæ•°æ®ï¼Œè¯†åˆ«å™¨è´Ÿè´£è¯†åˆ«æ•°æ®æ˜¯å¦ä¸ºçœŸã€‚

![03](./03.png)

è®­ç»ƒå¯¹æŠ—ç”Ÿæˆç½‘ç»œæœ‰ä¸¤å¤§ç›®æ ‡ï¼Œè¿™ä¸¤å¤§ç›®æ ‡æ˜¯çŸ›ç›¾çš„ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å«**å¯¹æŠ—**ç”Ÿæˆç½‘ç»œï¼š

- ç”Ÿæˆå™¨éœ€è¦ç”Ÿæˆéª—è¿‡è¯†åˆ«å™¨ (è¾“å‡ºä¸ºçœŸ) çš„æ•°æ®
- è¯†åˆ«å™¨éœ€è¦ä¸è¢«ç”Ÿæˆå™¨éª—è¿‡å» (é’ˆå¯¹ç”Ÿæˆå™¨ç”Ÿæˆçš„æ•°æ®è¾“å‡ºä¸ºå‡ï¼Œé’ˆå¯¹çœŸå®æ•°æ®è¾“å‡ºä¸ºçœŸ)

å¯¹æŠ—ç”Ÿæˆç½‘ç»œçš„è®­ç»ƒæµç¨‹å¤§è‡´å¦‚ä¸‹ï¼Œéœ€è¦å¾ªç¯è®­ç»ƒç”Ÿæˆå™¨å’Œè¯†åˆ«å™¨ï¼š

![04](./04.png)

ç®€å•é€šä¿—ä¸€ç‚¹æˆ‘ä»¬å¯ä»¥ç”¨é€ å‡çš®åŒ…ä¸ºä¾‹æ¥ç†è§£ï¼Œå¥½ç†è§£äº†å§ğŸ¤—ï¼š

![05](./05.png)

å’Œç°å®é€ å‡çš®åŒ…ä¸€æ ·ï¼Œç”Ÿæˆå™¨ä¼šç”Ÿæˆè¶Šæ¥è¶Šæ¥è¿‘çœŸå®æ•°æ®çš„å‡æ•°æ®ï¼Œæœ€åä¼šç”Ÿæˆå’ŒçœŸå®æ•°æ®ä¸€æ¨¡ä¸€æ ·çš„æ•°æ®ï¼Œä½†è¿™æ ·åè€Œå°±è¿œç¦»æˆ‘ä»¬æ„å»ºç”Ÿæˆç½‘ç»œçš„ç›®çš„äº†ï¼ˆä¸å¦‚ç›´æ¥ç”¨çœŸå®æ•°æ®ï¼‰ã€‚ä½¿ç”¨ç”Ÿæˆç½‘ç»œé€šå¸¸æ˜¯ä¸ºäº†è¾¾åˆ°ä»¥ä¸‹çš„ç›®çš„ï¼š

- è¦æ±‚å¤§é‡çœ‹ä¸Šå»æ˜¯çœŸçš„ï¼Œä½†ç¨å¾®ä¸ä¸€æ ·çš„æ•°æ®
- è¦æ±‚æ²¡æœ‰ç‰ˆæƒä¿æŠ¤çš„æ•°æ® (å‡æ•°æ®æ²¡æ¥çš„ç‰ˆæƒğŸ¤’)
- ç”Ÿæˆæƒ³è¦ä½†æ˜¯ç°å®æ²¡æœ‰çš„æ•°æ® (éœ€è¦æ›´è¿›ä¸€æ­¥çš„å·¥ä½œ)

çœ‹ä»¥ä¸Šçš„æµç¨‹ä½ å¯èƒ½ä¼šå‘ç°ï¼Œå› ä¸ºå¯¹æŠ—ç”Ÿæˆç½‘ç»œæ˜¯æ— ç›‘ç£å­¦ä¹ ï¼Œä¸éœ€è¦æ ‡ç­¾ï¼Œæˆ‘ä»¬åªèƒ½ç»™æ¨¡å‹ä¼ å…¥éšæœºçš„æ¡ä»¶æ¥è®©å®ƒç”Ÿæˆæ•°æ®ï¼Œæ¨¡å‹ç”Ÿæˆå‡ºæ¥çš„æ•°æ®çœ‹èµ·æ¥å¯èƒ½åƒçœŸçš„ä½†ä¸ä¸€å®šæ˜¯æˆ‘ä»¬æƒ³è¦çš„ã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦æŒ‡å®šå…·ä½“çš„æ¡ä»¶ï¼Œåˆ™éœ€è¦åœ¨è®­ç»ƒå®Œæˆä»¥ååˆ†æéšæœºæ¡ä»¶å¯¹ç”Ÿæˆç»“æœçš„å½±å“ï¼Œä¾‹å¦‚éšæœºç”Ÿæˆçš„ç¬¬äºŒä¸ªæ•°å­—ä»£è¡¨æ€§åˆ«ï¼Œç¬¬å…­ä¸ªæ•°å­—ä»£è¡¨å¹´é¾„ï¼Œç¬¬å…«ä¸ªæ•°å­—ä»£è¡¨å¤´å‘çš„æ•°é‡ï¼Œè¿™æ ·æˆ‘ä»¬å°±å¯ä»¥è°ƒæ•´è¿™äº›æ¡ä»¶æ¥è®©æ¨¡å‹ç”Ÿæˆæƒ³è¦çš„å›¾ç‰‡ã€‚

è¿˜è®°å¾—ä¸Šä¸€ç¯‡äººè„¸è¯†åˆ«çš„æ¨¡å‹ä¸ï¼Ÿäººè„¸è¯†åˆ«çš„æ¨¡å‹ä¼šæŠŠå›¾ç‰‡è½¬æ¢ä¸ºæŸä¸ªé•¿åº¦çš„å‘é‡ï¼Œè®­ç»ƒå®Œæˆä»¥åè¿™ä¸ªå‘é‡çš„å€¼ä¼šä»£è¡¨äººç‰©çš„å±æ€§ï¼Œè€Œè¿™ä¸€ç¯‡æ˜¯åè¿‡æ¥ï¼ŒæŠŠæŸä¸ªé•¿åº¦çš„å‘é‡è½¬æ¢å›å›¾ç‰‡ï¼Œè®­ç»ƒæˆåŠŸä»¥åè¿™ä¸ªå‘é‡åŒæ ·ä¼šä»£è¡¨äººç‰©çš„å„ä¸ªå±æ€§ã€‚å½“ç„¶ï¼Œä¸¤ç§çš„å‘é‡è¡¨ç°å½¢å¼æ˜¯ä¸åŒçš„ï¼ŒæŠŠäººè„¸è¯†åˆ«è¾“å‡ºçš„å‘é‡äº¤ç»™å¯¹æŠ—ç”Ÿæˆç½‘ç»œï¼Œç”Ÿæˆçš„å›¾ç‰‡å’ŒåŸæœ‰çš„å›¾ç‰‡å¯èƒ½ä¼šç›¸å·®å¾ˆè¿œï¼ŒæŠŠäººè„¸è¯†åˆ«è¾“å‡ºçš„å‘é‡è¿˜åŸå›å»çš„æ–¹æ³•åé¢å†ç ”ç©¶å§ğŸ¤•ã€‚

## å¯¹æŠ—ç”Ÿæˆç½‘ç»œçš„å®ç°

### åå·ç§¯å±‚ (ConvTranspose2d)

åœ¨[ç¬¬å…«ç¯‡](https://303248153.github.io/ml-08/)ä»‹ç» CNN çš„æ–‡ç« ä¸­ï¼Œæˆ‘ä»¬äº†è§£è¿‡å·ç§¯å±‚è¿ç®— (Conv2d) çš„å®ç°åŸç†ï¼ŒCNN æ¨¡å‹ä¼šåˆ©ç”¨å·ç§¯å±‚æ¥æŠŠå›¾ç‰‡çš„é•¿å®½é€æ¸ç¼©å°ï¼Œé€šé“æ•°é€æ¸æ‰©å¤§ï¼Œæœ€åæ‰å¹³åŒ–è¾“å‡ºä¸€ä¸ªä»£è¡¨å›¾ç‰‡ç‰¹å¾çš„å‘é‡ï¼š

![06](./06.png)

![07](./07.png)

è€Œåœ¨å¯¹æŠ—ç”Ÿæˆç½‘ç»œçš„ç”Ÿæˆå™¨ä¸­ï¼Œæˆ‘ä»¬éœ€è¦å®ç°åå‘çš„æ“ä½œï¼Œå³æŠŠå‘é‡å½“ä½œä¸€ä¸ª (å‘é‡é•¿åº¦, 1, 1) çš„å›¾ç‰‡ï¼Œç„¶åæŠŠé•¿å®½é€æ¸æ‰©å¤§ï¼Œé€šé“æ•° (æœ€å¼€å§‹æ˜¯å‘é‡é•¿åº¦) é€æ¸ç¼©å°ï¼Œæœ€åå˜ä¸º (3, å›¾ç‰‡é•¿åº¦, å›¾ç‰‡å®½åº¦) çš„å›¾ç‰‡ (3 ä»£è¡¨ RGB)ã€‚

å®ç°åå‘æ“ä½œéœ€è¦åå·ç§¯å±‚ (ConvTranspose2d)ï¼Œåå·ç§¯å±‚ç®€å•çš„æ¥è¯´å°±æ˜¯åœ¨å‚æ•°æ•°é‡ç›¸åŒçš„æƒ…å†µä¸‹ï¼ŒæŠŠè¾“å‡ºå¤§å°çš„æ•°æ®è¿˜åŸä¸ºè¾“å…¥å¤§å°çš„æ•°æ®ï¼š

![08](./08.png)

è¦ç†è§£åå·ç§¯å±‚çš„å…·ä½“è¿ç®—æ–¹å¼ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠå·ç§¯å±‚æ‹†è§£ä¸ºç®€å•çš„çŸ©é˜µä¹˜æ³•ï¼š

![09](./09.png)

å¯ä»¥çœ‹åˆ°å·ç§¯å±‚è®¡ç®—çš„æ—¶å€™å¯ä»¥æ ¹æ®å†…æ ¸å‚æ•°å’Œè¾“å…¥å¤§å°ç”Ÿæˆä¸€ä¸ªçŸ©é˜µï¼Œç„¶åè®¡ç®—è¾“å…¥ä¸è¿™ä¸ªçŸ©é˜µçš„ä¹˜ç§¯æ¥å¾—åˆ°è¾“å‡ºç»“æœã€‚

è€Œåå·ç§¯å±‚åˆ™ä¼šè®¡ç®—è¾“å…¥ä¸è½¬ç½® (Transpose) åçš„çŸ©é˜µçš„ä¹˜ç§¯å¾—åˆ°è¾“å‡ºç»“æœï¼š

![10](./10.png)

å¯ä»¥çœ‹åˆ°å·ç§¯å±‚ä¸åå·ç§¯å±‚çš„åŒºåˆ«åªåœ¨äºæ˜¯å¦è½¬ç½®è®¡ç®—ä½¿ç”¨çš„çŸ©é˜µã€‚æ­¤å¤–ï¼Œé€šé“æ•°é‡è½¬æ¢çš„è®¡ç®—æ–¹å¼ä¹Ÿæ˜¯ä¸€æ ·çš„ã€‚

æµ‹è¯•åå·ç§¯å±‚çš„ä»£ç å¦‚ä¸‹ï¼š

``` python
>>> import torch

# ç”Ÿæˆæµ‹è¯•ç”¨çš„çŸ©é˜µ
# ç¬¬ä¸€ä¸ªç»´åº¦ä»£è¡¨æ‰¹æ¬¡ï¼Œç¬¬äºŒä¸ªç»´åº¦ä»£è¡¨é€šé“æ•°é‡ï¼Œç¬¬ä¸‰ä¸ªç»´åº¦ä»£è¡¨é•¿åº¦ï¼Œç¬¬å››ä¸ªç»´åº¦ä»£è¡¨å®½åº¦
>>> a = torch.arange(1, 5).float().reshape(1, 1, 2, 2)
>>> a
tensor([[[[1., 2.],
          [3., 4.]]]])

# åˆ›å»ºåå·ç§¯å±‚
>>> convtranspose2d = torch.nn.ConvTranspose2d(1, 1, kernel_size=2, stride=2, bias=False)

# æ‰‹åŠ¨æŒ‡å®šæƒé‡ (è®©è®¡ç®—æ›´å¥½ç†è§£)
>>> convtranspose2d.weight = torch.nn.Parameter(torch.tensor([0.1, 0.2, 0.5, 0.8]).reshape(1, 1, 2, 2))
>>> convtranspose2d.weight
Parameter containing:
tensor([[[[0.1000, 0.2000],
          [0.5000, 0.8000]]]], requires_grad=True)

# æµ‹è¯•åå·ç§¯å±‚
>>> convtranspose2d(a)
tensor([[[[0.1000, 0.2000, 0.2000, 0.4000],
          [0.5000, 0.8000, 1.0000, 1.6000],
          [0.3000, 0.6000, 0.4000, 0.8000],
          [1.5000, 2.4000, 2.0000, 3.2000]]]],
       grad_fn=<SlowConvTranspose2DBackward>)
```

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸ä¸€å®šå­˜åœ¨ä¸€ä¸ªåå·ç§¯å±‚å¯ä»¥æŠŠå·ç§¯å±‚çš„è¾“å‡ºè¿˜åŸåˆ°è¾“å…¥ï¼Œè¿™æ˜¯å› ä¸ºå·ç§¯å±‚çš„è®¡ç®—æ˜¯ä¸å¯é€†çš„ï¼Œå³ä½¿å­˜åœ¨ä¸€ä¸ªå¯ä»¥æŠŠè¾“å‡ºè¿˜åŸåˆ°è¾“å…¥çš„çŸ©é˜µï¼Œè¿™ä¸ªçŸ©é˜µä¹Ÿä¸ä¸€å®šæœ‰ä¸€ä¸ªç­‰æ•ˆçš„åå·ç§¯å±‚çš„å†…æ ¸å‚æ•°ã€‚

### ç”Ÿæˆå™¨çš„å®ç° (Generator)

æ¥ä¸‹æ¥æˆ‘ä»¬çœ‹ä¸€ä¸‹ç”Ÿæˆå™¨çš„å®šä¹‰ï¼ŒåŸå§‹ä»‹ç» GAN çš„è®ºæ–‡ç»™å‡ºäº†ç”Ÿæˆ 64x64 å›¾ç‰‡çš„ç½‘ç»œï¼Œè€Œè¿™é‡Œç»™å‡ºçš„æ˜¯ç”Ÿæˆ 80x80 å›¾ç‰‡çš„ç½‘ç»œï¼Œå…¶å®åŒºåˆ«åªåœ¨äºä¸€å¼€å§‹çš„è¾“å‡ºé€šé“æ•°é‡ (è®ºæ–‡æ˜¯ 4, è¿™é‡Œæ˜¯ 5ï¼‰

``` python
class GenerationModel(nn.Module):
    """ç”Ÿæˆè™šå‡æ•°æ®çš„æ¨¡å‹"""
    # ç¼–ç é•¿åº¦
    EmbeddedSize = 128

    def __init__(self):
        super().__init__()
        self.generator = nn.Sequential(
            # 128,1,1 => 512,5,5
            nn.ConvTranspose2d(128, 512, kernel_size=5, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            # => 256,10,10
            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            # => 128,20,20
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            # => 64,40,40
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            # => 3,80,80
            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),
            # é™åˆ¶è¾“å‡ºåœ¨ -1 ~ 1ï¼Œä¸ä½¿ç”¨ Hardtanh æ˜¯ä¸ºäº†è®©è¶…è¿‡èŒƒå›´çš„å€¼å¯ä»¥ä¼ æ’­ç»™ä¸Šå±‚
            nn.Tanh())

    def forward(self, x):
        y = self.generator(x.view(x.shape[0], x.shape[1], 1, 1))
        return y
```

è¡¨ç°å¦‚ä¸‹ï¼š

![11](./11.png)

å…¶ä¸­æ‰¹æ¬¡æ­£è§„åŒ– (BatchNorm) ç”¨äºæ§åˆ¶å‚æ•°å€¼èŒƒå›´ï¼Œé˜²æ­¢å±‚æ•°è¿‡å¤š (åé¢ä¼šç»“åˆè¯†åˆ«å™¨è®­ç»ƒ) å¯¼è‡´æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ã€‚

è¿˜æœ‰ä¸€ä¸ªè¦ç‚¹æ˜¯ç”Ÿæˆå™¨è¾“å‡ºçš„èŒƒå›´ä¼šåœ¨ -1 ~ 1ï¼Œä¹Ÿå°±æ˜¯ä½¿ç”¨ -1 ~ 1 ä»£è¡¨ 0 ~ 255 çš„é¢œè‰²å€¼ï¼Œè¿™è·Ÿæˆ‘ä»¬ä¹‹å‰å¤„ç†å›¾ç‰‡çš„æ—¶å€™æŠŠå€¼é™¤ä»¥ 255 ä½¿å¾—èŒƒå›´åœ¨ 0 ~ 1 ä¸ä¸€æ ·ã€‚ä½¿ç”¨ -1 ~ 1 å¯ä»¥æå‡è¾“å‡ºé¢œè‰²çš„ç²¾åº¦ (å‡å°‘æµ®ç‚¹æ•°çš„ç²¾åº¦æŸå¤±)ã€‚

### è¯†åˆ«å™¨çš„å®ç° (Discriminator)

æˆ‘ä»¬å†çœ‹ä»¥ä¸‹è¯†åˆ«å™¨çš„å®šä¹‰ï¼ŒåŸºæœ¬ä¸Šå°±æ˜¯å‰é¢ç”Ÿæˆå™¨çš„ç›¸åæµç¨‹ï¼š

``` python
class DiscriminationModel(nn.Module):
    """è¯†åˆ«æ•°æ®æ˜¯å¦çœŸå®çš„æ¨¡å‹"""

    def __init__(self):
        super().__init__()
        self.discriminator = nn.Sequential(
            # 3,80,80 => 64,40,40
            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # => 128,20,20
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            # => 256,10,10
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            # => 512,5,5
            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
            # => 1,1,1
            nn.Conv2d(512, 1, kernel_size=5, stride=1, padding=0, bias=False),
            # æ‰å¹³åŒ–
            nn.Flatten(),
            # è¾“å‡ºæ˜¯å¦çœŸå®æ•°æ® (0 or 1)
            nn.Sigmoid())

    def forward(self, x):
        y = self.discriminator(x)
        return y
```

è¡¨ç°å¦‚ä¸‹ï¼š

![12](./12.png)

çœ‹åˆ°è¿™é‡Œä½ å¯èƒ½ä¼šæœ‰å‡ ä¸ªç–‘é—®ï¼š

- ä¸ºä»€ä¹ˆç”¨ LeakyReLU: è¿™æ˜¯ä¸ºäº†é˜²æ­¢å±‚æ•°å åŠ æ¬¡æ•°è¿‡å¤šå¯¼è‡´çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ï¼Œå‚è€ƒ[ç¬¬ä¸‰ç¯‡](https://303248153.github.io/ml-03/)ï¼ŒLeakyReLU å¯¹äºè´Ÿæ•°è¾“å…¥ä¸ä¼šè¿”å› 0ï¼Œè€Œæ˜¯è¿”å› `è¾“å…¥ * slope`ï¼Œè¿™é‡Œçš„ `slope` æŒ‡å®šä¸º 0.2
- ä¸ºä»€ä¹ˆç¬¬ä¸€å±‚ä¸åŠ æ‰¹æ¬¡æ­£è§„åŒ– (BatchNorm): åŸæœ‰è®ºæ–‡ä¸­æåˆ°å®é™…æµ‹è¯•ä¸­ï¼Œå¦‚æœåœ¨æ‰€æœ‰å±‚æ·»åŠ æ‰¹æ¬¡æ­£è§„åŒ–ä¼šè®©æ¨¡å‹è®­ç»ƒç»“æœä¸ç¨³å®šï¼Œç”Ÿæˆå™¨çš„æœ€åä¸€å±‚å’Œè¯†åˆ«å™¨çš„ç¬¬ä¸€å±‚æ‹¿æ‰ä»¥åæ•ˆæœä¼šå¥½ä¸€äº›
- ä¸ºä»€ä¹ˆä¸åŠ æ± åŒ–å±‚: æ·»åŠ æ± åŒ–å±‚ä»¥åå¯é€†æ€§å°†ä¼šé™ä½ï¼Œä¾‹å¦‚è¯†åˆ«å™¨é’ˆå¯¹å‡æ•°æ®è¿”å›æ¥è¿‘ 0 çš„æ•°å€¼æ—¶ï¼Œåˆ¤æ–­å“ªäº›éƒ¨åˆ†å¯¼è‡´è¿™ä¸ªè¾“å‡ºçš„ä¾æ®ä¼šå‡å°‘

### è®­ç»ƒç”Ÿæˆå™¨å’Œè¯†åˆ«å™¨çš„æ–¹æ³•

æ¥ä¸‹æ¥å°±æ˜¯è®­ç»ƒç”Ÿæˆå™¨å’Œè¯†åˆ«å™¨ï¼Œç”Ÿæˆå™¨å’Œè¯†åˆ«å™¨éœ€è¦åˆ†åˆ«è®­ç»ƒï¼Œè®­ç»ƒè¯†åˆ«å™¨çš„æ—¶å€™ä¸èƒ½åŠ¨ç”Ÿæˆå™¨çš„å‚æ•°ï¼Œè®­ç»ƒç”Ÿæˆå™¨çš„æ—¶å€™ä¸èƒ½åŠ¨è¯†åˆ«å™¨çš„å‚æ•°ï¼Œä½¿ç”¨çš„ä»£ç å¤§è‡´å¦‚ä¸‹ï¼š

``` python
# åˆ›å»ºæ¨¡å‹å®ä¾‹
generation_model = GenerationModel().to(device)
discrimination_model = DiscriminationModel().to(device)

# åˆ›å»ºå‚æ•°è°ƒæ•´å™¨
# æ ¹æ®ç”Ÿæˆå™¨å’Œè¯†åˆ«å™¨åˆ†åˆ«åˆ›å»º
optimizer_g = torch.optim.Adam(generation_model.parameters())
optimizer_d = torch.optim.Adam(discrimination_model.parameters())

# éšæœºç”Ÿæˆç¼–ç 
def generate_vectors(batch_size):
    vectors = torch.randn((batch_size, GenerationModel.EmbeddedSize), device=device)
    return vectors

# å¼€å§‹è®­ç»ƒè¿‡ç¨‹
for epoch in range(0, 10000):
    # æšä¸¾çœŸå®æ•°æ®
    for index, batch_x in enumerate(read_batches()):
        # ç”Ÿæˆéšæœºç¼–ç 
        training_vectors = generate_vectors(minibatch_size)
        # ç”Ÿæˆè™šå‡æ•°æ®
        generated = generation_model(training_vectors)
        # è·å–çœŸå®æ•°æ®
        real = batch_x
 
        # è®­ç»ƒè¯†åˆ«å™¨ (åªè°ƒæ•´è¯†åˆ«å™¨çš„å‚æ•°)
        predicted_t = discrimination_model(real)
        predicted_f = discrimination_model(generated)
        loss_d = (
            nn.functional.binary_cross_entropy(
                predicted_t, torch.ones(predicted_t.shape, device=device)) +
            nn.functional.binary_cross_entropy(
                predicted_f, torch.zeros(predicted_f.shape, device=device)))
        loss_d.backward() # æ ¹æ®æŸå¤±è‡ªåŠ¨å¾®åˆ†
        optimizer_d.step() # è°ƒæ•´è¯†åˆ«å™¨çš„å‚æ•°
        optimizer_g.zero_grad() # æ¸…ç©ºç”Ÿæˆå™¨å‚æ•°è®°å½•çš„å¯¼å‡½æ•°å€¼
        optimizer_d.zero_grad() # æ¸…ç©ºè¯†åˆ«å™¨å‚æ•°è®°å½•çš„å¯¼å‡½æ•°å€¼

        # è®­ç»ƒç”Ÿæˆå™¨ (åªè°ƒæ•´ç”Ÿæˆå™¨çš„å‚æ•°)
        predicted_f = discrimination_model(generated)
        loss_g = nn.functional.binary_cross_entropy(
            predicted_f, torch.ones(predicted_f.shape, device=device))
        loss_g.backward() # æ ¹æ®æŸå¤±è‡ªåŠ¨å¾®åˆ†
        optimizer_g.step() # è°ƒæ•´ç”Ÿæˆå™¨çš„å‚æ•°
        optimizer_g.zero_grad() # æ¸…ç©ºç”Ÿæˆå™¨å‚æ•°è®°å½•çš„å¯¼å‡½æ•°å€¼
        optimizer_d.zero_grad() # æ¸…ç©ºè¯†åˆ«å™¨å‚æ•°è®°å½•çš„å¯¼å‡½æ•°å€¼
```

ä¸Šè¿°ä¾‹å­åº”è¯¥å¯ä»¥å¸®åŠ©ä½ ç†è§£å¤§è‡´çš„è®­ç»ƒæµç¨‹å’Œåªè®­ç»ƒè¯†åˆ«å™¨æˆ–ç”Ÿæˆå™¨çš„æ–¹æ³•ï¼Œä½†æ˜¯ç›´æ¥è¿™ä¹ˆåšæ•ˆæœä¼šå¾ˆå·®ğŸ¤•ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬ä¼šçœ‹çœ‹å¯¹æŠ—ç”Ÿæˆç½‘ç»œçš„é—®é¢˜ï¼Œå¹¶ä¸”ç»™å‡ºä¼˜åŒ–æ–¹æ¡ˆï¼Œåé¢çš„å®Œæ•´ä»£ç ä¼šè·Ÿä¸Šè¿°ä¾‹å­æœ‰ä¸€äº›ä¸åŒã€‚

å¦‚æœå¯¹åŸå§‹è®ºæ–‡æœ‰å…´è¶£å¯ä»¥å‚è€ƒ[è¿™é‡Œ](https://arxiv.org/pdf/1511.06434.pdf)ï¼ŒåŸå§‹çš„å¯¹æŠ—ç”Ÿæˆç½‘ç»œåˆç§° DCGAN (Deep Convolutional GAN)ã€‚

## å¯¹æŠ—ç”Ÿæˆç½‘ç»œçš„é—®é¢˜

çœ‹å®Œä»¥ä¸Šçš„å†…å®¹ä½ å¯èƒ½ä¼šè§‰å¾—ï¼Œå˜¿å˜¿ï¼Œè¿˜æ˜¯æŒºç®€å•çš„ã€‚ä¸ğŸ¤•ï¼Œè™½ç„¶åŸç†çœ‹ä¸Šå»æŒºå¥½ç†è§£ï¼Œæ¨¡å‹æœ¬èº«ä¹Ÿä¸å¤æ‚ï¼Œä½†å¯¹æŠ—ç”Ÿæˆç½‘ç»œæ˜¯ç›®å‰ä»‹ç»è¿‡çš„æ¨¡å‹é‡Œé¢è®­ç»ƒéš¾åº¦æœ€é«˜çš„ï¼Œè¿™æ˜¯å› ä¸ºå¯¹æŠ—ç”Ÿæˆç½‘ç»œå»ºç«‹åœ¨çŸ›ç›¾ä¸Šï¼Œæ²¡æœ‰ä¸€ä¸ªæ˜ç¡®çš„ç›®æ ‡ (ä¹‹å‰çš„æ¨¡å‹ç›®æ ‡éƒ½æ˜¯é’ˆå¯¹æœªå­¦ä¹ è¿‡çš„æ•°æ®é¢„æµ‹æ­£ç¡®ç‡å°½å¯èƒ½æ¥è¿‘ 100%)ã€‚å¦‚æœç”Ÿæˆå™¨ç”Ÿæˆ 100% å¯ä»¥éª—è¿‡è¯†åˆ«å™¨çš„æ•°æ®ï¼Œé‚£å¯èƒ½ä»£è¡¨è¯†åˆ«å™¨æ ¹æœ¬æ²¡æ­£å¸¸å·¥ä½œï¼Œæˆ–è€…ç”Ÿæˆå™¨ç”Ÿæˆçš„æ•°æ®è·ŸçœŸå®æ•°æ® 100% ç›¸åŒï¼Œæ²¡å®ç”¨ä»·å€¼ï¼›è€Œå¦‚æœè¯†åˆ«å™¨ 100% å¯ä»¥è¯†åˆ«ç”Ÿæˆå™¨ç”Ÿæˆçš„æ•°æ®ï¼Œé‚£ä»£è¡¨ç”Ÿæˆå™¨ç”Ÿæˆçš„æ•°æ®å¤ªåƒåœ¾ï¼Œä¸€ä¸ªéƒ½éª—ä¸è¿‡ã€‚æœ¬ç¯‡ä»‹ç»çš„ä¾‹å­ä½¿ç”¨äº†æœ€è ¢æœ€ç®€å•çš„æ–¹æ³•ï¼ŒæŠŠæ¯ä¸€è½®å­¦ä¹ åç”Ÿæˆå™¨ç”Ÿæˆçš„æ•°æ®è¾“å‡ºåˆ°ç¡¬ç›˜ï¼Œç„¶åäººå·¥é‰´å®šç”Ÿæˆçš„æ•ˆæœæ€æ ·ğŸ¤’ï¼ŒåŒæ—¶è¿˜ä¼šæ¯ 100 è½®è®­ç»ƒè®°å½•ä¸€æ¬¡æ¨¡å‹çŠ¶æ€ï¼Œä¾›è®­ç»ƒå®Œä»¥åå›æ»šä½¿ç”¨ (æœ€åä¸€ä¸ªæ¨¡å‹çŠ¶æ€æ•ˆæœä¸ä¼šæ˜¯æœ€å¥½çš„ï¼Œåé¢ä¼šè¯´æ˜)ã€‚

å¦ä¸€ä¸ªé—®é¢˜æ˜¯è¯†åˆ«å™¨å’Œç”Ÿæˆå™¨ä¸èƒ½åŒæ—¶è®­ç»ƒï¼Œæ€æ ·å®‰æ’è®­ç»ƒè¿‡ç¨‹å¯¹è®­ç»ƒç»“æœçš„å½±å“éå¸¸å¤§ğŸ˜®ï¼Œç†æƒ³çš„è¿‡ç¨‹æ˜¯ï¼šè¯†åˆ«å™¨ç¨å¾®é¢†å…ˆç”Ÿæˆå™¨ï¼Œç”Ÿæˆå™¨è·Ÿç€è¯†åˆ«å™¨æ…¢æ…¢çš„ç”Ÿæˆè¶Šæ¥è¶Šç²¾å‡†çš„æ•°æ®ã€‚ä¸¾ä¾‹æ¥è¯´ï¼Œè¯†åˆ«å™¨é¦–å…ˆä¼šè¯†åˆ«è‚¤è‰²å æ¯”è¾ƒå¤šçš„å›¾ç‰‡ä¸ºäººè„¸ï¼Œæ¥ä¸‹æ¥ç”Ÿæˆå™¨ä¼šç”Ÿæˆå…¨éƒ¨éƒ½æ˜¯è‚¤è‰²çš„å›¾ç‰‡ï¼Œç„¶åè¯†åˆ«å™¨ä¼šè¯†åˆ«æœ‰ä¸¤ä¸ªçœ‹ä¸Šå»æ˜¯çœ¼ç›çš„å›¾ç‰‡ä¸ºäººè„¸ï¼Œæ¥ä¸‹æ¥ç”Ÿæˆå™¨ä¼šåŠ ä¸Šä¸¤ä¸ªçœ‹ä¸Šå»æ˜¯çœ¼ç›çš„å½¢çŠ¶åˆ°å›¾ç‰‡ï¼Œä¹‹åè¯†åˆ«å™¨ä¼šè¯†åˆ«å¸¦æœ‰äº”å®˜çš„å›¾ç‰‡ä¸ºäººè„¸ï¼Œæ¥ä¸‹æ¥ç”Ÿæˆå™¨ä¼šåŠ ä¸Šå‰©ä½™çš„äº”å®˜åˆ°å›¾ç‰‡ï¼Œæœ€åè¯†åˆ«å™¨ä¼šè¯†åˆ«äº”å®˜å’Œè„¸å½¢çŠ¶æ¯”è¾ƒæ­£å¸¸çš„äººä¸ºäººè„¸ï¼Œç”Ÿæˆå™¨ä¼šå°½é‡è°ƒæ•´äº”å®˜å’Œäººè„¸å½¢çŠ¶æ¥è¿‘æ­£å¸¸æ°´å¹³ã€‚è€Œä¸ç†æƒ³çš„è¿‡ç¨‹æ˜¯è¯†åˆ«å™¨å¤§å¹…é¢†å…ˆç”Ÿæˆå™¨ï¼Œä¾‹å¦‚è¯†åˆ«å™¨å¾ˆæ—©å°±è¾¾åˆ°äº†æ¥è¿‘ 100% çš„æ­£ç¡®ç‡ï¼Œè€Œç”Ÿæˆå™¨å› ä¸ºæ‰¾ä¸åˆ°å­¦ä¹ çš„æ–¹å‘æ­£ç¡®ç‡ä¼šä¸€ç›´åŸåœ°è¸æ­¥ï¼›å¦ä¸€ä¸ªä¸ç†æƒ³çš„è¿‡ç¨‹æ˜¯ç”Ÿæˆå™¨é¢†å…ˆè¯†åˆ«å™¨ï¼Œè¿™æ—¶ä¼šå‡ºç°è¯†åˆ«å™¨æ‰¾ä¸åˆ°å­¦ä¹ çš„æ–¹å‘ï¼Œç”Ÿæˆå™¨ä¹Ÿæ‰¾ä¸åˆ°å­¦ä¹ çš„æ–¹å‘è€ŒåŸåœ°è½¬çš„æƒ…å†µã€‚å®ç°è¯†åˆ«å™¨ç¨å¾®é¢†å…ˆç”Ÿæˆå™¨ï¼Œå¯ä»¥å¢åŠ è¯†åˆ«å™¨çš„è®­ç»ƒæ¬¡æ•°ï¼Œå¸¸è§çš„æ–¹æ³•æ˜¯æ¯è®­ç»ƒ n æ¬¡è¯†åˆ«å™¨å°±è®­ç»ƒ 1 æ¬¡ç”Ÿæˆå™¨ï¼Œè€Œæœ¬æ–‡åé¢ä¼šä»‹ç»æ ¹æ®æ­£ç¡®ç‡åŠ¨æ€è°ƒæ•´è¯†åˆ«å™¨å’Œç”Ÿæˆå™¨å­¦ä¹ æ¬¡æ•°çš„æ–¹æ³•ï¼Œå‚è€ƒåé¢çš„ä»£ç å§ã€‚

å¯¹æŠ—ç”Ÿæˆç½‘ç»œæœ€å¤§çš„é—®é¢˜æ˜¯æ¨¡å¼å´©æºƒ (Mode Collapse) é—®é¢˜ï¼Œè¿™ä¸ªé—®é¢˜æ‰€æœ‰è®­ç»ƒå¯¹æŠ—ç”Ÿæˆç½‘ç»œçš„äººéƒ½ä¼šé¢å¯¹ï¼Œå¹¶ä¸”ç›®å‰æ²¡æœ‰ 100% çš„æ–¹æ³•é¿å…ğŸ˜­ã€‚ç®€å•çš„æ¥è¯´å°±æ˜¯ç”Ÿæˆå™¨å­¦ä¼šå·æ‡’ä½œå¼Šï¼Œåªä¼šè¾“å‡ºä¸€åˆ°å‡ ä¸ªä¸çœŸå®æ•°æ®å‡ ä¹ä¸€æ¨¡ä¸€æ ·çš„è™šå‡æ•°æ®ï¼Œå› ä¸ºç”Ÿæˆçš„æ•°æ®åŒè´¨åŒ–éå¸¸ä¸¥é‡ï¼Œå³ä½¿å¯ä»¥éª—è¿‡è¯†åˆ«å™¨ä¹Ÿæ²¡ä»€ä¹ˆå®ç”¨ä»·å€¼ã€‚å‘ç”Ÿæ¨¡å¼å´©æºƒä»¥åçš„è¾“å‡ºä¾‹å­å¦‚ä¸‹ï¼Œå¯ä»¥çœ‹åˆ°å¾ˆå¤šäººè„¸éƒ½éå¸¸æ¥è¿‘ï¼š

![13](./13.png)

ä¸ºäº†å°½é‡é¿å…æ¨¡å¼å´©æºƒé—®é¢˜ï¼Œä»¥ä¸‹å‡ ä¸ªæ”¹è¿›çš„æ¨¡å‹è¢«å‘æ˜äº†å‡ºæ¥ï¼Œè¿™å°±æ˜¯äººæ°‘ç¾¤ä¼—çš„æ™ºæ…§å•ŠğŸ˜¡ã€‚

## æ”¹è¿›å¯¹æŠ—ç”Ÿæˆç½‘ç»œ (WGAN)

æ¨¡å¼å´©æºƒé—®é¢˜çš„åŸå› ä¹‹ä¸€å°±æ˜¯éƒ¨åˆ†æ¨¡å‹å‚æ•°ä¼šéšç€è®­ç»ƒå›ºåŒ– (è¾¾åˆ°æœ¬åœ°æœ€ä¼˜)ï¼Œå› ä¸ºåŸå§‹çš„å¯¹æŠ—ç”Ÿæˆç½‘ç»œä¼šè®©è¯†åˆ«å™¨è¾“å‡ºå°½å¯èƒ½æ¥è¿‘ 1 æˆ–è€… 0 çš„å€¼ï¼Œå¦‚æœå€¼å·²ç»æ˜¯ 0 æˆ–è€… 1 é‚£ä¹ˆå‚æ•°å°±ä¸ä¼šè¢«è°ƒæ•´ã€‚WGAN (Wasserstein GAN) çš„è§£å†³æ–¹å¼æ˜¯ä¸é™åˆ¶è¯†åˆ«å™¨è¾“å‡ºçš„å€¼èŒƒå›´ï¼Œåªè¦æ±‚è¯†åˆ«å™¨**é’ˆå¯¹çœŸå®æ•°æ®è¾“å‡ºçš„å€¼å¤§äºè™šå‡æ•°æ®è¾“å‡ºçš„å€¼**ï¼Œå’Œè¦æ±‚ç”Ÿæˆå™¨**ç”Ÿæˆå¯ä»¥è®©è¯†åˆ«å™¨è¾“å‡ºæ›´å¤§çš„å€¼çš„æ•°æ®**ã€‚

ç¬¬ä¸€ä¸ªä¿®æ”¹æ˜¯æ‹¿æ‰è¯†åˆ«å™¨æœ€åçš„ Sigmoidï¼Œè¿™æ ·è¯†åˆ«å™¨è¾“å‡ºçš„å€¼å°±ä¸ä¼šé™åˆ¶åœ¨ 0 ~ 1 çš„èŒƒå›´å†…ã€‚

ç¬¬äºŒä¸ªä¿®æ”¹æ˜¯ä¿®æ”¹è®¡ç®—æŸå¤±çš„æ–¹å¼ï¼š

``` python
# è®¡ç®—è¯†åˆ«å™¨çš„æŸå¤±ï¼Œä¿®æ”¹å‰
loss_d = (
    nn.functional.binary_cross_entropy(
        predicted_t, torch.ones(predicted_t.shape, device=device)) +
    nn.functional.binary_cross_entropy(
        predicted_f, torch.zeros(predicted_f.shape, device=device)))

# è®¡ç®—è¯†åˆ«å™¨çš„æŸå¤±ï¼Œä¿®æ”¹å
loss_d = predicted_f.mean() - predicted_t.mean()
```

``` python
# è®¡ç®—ç”Ÿæˆå™¨çš„æŸå¤±ï¼Œä¿®æ”¹å‰
loss_g = nn.functional.binary_cross_entropy(
            predicted_f, torch.ones(predicted_f.shape, device=device))

# è®¡ç®—ç”Ÿæˆå™¨çš„æŸå¤±ï¼Œä¿®æ”¹å
loss_g = -predicted_f.mean()
```

è¿™ä¹ˆä¿®æ”¹ä»¥åä¼šå‡ºç°ä¸€ä¸ªé—®é¢˜ï¼Œè¯†åˆ«å™¨è¾“å‡ºçš„å€¼èŒƒå›´ä¼šéšç€è®­ç»ƒè¶Šæ¥è¶Šå¤§ (ç”Ÿæˆå™¨æé«˜è™šå‡æ•°æ®çš„è¾“å‡ºå€¼ï¼Œæ¥ä¸‹æ¥è¯†åˆ«å™¨æé«˜çœŸå®æ•°æ®çš„è¾“å‡ºå€¼ï¼Œå¾ªç¯ä¸‹å»è¾“å‡ºå€¼å°±ä¼šè¶Šæ¥è¶Šå¤§ğŸ˜±)ï¼Œä»è€Œå¯¼è‡´æ¢¯åº¦çˆ†ç‚¸é—®é¢˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ WGAN å¯¹è¯†åˆ«å™¨å‚æ•°çš„å¯å–èŒƒå›´åšå‡ºäº†é™åˆ¶ï¼Œä¹Ÿå°±æ˜¯åœ¨è°ƒæ•´å®Œå‚æ•°ä»¥åè£å‰ªå‚æ•°ï¼Œç¬¬ä¸‰ä¸ªä¿®æ”¹å¦‚ä¸‹ï¼š

``` python
# è®©è¯†åˆ«å™¨å‚æ•°å¿…é¡»åœ¨ -0.1 ~ 0.1 ä¹‹é—´
for p in discrimination_model.parameters():
    p.data.clamp_(-0.1, 0.1)
```

å¦‚æœæœ‰å…´è¶£å¯ä»¥å‚è€ƒ WGAN çš„[åŸå§‹è®ºæ–‡](https://arxiv.org/pdf/1701.07875.pdf)ï¼Œé‡Œé¢ä¸€å¤§å †æ•°å­¦å…¬å¼å¯ä»¥æŠŠäººå“åğŸ˜±ï¼Œä½†ä¸»è¦çš„éƒ¨åˆ†åªæœ‰ä¸Šé¢æåˆ°çš„ä¸‰ç‚¹ã€‚

## æ”¹è¿›å¯¹æŠ—ç”Ÿæˆç½‘ç»œ (WGAN-GP)

WGAN ä¸ºäº†é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸é—®é¢˜å¯¹è¯†åˆ«å™¨å‚æ•°çš„å¯å–èŒƒå›´åšå‡ºäº†é™åˆ¶ï¼Œä½†è¿™ä¸ªåšæ³•æ¯”è¾ƒç²—æš´ï¼ŒWGAN-GP (Wasserstein GAN Gradient Penalty) æå‡ºäº†ä¸€ä¸ªæ›´ä¼˜é›…çš„æ–¹æ³•ï¼Œå³é™åˆ¶å¯¼å‡½æ•°å€¼çš„èŒƒå›´ï¼Œå¦‚æœå¯¼å‡½æ•°å€¼åç§»æŸä¸ªæŒ‡å®šçš„å€¼åˆ™é€šè¿‡æŸå¤±ç»™ä¸æ¨¡å‹æƒ©ç½šã€‚

å…·ä½“å®ç°å¦‚ä¸‹ï¼Œçœ‹èµ·æ¥æ¯”è¾ƒå¤æ‚ä½†åšçš„äº‹æƒ…åªæ˜¯è®¡ç®—è¯†åˆ«å™¨è¾“å…¥æ•°æ®çš„å¯¼å‡½æ•°å€¼ï¼Œç„¶ååˆ¤æ–­æ‰€æœ‰é€šé“åˆè®¡çš„å¯¼å‡½æ•°å€¼çš„ L2 åˆè®¡ä¸å¸¸é‡ 1 ç›¸å·®å¤šå°‘ï¼Œç›¸å·®è¶Šå¤§å°±è¿”å›è¶Šé«˜çš„æŸå¤±ï¼Œè¿™æ ·è¯†åˆ«å™¨æ¨¡å‹å‚æ•°è‡ªç„¶ä¼šæ§åˆ¶åœ¨æŸä¸ªæ°´å¹³ã€‚

``` python
def gradient_penalty(discrimination_model, real, generated):
    """æ§åˆ¶å¯¼å‡½æ•°å€¼çš„èŒƒå›´ï¼Œç”¨äºé˜²æ­¢æ¨¡å‹å‚æ•°å¤±æ§ (https://arxiv.org/pdf/1704.00028.pdf)"""

    # ç»™æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬åˆ†åˆ«ç”Ÿæˆä¸åŒçš„éšæœºå€¼ï¼ŒèŒƒå›´åœ¨ 0 ~ 1
    batch_size = real.shape[0]
    rate = torch.randn(batch_size, 1, 1, 1)
    rate = rate.expand(batch_size, real.shape[1], real.shape[2], real.shape[3]).to(device)

    # æŒ‰éšæœºå€¼æ¯”ä¾‹æ··åˆçœŸæ ·æœ¬å’Œå‡æ ·æœ¬
    mixed = (rate * real + (1 - rate) * generated)

    # è¯†åˆ«æ··åˆæ ·æœ¬
    predicted_m = discrimination_model(mixed)

    # è®¡ç®— mixed å¯¹ predicted_m çš„å½±å“ï¼Œä¹Ÿå°±æ˜¯ mixed => predicted_m çš„å¾®åˆ†
    # ä¸ä»¥ä¸‹ä»£ç è®¡ç®—ç»“æœç›¸åŒï¼Œä½†ä¸ä¼šå½±å“é€”ä¸­ (å³æ¨¡å‹å‚æ•°) çš„ grad å€¼
    # mixed = torch.tensor(mixed, requires_grad=True)
    # predicted_m.sum().backward()
    # grad = mixed.grad
    grad = torch.autograd.grad(
        outputs = predicted_m,
        inputs = mixed,
        grad_outputs = torch.ones(predicted_m.shape).to(device),
        create_graph=True,
        retain_graph=True)[0]

    # è®©å¯¼å‡½æ•°å€¼çš„ L2 norm (æ‰€æœ‰é€šé“åˆè®¡) åœ¨ 1 å·¦å³ï¼Œå¦‚æœåç¦» 1 åˆ™ä½¿ç”¨æŸå¤±ç»™ä¸æƒ©ç½š
    grad_penalty = ((grad.norm(2, dim=1) - 1) ** 2).mean() * 10
    return grad_penalty
```

ç„¶åå†ä¿®æ”¹è®¡ç®—è¯†åˆ«å™¨æŸå¤±çš„æ–¹æ³•ï¼š

``` python
# è®¡ç®—è¯†åˆ«å™¨çš„æŸå¤±ï¼Œä¿®æ”¹å‰
loss_d = predicted_f.mean() - predicted_t.mean()

# è®¡ç®—è¯†åˆ«å™¨çš„æŸå¤±ï¼Œä¿®æ”¹å
loss_d = (predicted_f.mean() - predicted_t.mean() +
    gradient_penalty(discrimination_model, real, generated))
```

æœ€åæŠŠè¯†åˆ«å™¨ä¸­çš„æ‰¹æ¬¡æ­£è§„åŒ– (BatchNorm) åˆ æ‰æˆ–è€…æ”¹ä¸ºå®ä¾‹æ­£è§„åŒ– (InstanceNorm) å°±å®Œäº†ã€‚InstanceNorm å’Œ BatchNorm çš„åŒºåˆ«åœ¨äºè®¡ç®—å¹³å‡å€¼å’Œæ ‡å‡†å·®çš„æ—¶å€™ä¸ä¼šæ ¹æ®æ•´ä¸ªæ‰¹æ¬¡è®¡ç®—ï¼Œè€Œæ˜¯åªæ ¹æ®å„ä¸ªæ ·æœ¬è‡ªèº«è®¡ç®—ï¼Œå…³äº BatchNorm çš„è®¡ç®—æ–¹å¼å¯ä»¥å‚è€ƒ[ç¬¬å››ç¯‡](https://303248153.github.io/ml-04/)ã€‚

å¦‚æœæœ‰å…´è¶£å¯ä»¥å‚è€ƒ WGAN-GP çš„[åŸå§‹è®ºæ–‡](https://arxiv.org/pdf/1704.00028.pdf)ã€‚

## å®Œæ•´ä»£ç 

åˆåˆ°å®Œæ•´ä»£ç çš„æ—¶é—´äº†ğŸ¤—ï¼Œè¿™ä»½ä»£ç åŒæ—¶åŒ…å«äº†åŸå§‹çš„ GAN æ¨¡å‹ (DCGAN)ï¼ŒWGAN å’Œ WGAN-GP çš„å®ç°ï¼Œåé¢è¿˜ä¼šæ¯”è¾ƒå®ƒä»¬ä¹‹é—´çš„æ•ˆæœç›¸å·®å¤šå°‘ã€‚

ä½¿ç”¨çš„æ•°æ®é›†é“¾æ¥å¦‚ä¸‹ï¼Œå‰ä¸€ç¯‡çš„äººè„¸è¯†åˆ«æ–‡ç« ä¹Ÿç”¨åˆ°äº†è¿™ä¸ªæ•°æ®é›†ï¼š

https://www.kaggle.com/atulanandjha/lfwpeople

éœ€è¦æ³¨æ„çš„æ˜¯äººè„¸å›¾ç‰‡æ•°é‡è¶Šå¤šå°±è¶Šå®¹æ˜“å‡ºç°æ¨¡å¼å´©æºƒé—®é¢˜ï¼Œè¿™ä¹Ÿæ˜¯å¯¹æŠ—ç”Ÿæˆç½‘ç»œè®­ç»ƒçš„éš¾ç‚¹ä¹‹ä¸€ğŸ¤’ï¼Œè¿™ä»½ä»£ç åªä¼šéšæœºé€‰å– 2000 å¼ å›¾ç‰‡ç”¨äºè®­ç»ƒã€‚

è¿™ä»½ä»£ç è¿˜ä¼šæ ¹æ®æ­£ç¡®ç‡åŠ¨æ€è°ƒæ•´ç”Ÿæˆå™¨å’Œè¯†åˆ«å™¨çš„è®­ç»ƒæ¯”ä¾‹ï¼Œå¦‚æœè¯†åˆ«å™¨æ¯”ç”Ÿæˆå™¨æ›´å¼ºåˆ™è®­ç»ƒ 1 æ¬¡ç”Ÿæˆå™¨ï¼Œå¦‚æœç”Ÿæˆå™¨æ¯”è¯†åˆ«å™¨æ›´å¼ºåˆ™è®­ç»ƒ 5 æ¬¡è¯†åˆ«å™¨ï¼Œè¿™ä¹ˆåšå¯ä»¥çœå»æ‰‹åŠ¨è°ƒæ•´è®­ç»ƒæ¯”ä¾‹çš„éº»çƒ¦ï¼Œç»å®éªŒæ•ˆæœä¹Ÿä¸é”™ğŸ¥³ã€‚

``` python
import os
import sys
import torch
import gzip
import itertools
import random
import numpy
import math
import json
from PIL import Image
from torch import nn
from matplotlib import pyplot
from functools import lru_cache

# ç”Ÿæˆæˆ–è¯†åˆ«å›¾ç‰‡çš„å¤§å°
IMAGE_SIZE = (80, 80)
# è®­ç»ƒä½¿ç”¨çš„æ•°æ®é›†è·¯å¾„
DATASET_DIR = "./dataset/lfwpeople/lfw_funneled"
# æ¨¡å‹ç±»åˆ«, æ”¯æŒ DCGAN, WGAN, WGAN-GP
MODEL_TYPE = "WGAN-GP"

# ç”¨äºå¯ç”¨ GPU æ”¯æŒ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class GenerationModel(nn.Module):
    """ç”Ÿæˆè™šå‡æ•°æ®çš„æ¨¡å‹"""
    # ç¼–ç é•¿åº¦
    EmbeddedSize = 128

    def __init__(self):
        super().__init__()
        self.generator = nn.Sequential(
            # 128,1,1 => 512,5,5
            nn.ConvTranspose2d(128, 512, kernel_size=5, stride=1, padding=0, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            # => 256,10,10
            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            # => 128,20,20
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            # => 64,40,40
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            # => 3,80,80
            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1, bias=False),
            # é™åˆ¶è¾“å‡ºåœ¨ -1 ~ 1ï¼Œä¸ä½¿ç”¨ Hardtanh æ˜¯ä¸ºäº†è®©è¶…è¿‡èŒƒå›´çš„å€¼å¯ä»¥ä¼ æ’­ç»™ä¸Šå±‚
            nn.Tanh())

    def forward(self, x):
        y = self.generator(x.view(x.shape[0], x.shape[1], 1, 1))
        return y

    @staticmethod
    def calc_accuracy(predicted_f):
        """æ­£ç¡®ç‡è®¡ç®—å™¨"""
        # è¿”å›éª—è¿‡è¯†åˆ«å™¨çš„è™šå‡æ•°æ®æ¯”ä¾‹
        if MODEL_TYPE == "DCGAN":
            threshold = 0.5
        elif MODEL_TYPE in ("WGAN", "WGAN-GP"):
            threshold = DiscriminationModel.LastTrueSamplePredictedMean
        else:
            raise ValueError("unknown model type")
        return (predicted_f >= threshold).float().mean().item()

class DiscriminationModel(nn.Module):
    """è¯†åˆ«æ•°æ®æ˜¯å¦çœŸå®çš„æ¨¡å‹"""
    # æœ€ç»ˆè¯†åˆ«çœŸå®æ ·æœ¬çš„è¾“å‡ºå¹³å‡å€¼ï¼ŒWGAN ä¼šä½¿ç”¨è¿™ä¸ªå€¼åˆ¤æ–­éª—è¿‡è¯†åˆ«å™¨çš„è™šå‡æ•°æ®æ¯”ä¾‹
    LastTrueSamplePredictedMean = 0.5

    def __init__(self):
        super().__init__()
        # æ ‡å‡†åŒ–å‡½æ•°
        def norm2d(features):
            if MODEL_TYPE == "WGAN-GP":
                # WGAN-GP æœ¬æ¥ä¸éœ€è¦ BatchNormï¼Œä½†å¯ä»¥é¢å¤–çš„åŠ  InstanceNorm æ”¹å–„æ•ˆæœ
                # InstanceNorm ä¸ä¸€æ ·çš„æ˜¯å¹³å‡å€¼å’Œæ ‡å‡†å·®ä¼šé’ˆå¯¹æ‰¹æ¬¡ä¸­çš„å„ä¸ªæ ·æœ¬åˆ†åˆ«è®¡ç®—
                # affine = True è¡¨ç¤ºè°ƒæ•´é‡å¯å­¦ä¹  (BatchNorm2d é»˜è®¤ä¸º True)
                return nn.InstanceNorm2d(features, affine=True)
            return nn.BatchNorm2d(features)
        self.discriminator = nn.Sequential(
            # 3,80,80 => 64,40,40
            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # => 128,20,20
            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),
            norm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            # => 256,10,10
            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),
            norm2d(256),
            nn.LeakyReLU(0.2, inplace=True),
            # => 512,5,5
            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),
            norm2d(512),
            nn.LeakyReLU(0.2, inplace=True),
            # => 1,1,1
            nn.Conv2d(512, 1, kernel_size=5, stride=1, padding=0, bias=False),
            # æ‰å¹³åŒ–
            nn.Flatten())
        if MODEL_TYPE == "DCGAN":
            # è¾“å‡ºæ˜¯å¦çœŸå®æ•°æ® (0 or 1)
            # WGAN ä¸é™åˆ¶è¾“å‡ºå€¼èŒƒå›´åœ¨ 0 ~ 1 ä¹‹é—´
            self.discriminator.add_module("sigmoid", nn.Sigmoid())

    def forward(self, x):
        y = self.discriminator(x)
        return y

    @staticmethod
    def calc_accuracy(predicted_f, predicted_t):
        """æ­£ç¡®ç‡è®¡ç®—å™¨"""
        # è¿”å›æ­£ç¡®è¯†åˆ«çš„æ•°æ®æ¯”ä¾‹
        if MODEL_TYPE == "DCGAN":
            return (((predicted_f <= 0.5).float().mean() + (predicted_t > 0.5).float().mean()) / 2).item()
        elif MODEL_TYPE in ("WGAN", "WGAN-GP"):
            DiscriminationModel.LastTrueSamplePredictedMean = predicted_t.mean()
            return (predicted_t > predicted_f).float().mean().item()
        else:
            raise ValueError("unknown model type")

    def gradient_penalty(self, real, generated):
        """æ§åˆ¶å¯¼å‡½æ•°å€¼çš„èŒƒå›´ï¼Œç”¨äºé˜²æ­¢æ¨¡å‹å‚æ•°å¤±æ§ (https://arxiv.org/pdf/1704.00028.pdf)"""
        # ç»™æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ ·æœ¬åˆ†åˆ«ç”Ÿæˆä¸åŒçš„éšæœºå€¼ï¼ŒèŒƒå›´åœ¨ 0 ~ 1
        batch_size = real.shape[0]
        rate = torch.randn(batch_size, 1, 1, 1)
        rate = rate.expand(batch_size, real.shape[1], real.shape[2], real.shape[3]).to(device)
        # æŒ‰éšæœºå€¼æ¯”ä¾‹æ··åˆçœŸæ ·æœ¬å’Œå‡æ ·æœ¬
        mixed = (rate * real + (1 - rate) * generated)
        # è¯†åˆ«æ··åˆæ ·æœ¬
        predicted_m = self.forward(mixed)
        # è®¡ç®— mixed å¯¹ predicted_m çš„å½±å“ï¼Œä¹Ÿå°±æ˜¯ mixed => predicted_m çš„å¾®åˆ†
        # ä¸ä»¥ä¸‹ä»£ç è®¡ç®—ç»“æœç›¸åŒï¼Œä½†ä¸ä¼šå½±å“é€”ä¸­ (å³æ¨¡å‹å‚æ•°) çš„ grad å€¼
        # mixed = torch.tensor(mixed, requires_grad=True)
        # predicted_m.sum().backward()
        # grad = mixed.grad
        grad = torch.autograd.grad(
            outputs = predicted_m,
            inputs = mixed,
            grad_outputs = torch.ones(predicted_m.shape).to(device),
            create_graph=True,
            retain_graph=True)[0]
        # è®©å¯¼å‡½æ•°å€¼çš„ L2 norm (æ‰€æœ‰é€šé“åˆè®¡) åœ¨ 1 å·¦å³ï¼Œå¦‚æœåç¦» 1 åˆ™ä½¿ç”¨æŸå¤±ç»™ä¸æƒ©ç½š
        grad_penalty = ((grad.norm(2, dim=1) - 1) ** 2).mean() * 10
        return grad_penalty

def save_tensor(tensor, path):
    """ä¿å­˜ tensor å¯¹è±¡åˆ°æ–‡ä»¶"""
    torch.save(tensor, gzip.GzipFile(path, "wb"))

# ä¸ºäº†å‡å°‘è¯»å–æ—¶é—´è¿™é‡Œç¼“å­˜äº†è¯»å–çš„ tensor å¯¹è±¡
# å¦‚æœå†…å­˜ä¸å¤Ÿåº”è¯¥é€‚å½“å‡å°‘ maxsize
@lru_cache(maxsize=200)
def load_tensor(path):
    """ä»æ–‡ä»¶è¯»å– tensor å¯¹è±¡"""
    return torch.load(gzip.GzipFile(path, "rb"))

def image_to_tensor(img):
    """ç¼©æ”¾å¹¶è½¬æ¢å›¾ç‰‡å¯¹è±¡åˆ° tensor å¯¹è±¡"""
    img = img.resize(IMAGE_SIZE) # ç¼©æ”¾å›¾ç‰‡ï¼Œæ¯”ä¾‹ä¸ä¸€è‡´æ—¶æ‹‰ä¼¸
    arr = numpy.asarray(img)
    t = torch.from_numpy(arr)
    t = t.transpose(0, 2) # è½¬æ¢ç»´åº¦ H,W,C åˆ° C,W,H
    t = (t / 255.0) * 2 - 1 # æ­£è§„åŒ–æ•°å€¼ä½¿å¾—èŒƒå›´åœ¨ -1 ~ 1
    return t

def tensor_to_image(t):
    """è½¬æ¢ tensor å¯¹è±¡åˆ°å›¾ç‰‡"""
    t = (t + 1) / 2 * 255.0 # è½¬æ¢é¢œè‰²å› 0 ~ 255
    t = t.transpose(0, 2) # è½¬æ¢ç»´åº¦ C,W,H åˆ° H,W,C
    t = t.int() # è½¬æ¢æ•°å€¼åˆ°æ•´æ•°
    img = Image.fromarray(t.numpy().astype("uint8"), "RGB")
    return img

def prepare():
    """å‡†å¤‡è®­ç»ƒ"""
    # æ•°æ®é›†è½¬æ¢åˆ° tensor ä»¥åä¼šä¿å­˜åœ¨ data æ–‡ä»¶å¤¹ä¸‹
    if not os.path.isdir("data"):
        os.makedirs("data")

    # æŸ¥æ‰¾äººè„¸å›¾ç‰‡åˆ—è¡¨
    # æ¯ä¸ªäººæœ€å¤šä½¿ç”¨ 2 å¼ å›¾ç‰‡
    image_paths = []
    for dirname in os.listdir(DATASET_DIR):
        dirpath = os.path.join(DATASET_DIR, dirname)
        if not os.path.isdir(dirpath):
            continue
        for filename in os.listdir(dirpath)[:2]:
            image_paths.append(os.path.join(DATASET_DIR, dirname, filename))
    print(f"found {len(image_paths)} images")

    # éšæœºæ‰“ä¹±äººè„¸å›¾ç‰‡åˆ—è¡¨
    random.shuffle(image_paths)

    # é™åˆ¶äººè„¸æ•°é‡
    # å¦‚æœæ•°é‡å¤ªå¤šï¼Œè¯†åˆ«å™¨éš¾ä»¥è®°ä½äººè„¸çš„å…·ä½“ç‰¹å¾ï¼Œä¼šéœ€è¦æ›´é•¿æ—¶é—´è®­ç»ƒæˆ–ç›´æ¥é™·å…¥æ¨¡å¼å´©æºƒé—®é¢˜
    image_paths = image_paths[:2000]
    print(f"only use {len(image_paths)} images")

    # ä¿å­˜äººè„¸å›¾ç‰‡æ•°æ®
    for batch, index in enumerate(range(0, len(image_paths), 200)):
        paths = image_paths[index:index+200]
        images = []
        for path in paths:
            img = Image.open(path)
            # æ‰©å¤§äººè„¸å æ¯”
            w, h = img.size
            img = img.crop((int(w*0.25), int(h*0.25), int(w*0.75), int(h*0.75)))
            images.append(img)
        tensors = [ image_to_tensor(img) for img in images ]
        tensor = torch.stack(tensors) # ç»´åº¦: (å›¾ç‰‡æ•°é‡, 3, å®½åº¦, é«˜åº¦)
        save_tensor(tensor, os.path.join("data", f"{batch}.pt"))
        print(f"saved batch {batch}")

    print("done")

def train():
    """å¼€å§‹è®­ç»ƒæ¨¡å‹"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    generation_model = GenerationModel().to(device)
    discrimination_model = DiscriminationModel().to(device)

    # åˆ›å»ºæŸå¤±è®¡ç®—å™¨
    ones_map = {}
    zeros_map = {}
    def loss_function_t(predicted):
        """æŸå¤±è®¡ç®—å™¨ (è®­ç»ƒè¯†åˆ«ç»“æœä¸º 1)"""
        count = predicted.shape[0]
        ones = ones_map.get(count)
        if ones is None:
            ones = torch.ones((count, 1), device=device)
            ones_map[count] = ones
        return nn.functional.binary_cross_entropy(predicted, ones)
    def loss_function_f(predicted):
        """æŸå¤±è®¡ç®—å™¨ (è®­ç»ƒè¯†åˆ«ç»“æœä¸º 0)"""
        count = predicted.shape[0]
        zeros = zeros_map.get(count)
        if zeros is None:
            zeros = torch.zeros((count, 1), device=device)
            zeros_map[count] = zeros
        return nn.functional.binary_cross_entropy(predicted, zeros)

    # åˆ›å»ºå‚æ•°è°ƒæ•´å™¨
    if MODEL_TYPE == "DCGAN":
        optimizer_g = torch.optim.Adam(generation_model.parameters(), lr=0.0002, betas=(0.5, 0.999))
        optimizer_d = torch.optim.Adam(discrimination_model.parameters(), lr=0.0002, betas=(0.5, 0.999))
    elif MODEL_TYPE == "WGAN":
        optimizer_g = torch.optim.RMSprop(generation_model.parameters(), lr=0.00005)
        optimizer_d = torch.optim.RMSprop(discrimination_model.parameters(), lr=0.00005)
    elif MODEL_TYPE == "WGAN-GP":
        optimizer_g = torch.optim.Adam(generation_model.parameters(), lr=0.0001, betas=(0.0, 0.999))
        optimizer_d = torch.optim.Adam(discrimination_model.parameters(), lr=0.0001, betas=(0.0, 0.999))
    else:
        raise ValueError("unknown model type")

    # è®°å½•è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    training_accuracy_g_history = []
    training_accuracy_d_history = []

    # è®¡ç®—æ­£ç¡®ç‡çš„å·¥å…·å‡½æ•°
    calc_accuracy_g = generation_model.calc_accuracy
    calc_accuracy_d = discrimination_model.calc_accuracy

    # éšæœºç”Ÿæˆç¼–ç 
    def generate_vectors(batch_size):
        vectors = torch.randn((batch_size, GenerationModel.EmbeddedSize), device=device)
        return vectors

    # è¾“å‡ºç”Ÿæˆçš„å›¾ç‰‡æ ·æœ¬
    def output_generated_samples(epoch, samples):
        dir_path = f"./generated_samples/{epoch}"
        if not os.path.isdir(dir_path):
            os.makedirs(dir_path)
        for index, sample in enumerate(samples):
            path = os.path.join(dir_path, f"{index}.png")
            tensor_to_image(sample.cpu()).save(path)

    # è¯»å–æ‰¹æ¬¡çš„å·¥å…·å‡½æ•°
    def read_batches():
        for batch in itertools.count():
            path = f"data/{batch}.pt"
            if not os.path.isfile(path):
                break
            x = load_tensor(path)
            yield x.to(device)

    # å¼€å§‹è®­ç»ƒè¿‡ç¨‹
    validating_vectors = generate_vectors(100)
    for epoch in range(0, 10000):
        print(f"epoch: {epoch}")

        # æ ¹æ®è®­ç»ƒé›†è®­ç»ƒå¹¶ä¿®æ”¹å‚æ•°
        # åˆ‡æ¢æ¨¡å‹åˆ°è®­ç»ƒæ¨¡å¼
        generation_model.train()
        discrimination_model.train()
        training_accuracy_g_list = []
        training_accuracy_d_list = []
        last_accuracy_g = 0
        last_accuracy_d = 0
        minibatch_size = 20
        train_discriminator_count = 0
        for index, batch_x in enumerate(read_batches()):
            # ä½¿ç”¨å°æ‰¹æ¬¡è®­ç»ƒ
            training_batch_accuracy_g = 0.0
            training_batch_accuracy_d = 0.0
            minibatch_count = 0
            for begin in range(0, batch_x.shape[0], minibatch_size):
                # æµ‹è¯•ç›®å‰ç”Ÿæˆå™¨å’Œè¯†åˆ«å™¨å“ªè¾¹å åŠ£åŠ¿ï¼Œè®­ç»ƒå åŠ£åŠ¿çš„ä¸€æ–¹
                # æœ€ç»ˆçš„å¹³è¡¡çŠ¶æ€æ˜¯: ç”Ÿæˆå™¨æ­£ç¡®ç‡ = 1.0, è¯†åˆ«å™¨æ­£ç¡®ç‡ = 0.5
                # ä»£è¡¨ç”Ÿæˆå™¨ç”Ÿæˆçš„å›¾ç‰‡å’ŒçœŸå®å›¾ç‰‡åŸºæœ¬å®Œå…¨ä¸€æ ·ï¼Œä½†ä¸åº”è¯¥è®­ç»ƒåˆ°è¿™ä¸ªç¨‹åº¦
                training_vectors = generate_vectors(minibatch_size) # éšæœºå‘é‡
                generated = generation_model(training_vectors) # æ ¹æ®éšæœºå‘é‡ç”Ÿæˆçš„è™šå‡æ•°æ®
                real = batch_x[begin:begin+minibatch_size] # çœŸå®æ•°æ®
                predicted_t = discrimination_model(real)
                predicted_f = discrimination_model(generated)
                accuracy_g = calc_accuracy_g(predicted_f)
                accuracy_d = calc_accuracy_d(predicted_f, predicted_t)
                train_discriminator = (accuracy_g / 2) >= accuracy_d
                if train_discriminator or train_discriminator_count > 0:
                    # è®­ç»ƒè¯†åˆ«å™¨
                    if MODEL_TYPE == "DCGAN":
                        loss_d = loss_function_f(predicted_f) + loss_function_t(predicted_t)
                    elif MODEL_TYPE == "WGAN":
                        loss_d = predicted_f.mean() - predicted_t.mean()
                    elif MODEL_TYPE == "WGAN-GP":
                        loss_d = (predicted_f.mean() - predicted_t.mean() +
                            discrimination_model.gradient_penalty(real, generated))
                    else:
                        raise ValueError("unknown model type")
                    loss_d.backward()
                    optimizer_d.step()
                    # é™åˆ¶è¯†åˆ«å™¨å‚æ•°èŒƒå›´ä»¥é˜²æ­¢æ¨¡å‹å‚æ•°å¤±æ§ (WGAN-GP æœ‰æ›´å¥½çš„æ–¹æ³•)
                    # è¿™é‡Œçš„é™åˆ¶å€¼æ¯”è®ºæ–‡çš„å€¼ (0.01) æ›´å¤§æ˜¯å› ä¸ºæ¨¡å‹å±‚æ•°å’Œå‚æ•°é‡æ›´å¤š
                    if MODEL_TYPE == "WGAN":
                        for p in discrimination_model.parameters():
                            p.data.clamp_(-0.1, 0.1)
                    # è®©è¯†åˆ«å™¨è®­ç»ƒæ¬¡æ•°å¤šäºç”Ÿæˆå™¨
                    if train_discriminator and train_discriminator_count == 0:
                        train_discriminator_count = 5
                    train_discriminator_count -= 1
                else:
                    # è®­ç»ƒç”Ÿæˆå™¨
                    if MODEL_TYPE == "DCGAN":
                        loss_g = loss_function_t(predicted_f)
                    elif MODEL_TYPE in ("WGAN", "WGAN-GP"):
                        loss_g = -predicted_f.mean()
                    else:
                        raise ValueError("unknown model type")
                    loss_g.backward()
                    optimizer_g.step()
                optimizer_g.zero_grad()
                optimizer_d.zero_grad()
                training_batch_accuracy_g += accuracy_g
                training_batch_accuracy_d += accuracy_d
                minibatch_count += 1
            training_batch_accuracy_g /= minibatch_count
            training_batch_accuracy_d /= minibatch_count
            # è¾“å‡ºæ‰¹æ¬¡æ­£ç¡®ç‡
            training_accuracy_g_list.append(training_batch_accuracy_g)
            training_accuracy_d_list.append(training_batch_accuracy_d)
            print(f"epoch: {epoch}, batch: {index},",
                f"accuracy_g: {training_batch_accuracy_g}, accuracy_d: {training_batch_accuracy_d}")
        training_accuracy_g = sum(training_accuracy_g_list) / len(training_accuracy_g_list)
        training_accuracy_d = sum(training_accuracy_d_list) / len(training_accuracy_d_list)
        training_accuracy_g_history.append(training_accuracy_g)
        training_accuracy_d_history.append(training_accuracy_d)
        print(f"training accuracy_g: {training_accuracy_g}, accuracy_d: {training_accuracy_d}")

        # ä¿å­˜è™šå‡æ•°æ®ç”¨äºè¯„ä»·è®­ç»ƒæ•ˆæœ
        output_generated_samples(epoch, generation_model(validating_vectors))

        # ä¿å­˜æ¨¡å‹çŠ¶æ€
        if (epoch + 1) % 10 == 0:
            save_tensor(generation_model.state_dict(), "model.generation.pt")
            save_tensor(discrimination_model.state_dict(), "model.discrimination.pt")
            if (epoch + 1) % 100 == 0:
                save_tensor(generation_model.state_dict(), f"model.generation.epoch_{epoch}.pt")
                save_tensor(discrimination_model.state_dict(), f"model.discrimination.epoch_{epoch}.pt")
            print("model saved")

    print("training finished")

    # æ˜¾ç¤ºè®­ç»ƒé›†çš„æ­£ç¡®ç‡å˜åŒ–
    pyplot.plot(training_accuracy_g_history, label="training_accuracy_g")
    pyplot.plot(training_accuracy_d_history, label="training_accuracy_d")
    pyplot.ylim(0, 1)
    pyplot.legend()
    pyplot.show()

from http.server import HTTPServer, BaseHTTPRequestHandler
from urllib.parse import parse_qs
from io import BytesIO
class RequestHandler(BaseHTTPRequestHandler):
    """ç”¨äºæµ‹è¯•ç”Ÿæˆå›¾ç‰‡çš„ç®€å•æœåŠ¡å™¨"""
    # æ¨¡å‹çŠ¶æ€çš„è·¯å¾„ï¼Œè¿™é‡Œä½¿ç”¨çœ‹èµ·æ¥æ•ˆæœæœ€å¥½çš„è®°å½•
    MODEL_STATE_PATH = "model.generation.epoch_2999.pt"
    Model = None

    @staticmethod
    def get_model():
        if RequestHandler.Model is None:
            # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ŒåŠ è½½è®­ç»ƒå¥½çš„çŠ¶æ€ï¼Œç„¶ååˆ‡æ¢åˆ°éªŒè¯æ¨¡å¼
            model = GenerationModel().to(device)
            model.load_state_dict(load_tensor(RequestHandler.MODEL_STATE_PATH))
            model.eval()
            RequestHandler.Model = model
        return RequestHandler.Model

    def do_GET(self):
        parts = self.path.partition("?")
        if parts[0] == "/":
            self.send_response(200)
            self.send_header("Content-type", "text/html")
            self.end_headers()
            with open("gan_eval.html", "rb") as f:
                self.wfile.write(f.read())
        elif parts[0] == "/generate":
            # æ ¹æ®ä¼ å…¥çš„å‚æ•°ç”Ÿæˆå›¾ç‰‡
            params = parse_qs(parts[-1])
            vector = (torch.tensor([float(x) for x in params["values"][0].split(",")])
                .reshape(1, GenerationModel.EmbeddedSize)
                .to(device))
            generated = RequestHandler.get_model()(vector)[0]
            img = tensor_to_image(generated.cpu())
            bytes_io = BytesIO()
            img.save(bytes_io, format="PNG")
            # è¿”å›å›¾ç‰‡
            self.send_response(200)
            self.send_header("Content-type", "image/png")
            self.end_headers()
            self.wfile.write(bytes_io.getvalue())
        else:
            self.send_response(404)
            self.end_headers()
            self.wfile.write(b"Not Found")

def eval_model():
    """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆå›¾ç‰‡"""
    server = HTTPServer(("localhost", 8666), RequestHandler)
    print("Please access http://localhost:8666")
    try:
        server.serve_forever()
    except KeyboardInterrupt:
        pass
    server.server_close()
    exit()

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print(f"Please run: {sys.argv[0]} prepare|train|eval")
        exit()

    # ç»™éšæœºæ•°ç”Ÿæˆå™¨åˆ†é…ä¸€ä¸ªåˆå§‹å€¼ï¼Œä½¿å¾—æ¯æ¬¡è¿è¡Œéƒ½å¯ä»¥ç”Ÿæˆç›¸åŒçš„éšæœºæ•°
    # è¿™æ˜¯ä¸ºäº†è®©è¿‡ç¨‹å¯é‡ç°ï¼Œä½ ä¹Ÿå¯ä»¥é€‰æ‹©ä¸è¿™æ ·åš
    random.seed(0)
    torch.random.manual_seed(0)

    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ“ä½œ
    operation = sys.argv[1]
    if operation == "prepare":
        prepare()
    elif operation == "train":
        train()
    elif operation == "eval":
        eval_model()
    else:
        raise ValueError(f"Unsupported operation: {operation}")

if __name__ == "__main__":
    main()
```

ä¿å­˜ä»£ç åˆ° `gan.py`ï¼Œç„¶åæ‰§è¡Œä»¥ä¸‹å‘½ä»¤å³å¯å¼€å§‹è®­ç»ƒï¼š

``` text
python3 gan.py prepare
python3 gan.py train
```

åŒæ ·è®­ç»ƒ 2000 è½®ä»¥åï¼ŒDCGAN, WGAN, WGAN-GP è¾“å‡ºçš„æ ·æœ¬å¦‚ä¸‹ï¼š

DCGAN

![samples_dcgan](./samples_dcgan.png)

WGAN

![samples_wgan](./samples_wgan.png)

WGAN-GP

![samples_wgan](./samples_wgan_gp.png)

å¯ä»¥çœ‹åˆ° WGAN-GP å—æ¨¡å¼å´©æºƒé—®é¢˜å½±å“æœ€å°‘ï¼Œå¹¶ä¸”æ•ˆæœä¹Ÿæ›´å¥½ğŸ˜¤ã€‚

WGAN-GP è®­ç»ƒåˆ° 3000 æ¬¡ä»¥åè¾“å‡ºçš„æ ·æœ¬å¦‚ä¸‹ï¼š

![samples_wgan_gp_3000](./samples_wgan_gp_3000.png)

WGAN-GP è®­ç»ƒåˆ° 10000 æ¬¡ä»¥åè¾“å‡ºçš„æ ·æœ¬å¦‚ä¸‹ï¼š

![samples_wgan_gp_10000.png](./samples_wgan_gp_10000.png)

éšç€è®­ç»ƒæ¬¡æ•°å¢å¤šï¼ŒWGAN-GP ä¸€æ ·æ— æ³•é¿å…æ¨¡å¼å´©æºƒé—®é¢˜ï¼Œè¿™å°±æ˜¯ä¸ºä»€ä¹ˆä»¥ä¸Šä»£ç ä¼šè®°å½•æ¯ä¸€è½®è®­ç»ƒåè¾“å‡ºçš„æ ·æœ¬ï¼Œå¹¶åœ¨æ¯ 100 è½®è®­ç»ƒä»¥åä¿å­˜å•ç‹¬çš„æ¨¡å‹çŠ¶æ€ï¼Œè¿™æ ·è®­ç»ƒç»“æŸä»¥åæˆ‘ä»¬å¯ä»¥é€šè¿‡è¯„ä»·è¾“å‡ºçš„æ ·æœ¬æ‰¾åˆ°æ•ˆæœæœ€å¥½çš„æ‰¹æ¬¡ï¼Œç„¶åä½¿ç”¨è¯¥æ‰¹æ¬¡çš„æ¨¡å‹çŠ¶æ€ã€‚

ä¸Šè¿°çš„ä¾‹å­æ•ˆæœæœ€å¥½çš„çŠ¶æ€æ˜¯è®­ç»ƒ 3000 æ¬¡ä»¥åçš„çŠ¶æ€ã€‚

ä½ å¯èƒ½å‘ç°è¾“å‡ºçš„æ ·æœ¬ä¸­å¤¹æ‚äº†ä¸€äº›ç•¸å½¢ğŸ¥´ï¼Œè¿™æ˜¯å› ä¸ºç”Ÿæˆå™¨æ²¡æœ‰è¦†ç›–åˆ°è¾“å…¥çš„å‘é‡ç©ºé—´ï¼Œæœ€ä¸»è¦çš„åŸå› æ˜¯éšæœºè¾“å…¥ä¸­åŒ…å«äº†å¾ˆå¤šæ¥è¿‘ 0 çš„å€¼ï¼Œé¿å…è¿™ä¸ªé—®é¢˜ç®€å•çš„åšæ³•æ˜¯ç”Ÿæˆéšæœºè¾“å…¥æ—¶é™åˆ¶å€¼å¿…é¡»å°äºæˆ–å¤§äºæŸä¸ªå€¼ã€‚åŸåˆ™ä¸Šç»™åå·ç§¯å±‚è®¾ç½® Bias ä¹Ÿå¯ä»¥é¿å…è¿™ä¸ªé—®é¢˜ï¼Œä½†ä¼šæ›´å®¹æ˜“é™·å…¥æ¨¡å¼å´©æºƒé—®é¢˜ã€‚

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ç”Ÿæˆäººè„¸å°±æ¯”è¾ƒç®€å•äº†ï¼š

``` python
generation_model = GenerationModel().to(device)
model.load_state_dict(load_tensor("model.generation.epoch_2999.pt"))
model.eval()

# éšæœºç”Ÿæˆ 100 å¼ äººè„¸
vector = torch.randn((100, GenerationModel.EmbeddedSize), device=device)
samples = model(vector)
for index, sample in enumerate(samples):
    img = tensor_to_image(sample.cpu())
    img.save(f"{index}.png")
```

é¢å¤–çš„ï¼Œæˆ‘åšäº†ä¸€ä¸ªå¯ä»¥åŠ¨æ€è°ƒæ•´å‚æ•°æè„¸çš„ç½‘é¡µï¼Œhtml ä»£ç å¦‚ä¸‹ï¼š

``` html
<!DOCTYPE html>
<html lang="cn">
  <head>
    <meta charset="utf-8">
    <title>æµ‹è¯•äººè„¸ç”Ÿæˆ</title>
    <style>
        html, body {
            width: 100%;
            height: 100%;
            margin: 0px;
        }
        .left-pane {
            width: 50%;
            height: 100%;
            border-right: 1px solid #000;
        }
        .right-pane {
            position: fixed;
            left: 70%;
            top: 35%;
            width: 25%;
        }
        .sliders {
            padding: 8px;
        }
        .slider-container {
            display: inline-block;
            min-width: 25%;
        }
        #image {
            left: 25%;
            top: 25%;
            width: 50%;
            height: 50%;
        }
    </style>
  </head>
  <body>
    <div class="left-pane">
        <div class="sliders">
        </div>
    </div>
    <div class="right-pane">
       <p><img id="target" src="data:image/png;base64," alt="image" /></p>
       <p><button class="set-random">éšæœºç”Ÿæˆ</button></p>
    </div>
  </body>
  <script>
    (function() {
        // æ»‘åŠ¨æ¡æ”¹å˜åçš„å¤„ç†
        var onChanged = function() {
            var sliderInputs = document.querySelectorAll(".slider");
            var values = [];
            sliderInputs.forEach(function(s) {
                values.push(s.value);
            });
            var image = document.querySelector("#target");
            image.setAttribute("src", "/generate?values=" + values.join(","));
        };

        // ç‚¹å‡»éšæœºç”Ÿæˆæ—¶çš„å¤„ç†
        var setRandomButton = document.querySelector(".set-random");
        setRandomButton.onclick = function() {
            var sliderInputs = document.querySelectorAll(".slider");
            sliderInputs.forEach(function(s) { s.value = Math.random() * 2 - 1; });
            onChanged();
        };

        // æ·»åŠ æ»‘åŠ¨æ¡
        var sliders = document.querySelector(".sliders");
        for (var n = 0; n < 128; ++n) {
            var container = document.createElement("div");
            container.setAttribute("class", "slider-container");
            var span = document.createElement("span");
            span.innerText = n;
            container.appendChild(span);
            var slider = document.createElement("input");
            slider.setAttribute("type", "range")
            slider.setAttribute("class", "slider");
            slider.setAttribute("min", "-1");
            slider.setAttribute("max", "1");
            slider.setAttribute("step", "0.01");
            slider.value = 0;
            slider.onchange = onChanged;
            slider.oninput = onChanged;
            container.appendChild(slider);
            sliders.appendChild(container);
        }
    })();
  </script>
</html>
```

ä¿å­˜åˆ° `gan_eval.html` ä»¥åæ‰§è¡Œä»¥ä¸‹å‘½ä»¤å³å¯å¯åŠ¨æœåŠ¡å™¨ï¼š

``` text
python3 gan.py eval
```

æµè§ˆå™¨æ‰“å¼€ `http://localhost:8666` ä»¥åä¼šæ˜¾ç¤ºä»¥ä¸‹ç•Œé¢ï¼Œç‚¹å‡»éšæœºç”ŸæˆæŒ‰é’®å¯ä»¥éšæœºç”Ÿæˆäººè„¸ï¼Œæ‹‰åŠ¨å·¦è¾¹çš„å‚æ•°æ¡å¯ä»¥åŠ¨æ€è°ƒæ•´å‚æ•°ï¼š

![eval_html](./eval_html.png)

ä¸€äº›æè„¸çš„ç½‘ç«™ä¼šåˆ†æå„ä¸ªå‚æ•°çš„å«ä¹‰ï¼Œçœ‹çœ‹å“ªäº›å‚æ•°ä»£è¡¨è‚¤è‰²ï¼Œé‚£äº›å‚æ•°ä»£è¡¨è¡¨æƒ…ï¼Œå“ªäº›å‚æ•°ä»£è¡¨è„±å‘ç¨‹åº¦ï¼Œæˆ‘æ¯”è¾ƒæ‡’å°±åªç»™å‡ºå„ä¸ªå‚æ•°çš„åºå·äº†ğŸ¤’ã€‚

## å†™åœ¨æœ€å

åˆæ‘¸å®Œä¸€ä¸ªæ–°çš„æ¨¡å‹äº†ï¼Œè·Ÿåˆ°è¿™ç¯‡çš„äººä¹Ÿè¶Šæ¥è¶Šå°‘äº†ï¼Œä¼°è®¡è¿™ä¸ªç³»åˆ—å†å†™ä¸€ä¸¤ç¯‡å°±ä¼šç»“æŸ (VAE, å¼ºåŒ–å­¦ä¹ )ã€‚
