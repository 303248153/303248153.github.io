# å†™ç»™ç¨‹åºå‘˜çš„æœºå™¨å­¦ä¹ å…¥é—¨ (å…«) - å·ç§¯ç¥ç»ç½‘ç»œ (CNN) - å›¾ç‰‡åˆ†ç±»å’ŒéªŒè¯ç è¯†åˆ«

è¿™ä¸€ç¯‡å°†ä¼šä»‹ç»å·ç§¯ç¥ç»ç½‘ç»œ (CNN)ï¼ŒCNN æ¨¡å‹éå¸¸é€‚åˆç”¨æ¥è¿›è¡Œå›¾ç‰‡ç›¸å…³çš„å­¦ä¹ ï¼Œä¾‹å¦‚å›¾ç‰‡åˆ†ç±»å’ŒéªŒè¯ç è¯†åˆ«ï¼Œä¹Ÿå¯ä»¥é…åˆå…¶ä»–æ¨¡å‹å®ç° OCRã€‚

## ä½¿ç”¨ Python å¤„ç†å›¾ç‰‡

åœ¨å…·ä½“ä»‹ç» CNN ä¹‹å‰ï¼Œæˆ‘ä»¬å…ˆæ¥çœ‹çœ‹æ€æ ·ä½¿ç”¨ Python å¤„ç†å›¾ç‰‡ã€‚Python å¤„ç†å›¾ç‰‡æœ€ä¸»è¦ä½¿ç”¨çš„ç±»åº“æ˜¯ Pillow (Python2 PIL çš„ fork)ï¼Œä½¿ç”¨ä»¥ä¸‹å‘½ä»¤å³å¯å®‰è£…ï¼š

``` text
pip3 install Pillow
```

ä¸€äº›ç®€å•æ“ä½œçš„ä¾‹å­å¦‚ä¸‹ï¼Œå¦‚æœä½ æƒ³äº†è§£æ›´å¤šå¯ä»¥å‚è€ƒ Pillow çš„[æ–‡æ¡£](https://pillow.readthedocs.io/en/stable/)ï¼š

``` python
# æ‰“å¼€å›¾ç‰‡
>>> from PIL import Image
>>> img = Image.open("1.png")

# æŸ¥çœ‹å›¾ç‰‡ä¿¡æ¯
>>> img.size
(175, 230)
>>> img.mode
'RGB'
>>> img
<PIL.PngImagePlugin.PngImageFile image mode=RGB size=175x230 at 0x10B807B50>

# ç¼©æ”¾å›¾ç‰‡
>>> img1 = img.resize((20, 30))
>>> img1
<PIL.Image.Image image mode=RGB size=20x30 at 0x106426FD0>

# è£å‰ªå›¾ç‰‡
>>> img2 = img.crop((0, 0, 16, 16))
>>> img2
<PIL.Image.Image image mode=RGB size=16x16 at 0x105E0EFD0>

# ä¿å­˜å›¾ç‰‡
>>> img1.save("11.png")
>>> img2.save("12.png")
```

ä½¿ç”¨ pytorch å¤„ç†å›¾ç‰‡æ—¶è¦é¦–å…ˆè·å–å›¾ç‰‡çš„æ•°æ®ï¼Œå³å„ä¸ªåƒç´ å¯¹åº”çš„é¢œè‰²å€¼ï¼Œä¾‹å¦‚å¤§å°ä¸º 175 * 230ï¼Œæ¨¡å¼æ˜¯ RGB çš„å›¾ç‰‡ä¼šæ‹¥æœ‰ 175 * 230 * 3 çš„æ•°æ®ï¼Œ3 åˆ†åˆ«ä»£è¡¨çº¢ç»¿è“çš„å€¼ï¼ŒèŒƒå›´æ˜¯ 0 ï½ 255ï¼ŒæŠŠå›¾ç‰‡è½¬æ¢ä¸º pytorch çš„ tensor å¯¹è±¡éœ€è¦ç»è¿‡ numpy ä¸­è½¬ï¼Œä»¥ä¸‹æ˜¯è½¬æ¢çš„ä¾‹å­ï¼š

``` python
>>> import numpy
>>> import torch
>>> v = numpy.asarray(img)
>>> t = torch.tensor(v)
>>> t
tensor([[[255, 253, 254],
         [255, 253, 254],
         [255, 253, 254],
         ...,
         [255, 253, 254],
         [255, 253, 254],
         [255, 253, 254]],

        [[255, 253, 254],
         [255, 253, 254],
         [255, 253, 254],
         ...,
         [255, 253, 254],
         [255, 253, 254],
         [255, 253, 254]],

        [[255, 253, 254],
         [255, 253, 254],
         [255, 253, 254],
         ...,
         [255, 253, 254],
         [255, 253, 254],
         [255, 253, 254]],

        ...,

        [[255, 253, 254],
         [255, 253, 254],
         [255, 253, 254],
         ...,
         [255, 253, 254],
         [255, 253, 254],
         [255, 253, 254]],

        [[255, 253, 254],
         [255, 253, 254],
         [255, 253, 254],
         ...,
         [255, 253, 254],
         [255, 253, 254],
         [255, 253, 254]],

        [[255, 253, 254],
         [255, 253, 254],
         [255, 253, 254],
         ...,
         [255, 253, 254],
         [255, 253, 254],
         [255, 253, 254]]], dtype=torch.uint8)
>>> t.shape
torch.Size([230, 175, 3])
```

å¯ä»¥çœ‹åˆ° tensor çš„ç»´åº¦æ˜¯ `é«˜åº¦ x å®½åº¦ x é€šé“æ•°` (RGB å›¾ç‰‡ä¸º 3ï¼Œé»‘ç™½å›¾ç‰‡ä¸º 1ï¼‰ï¼Œå¯æ˜¯ pytorch çš„ CNN æ¨¡å‹ä¼šè¦æ±‚ç»´åº¦ä¸º `é€šé“æ•° x å®½åº¦ x é«˜åº¦`ï¼Œå¹¶ä¸”æ•°å€¼åº”è¯¥æ­£è§„åŒ–åˆ° 0 ~ 1 çš„èŒƒå›´å†…ï¼Œä½¿ç”¨ä»¥ä¸‹ä»£ç å¯ä»¥å®ç°ï¼š

``` python
# äº¤æ¢ç»´åº¦ 0 (é«˜åº¦) å’Œ ç»´åº¦ 2 (é€šé“æ•°)
>>> t1 = t.transpose(0, 2)
>>> t1.shape
torch.Size([3, 175, 230])

>>> t2 = t1 / 255.0
>>> t2
tensor([[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
         ...,
         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],
         [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000]],

        [[0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],
         [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],
         [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],
         ...,
         [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],
         [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922],
         [0.9922, 0.9922, 0.9922,  ..., 0.9922, 0.9922, 0.9922]],

        [[0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],
         [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],
         [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],
         ...,
         [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],
         [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961],
         [0.9961, 0.9961, 0.9961,  ..., 0.9961, 0.9961, 0.9961]]])
```

ä¹‹åå°±å¯ä»¥å›´ç»•ç±»ä¼¼ä¸Šé¢ä¾‹å­ä¸­ `t2` è¿™æ ·çš„ tensor å¯¹è±¡åšæ–‡ç« äº†ğŸ¥³ã€‚

## å·ç§¯ç¥ç»ç½‘ç»œ (CNN)

å·ç§¯ç¥ç»ç½‘ç»œ (CNN) ä¼šä»å›¾ç‰‡çš„å„ä¸ªéƒ¨åˆ†æå–ç‰¹å¾ï¼Œç„¶åå†ä»ä¸€çº§ç‰¹å¾æå–äºŒçº§ç‰¹å¾ï¼Œå¦‚æœ‰å¿…è¦å†æå–ä¸‰çº§ç‰¹å¾ (ä»¥æ­¤ç±»æ¨)ï¼Œæå–ç»“æŸä»¥åæ‰å¹³åŒ–åˆ°æœ€ç»ˆç‰¹å¾ï¼Œç„¶åä½¿ç”¨å¤šå±‚æˆ–å•å±‚çº¿æ€§æ¨¡å‹æ¥å®ç°åˆ†ç±»è¯†åˆ«ã€‚æå–å„çº§ç‰¹å¾ä¼šä½¿ç”¨å·ç§¯å±‚ (Convolution Layer) å’Œæ± åŒ–å±‚ (Pooling Layer)ï¼Œæå–ç‰¹å¾æ—¶å¯ä»¥é€‰æ‹©æ·»åŠ é€šé“æ•°é‡ä»¥å¢åŠ å„ä¸ªéƒ¨åˆ†çš„ä¿¡æ¯é‡ï¼Œåˆ†ç±»è¯†åˆ«æœ€ç»ˆç‰¹å¾ä½¿ç”¨çš„çº¿æ€§æ¨¡å‹åˆç§°å…¨è¿æ¥å±‚ (Fully Connected Layer)ï¼Œä¸‹å›¾æ˜¯æµç¨‹ç¤ºä¾‹ï¼š

![01](./01.png)

ä¹‹å‰çš„æ–‡ç« ä»‹ç»çº¿æ€§æ¨¡å‹å’Œé€’å½’æ¨¡å‹çš„æ—¶å€™æˆ‘ä½¿ç”¨äº†æ•°å­¦å…¬å¼ï¼Œä½†åªç”¨æ•°å­¦å…¬å¼è¯´æ˜ CNN å°†ä¼šéå¸¸éš¾ä»¥ç†è§£ï¼Œæ‰€ä»¥æ¥ä¸‹æ¥æˆ‘ä¼šä¼´éšä¾‹å­é€æ­¥è®²è§£å„ä¸ªå±‚å…·ä½“åšäº†æ€æ ·çš„è¿ç®—ã€‚

### å·ç§¯å±‚ (Convolution Layer)

å·ç§¯å±‚ä¼šå¯¹å›¾ç‰‡çš„å„ä¸ªéƒ¨åˆ†åšçŸ©é˜µä¹˜æ³•æ“ä½œï¼Œç„¶åæŠŠç»“æœä½œä¸ºä¸€ä¸ªæ–°çš„çŸ©é˜µï¼Œæ¯ä¸ªå·ç§¯å±‚æœ‰ä¸¤ä¸ªä¸»è¦çš„å‚æ•°ï¼Œä¸€ä¸ªæ˜¯å†…æ ¸å¤§å° (`kernel_size`)ï¼Œä¸€ä¸ªæ˜¯å¤„ç†é—´éš” (`stride`)ï¼Œä¸‹å›¾æ˜¯ä¸€ä¸ªéå¸¸ç®€å•çš„è®¡ç®—æµç¨‹ä¾‹å­ï¼š

![02](./02.png)

å¦‚æœå¢åŠ å¤„ç†é—´éš”ä¼šæ€æ ·å‘¢ï¼Ÿä¸‹å›¾å±•ç¤ºäº†ä¸åŒå¤„ç†é—´éš”çš„è®¡ç®—éƒ¨åˆ†å’Œè¾“å‡ºç»“æœç»´åº¦çš„åŒºåˆ«ï¼š

![03](./03.png)

æˆ‘ä»¬å¯ä»¥çœ‹åˆ°å¤„ç†é—´éš”å†³å®šäº†æ¯æ¬¡å‘å³æˆ–è€…å‘ä¸‹ç§»åŠ¨çš„è·ç¦»ï¼Œè¾“å‡ºé•¿åº¦å¯ä»¥ä½¿ç”¨å…¬å¼ `(é•¿åº¦ - å†…æ ¸å¤§å°) / å¤„ç†é—´éš” + 1` è®¡ç®—ï¼Œè¾“å‡ºå®½åº¦å¯ä»¥ä½¿ç”¨å…¬å¼ `(é•¿åº¦ - å†…æ ¸å¤§å°) / å¤„ç†é—´éš” + 1` è®¡ç®—ã€‚

ç°åœ¨å†æ¥çœ‹çœ‹ pytorch ä¸­æ€æ ·ä½¿ç”¨å·ç§¯å±‚ï¼Œåˆ›å»ºå·ç§¯å±‚å¯ä»¥ä½¿ç”¨ `torch.nn.Conv2d`ï¼š

``` python
# åˆ›å»ºå·ç§¯å±‚ï¼Œå…¥é€šé“ = 1ï¼Œå‡ºé€šé“ = 1ï¼Œå†…æ ¸å¤§å° = 2ï¼Œå¤„ç†é—´éš” = 1
>>> conv2d = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 2, stride = 1)

# æŸ¥çœ‹å·ç§¯å±‚å†…éƒ¨çš„å‚æ•°ï¼Œç¬¬ä¸€ä¸ªæ˜¯å†…æ ¸å¯¹åº”çš„æƒé‡çŸ©é˜µï¼Œç¬¬äºŒä¸ªæ˜¯åç§»å€¼
>>> p = list(conv2d.parameters())
>>> p
[Parameter containing:
tensor([[[[-0.0650, -0.0575],
          [-0.0313, -0.3539]]]], requires_grad=True), Parameter containing:
tensor([0.1482], requires_grad=True)]

# ç°åœ¨ç”Ÿæˆä¸€ä¸ª 5 x 5ï¼Œå•é€šé“çš„å›¾ç‰‡æ•°æ®ï¼Œä¸ºäº†æ–¹ä¾¿ç†è§£è¿™é‡Œä½¿ç”¨äº† 1 ~ 25ï¼Œå®é™…åº”è¯¥ä½¿ç”¨ 0 ~ 1 ä¹‹é—´çš„å€¼
>>> x = torch.tensor(list(range(1, 26)), dtype=torch.float).reshape(1, 1, 5, 5)
>>> x
tensor([[[[ 1.,  2.,  3.,  4.,  5.],
          [ 6.,  7.,  8.,  9., 10.],
          [11., 12., 13., 14., 15.],
          [16., 17., 18., 19., 20.],
          [21., 22., 23., 24., 25.]]]])

# ä½¿ç”¨å·ç§¯å±‚è®¡ç®—è¾“å‡º
>>> y = conv2d(x)
>>> y
tensor([[[[ -2.6966,  -3.2043,  -3.7119,  -4.2196],
          [ -5.2349,  -5.7426,  -6.2502,  -6.7579],
          [ -7.7732,  -8.2809,  -8.7885,  -9.2962],
          [-10.3115, -10.8192, -11.3268, -11.8345]]]],
       grad_fn=<MkldnnConvolutionBackward>)

# æˆ‘ä»¬å¯ä»¥æ¨¡æ‹Ÿä¸€ä¸‹å¤„ç†å•ä¸ªéƒ¨åˆ†çš„è®¡ç®—ï¼Œçœ‹çœ‹å’Œä¸Šé¢çš„è¾“å‡ºæ˜¯å¦ä¸€è‡´

# ç¬¬ 1 éƒ¨åˆ†
>>> x[0,0,0:2,0:2]
tensor([[1., 2.],
        [6., 7.]])
>>> (p[0][0,0,:,:] * x[0,0,0:2,0:2]).sum() + p[1]
tensor([-2.6966], grad_fn=<AddBackward0>)

# ç¬¬ 2 éƒ¨åˆ†
>>> x[0,0,0:2,1:3]
tensor([[2., 3.],
        [7., 8.]])
>>> (p[0][0,0,:,:] * x[0,0,0:2,1:3]).sum() + p[1]
tensor([-3.2043], grad_fn=<AddBackward0>)

# ç¬¬ 3 éƒ¨åˆ†
>>> (p[0][0,0,:,:] * x[0,0,0:2,2:4]).sum() + p[1]
tensor([-3.7119], grad_fn=<AddBackward0>)

# ä¸€è‡´å§ğŸ¥³
```

åˆ°è¿™é‡Œä½ åº”è¯¥äº†è§£å•é€šé“çš„å·ç§¯å±‚æ˜¯æ€æ ·è®¡ç®—çš„ï¼Œé‚£ä¹ˆå¤šé€šé“å‘¢ï¼Ÿå¦‚æœæœ‰å¤šä¸ªå…¥é€šé“ï¼Œé‚£ä¹ˆå·ç§¯å±‚çš„æƒé‡çŸ©é˜µä¼šç›¸åº”æœ‰å¤šä»½ï¼Œå¦‚æœæœ‰å¤šä¸ªå‡ºé€šé“ï¼Œé‚£ä¹ˆå·ç§¯å±‚çš„æƒé‡çŸ©é˜µæ•°é‡ä¹Ÿä¼šä¹˜ä»¥å‡ºé€šé“çš„å€æ•°ï¼Œä¾‹å¦‚æœ‰ 3 ä¸ªå…¥é€šé“ï¼Œ2 ä¸ªå‡ºé€šé“æ—¶ï¼Œå·ç§¯å±‚çš„æƒé‡çŸ©é˜µä¼šæœ‰ 6 ä¸ª (`3 * 2`)ï¼Œåç§»å€¼ä¼šæœ‰ 2 ä¸ªï¼Œè®¡ç®—è§„åˆ™å¦‚ä¸‹ï¼š

``` text
éƒ¨åˆ†è¾“å‡º[å‡ºé€šé“1] = éƒ¨åˆ†è¾“å…¥[å…¥é€šé“1] * æƒé‡çŸ©é˜µ[0][0] + éƒ¨åˆ†è¾“å…¥[å…¥é€šé“2] * æƒé‡çŸ©é˜µ[0][1] + éƒ¨åˆ†è¾“å…¥[å…¥é€šé“3] * æƒé‡çŸ©é˜µ[0][2] + åç§»å€¼1
éƒ¨åˆ†è¾“å‡º[å‡ºé€šé“2] = éƒ¨åˆ†è¾“å…¥[å…¥é€šé“1] * æƒé‡çŸ©é˜µ[1][0] + éƒ¨åˆ†è¾“å…¥[å…¥é€šé“2] * æƒé‡çŸ©é˜µ[1][1] + éƒ¨åˆ†è¾“å…¥[å…¥é€šé“3] * æƒé‡çŸ©é˜µ[1][2] + åç§»å€¼2
```

ä»è®¡ç®—è§„åˆ™å¯ä»¥çœ‹å‡ºï¼Œå‡ºé€šé“è¶Šå¤šæ¯ä¸ªéƒ¨åˆ†å¯æå–çš„ç‰¹å¾æ•°é‡ (ä¿¡æ¯é‡) ä¹Ÿå°±è¶Šå¤šï¼Œä½†è®¡ç®—é‡ä¹Ÿä¼šç›¸åº”å¢å¤§ã€‚

æœ€åçœ‹çœ‹å·ç§¯å±‚çš„æ•°å­¦å…¬å¼ (åŸºæœ¬å’Œ pytorch æ–‡æ¡£çš„å…¬å¼ç›¸åŒ)ï¼Œç°åœ¨åº”è¯¥å¯ä»¥ç†è§£äº†å§ğŸ¤¢ï¼Ÿ

![04](./04.png)

### æ± åŒ–å±‚ (Pooling Layer)

æ± åŒ–å±‚çš„å¤„ç†æ¯”è¾ƒå¥½ç†è§£ï¼Œå®ƒä¼šå¯¹æ¯ä¸ªå›¾ç‰‡æ¯ä¸ªåŒºåŸŸè¿›è¡Œæ±‚æœ€å¤§å€¼æˆ–è€…æ±‚å¹³å‡å€¼ç­‰è¿ç®—ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![05](./05.png)

ç°åœ¨å†æ¥çœ‹çœ‹ pytorch ä¸­æ€æ ·ä½¿ç”¨å·ç§¯å±‚ï¼Œåˆ›å»ºæ±‚æœ€å¤§å€¼çš„æ± åŒ–å±‚å¯ä»¥ä½¿ç”¨ `torch.nn.MaxPool2d`ï¼Œåˆ›å»ºæ±‚å¹³å‡å€¼çš„æ± åŒ–å±‚å¯ä»¥ä½¿ç”¨ `torch.nn.AvgPool2d`ï¼š

``` python
# åˆ›å»ºæ± åŒ–å±‚ï¼Œå†…æ ¸å¤§å° = 2ï¼Œå¤„ç†é—´éš” = 2
>>> maxPool = torch.nn.MaxPool2d(2, stride=2)

# ç”Ÿæˆä¸€ä¸ª 6 x 6ï¼Œå•é€šé“çš„å›¾ç‰‡æ•°æ®
>>> x = torch.tensor(range(1, 37), dtype=float).reshape(1, 1, 6, 6)
>>> x
tensor([[[[ 1.,  2.,  3.,  4.,  5.,  6.],
          [ 7.,  8.,  9., 10., 11., 12.],
          [13., 14., 15., 16., 17., 18.],
          [19., 20., 21., 22., 23., 24.],
          [25., 26., 27., 28., 29., 30.],
          [31., 32., 33., 34., 35., 36.]]]], dtype=torch.float64)

# ä½¿ç”¨æ± åŒ–å±‚è®¡ç®—è¾“å‡º
>>> maxPool(x)
tensor([[[[ 8., 10., 12.],
          [20., 22., 24.],
          [32., 34., 36.]]]], dtype=torch.float64)

# å¾ˆå¥½ç†è§£å§ğŸ¥³

# åˆ›å»ºå’Œä½¿ç”¨æ±‚å¹³å‡å€¼çš„æ± åŒ–å±‚ä¹Ÿå¾ˆç®€å•
>>> avgPool = torch.nn.AvgPool2d(2, stride=2)
>>> avgPool(x)
tensor([[[[ 4.5000,  6.5000,  8.5000],
          [16.5000, 18.5000, 20.5000],
          [28.5000, 30.5000, 32.5000]]]], dtype=torch.float64)
```

### å…¨è¿æ¥å±‚ (Fully Connected Layer)

å…¨è¿æ¥å±‚å®é™…ä¸Šå°±æ˜¯å¤šå±‚æˆ–å•å±‚çº¿æ€§æ¨¡å‹ï¼Œä½†æŠŠç‰¹å¾ä¼ åˆ°å…¨è¿æ¥å±‚ä¹‹å‰è¿˜éœ€è¦è¿›è¡Œæ‰å¹³åŒ– (Flatten)ï¼Œä¾‹å­å¦‚ä¸‹æ‰€ç¤ºï¼š

``` python
# æ¨¡æ‹Ÿåˆ›å»ºä¸€ä¸ªæ‰¹æ¬¡æ•°é‡ä¸º 2ï¼Œé€šé“æ•°ä¸º 3ï¼Œé•¿å®½å„ä¸º 2 çš„ç‰¹å¾
>>> x = torch.rand((2, 3, 2, 2))
>>> x
tensor([[[[0.6395, 0.6240],
          [0.4194, 0.6054]],

         [[0.4798, 0.4690],
          [0.2647, 0.6087]],

         [[0.5727, 0.7567],
          [0.8287, 0.1382]]],


        [[[0.7903, 0.8635],
          [0.0053, 0.6417]],

         [[0.7093, 0.7740],
          [0.3115, 0.7587]],

         [[0.5875, 0.8268],
          [0.2923, 0.6016]]]])

# å¯¹å®ƒè¿›è¡Œæ‰å¹³åŒ–ï¼Œç»´åº¦ä¼šå˜ä¸º æ‰¹æ¬¡æ•°é‡, é€šé“æ•°*é•¿*å®½
>>> x_flatten = x.view(x.shape[0], -1)
>>> x_flatten
tensor([[0.6395, 0.6240, 0.4194, 0.6054, 0.4798, 0.4690, 0.2647, 0.6087, 0.5727,
         0.7567, 0.8287, 0.1382],
        [0.7903, 0.8635, 0.0053, 0.6417, 0.7093, 0.7740, 0.3115, 0.7587, 0.5875,
         0.8268, 0.2923, 0.6016]])

# ä¹‹åå†ä¼ ç»™çº¿æ€§æ¨¡å‹å³å¯
>>> linear = torch.nn.Linear(in_features=12, out_features=2)
>>> linear(x_flatten)
tensor([[-0.3067, -0.5534],
        [-0.1876, -0.6523]], grad_fn=<AddmmBackward>)
```

### å¡«å……å¤„ç†

åœ¨çœ‹å‰é¢æåˆ°çš„å·ç§¯å±‚æ“ä½œçš„æ—¶å€™ï¼Œä½ å¯èƒ½ä¼šå‘ç°å¦‚æœå¤„ç†é—´éš” (stride) å°äºå†…æ ¸å¤§å° (kernel_size)ï¼Œé‚£ä¹ˆå›¾ç‰‡è¾¹ç¼˜çš„åƒç´ å‚ä¸è¿ç®—çš„æ¬¡æ•°ä¼šæ¯”å›¾ç‰‡ä¸­é—´çš„åƒç´ è¦å°‘ï¼Œä¹Ÿå°±æ˜¯è¯´å›¾ç‰‡è¾¹ç¼˜å¯¹è¿ç®—ç»“æœçš„å½±å“ä¼šæ›´å°ï¼Œå¦‚æœå›¾ç‰‡è¾¹ç¼˜çš„ä¿¡æ¯åŒæ ·æ¯”è¾ƒé‡è¦ï¼Œé‚£ä¹ˆå°±ä¼šå½±å“é¢„æµ‹è¾“å‡ºçš„ç²¾åº¦ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜å‘æ˜çš„å°±æ˜¯å¡«å……å¤„ç†ï¼Œå¡«å……å¤„ç†ç®€å•çš„æ¥è¯´å°±æ˜¯åœ¨å·ç§¯å±‚åˆæœŸå‰ç»™å›¾ç‰‡çš„å‘¨è¾¹æ·»åŠ  0ï¼Œå¦‚æœå¡«å……é‡ç­‰äº 1ï¼Œé‚£ä¹ˆé•¿å®½ä¼šå„å¢åŠ  2ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![06](./06.png)

åœ¨ pytorch ä¸­æ·»åŠ å¡«å……å¤„ç†å¯ä»¥åœ¨åˆ›å»º `Conv2d` çš„æ—¶å€™æŒ‡å®š `padding` å‚æ•°ï¼š

``` python
# åˆ›å»ºå·ç§¯å±‚ï¼Œå…¥é€šé“ = 1ï¼Œå‡ºé€šé“ = 1ï¼Œå†…æ ¸å¤§å° = 2ï¼Œå¤„ç†é—´éš” = 1, å¡«å……é‡ = 1
>>> conv2d = torch.nn.Conv2d(in_channels = 1, out_channels = 1, kernel_size = 2, stride = 1, padding = 1)
```

## ä½¿ç”¨ CNN å®ç°å›¾ç‰‡åˆ†ç±» (LeNet)

æ¥ä¸‹æ¥æˆ‘ä»¬è¯•è¯•ä½¿ç”¨ CNN å®ç°å›¾ç‰‡åˆ†ç±»ï¼Œä¹Ÿå°±æ˜¯ç»™å‡ºä¸€å¼ å›¾ç‰‡è®©ç¨‹åºè¯†åˆ«é‡Œé¢çš„æ˜¯ä»€ä¹ˆä¸œè¥¿ï¼Œä½¿ç”¨çš„æ•°æ®é›†æ˜¯ cifar-10ï¼Œè¿™æ˜¯ä¸€ä¸ªå¾ˆç»å…¸çš„æ•°æ®é›†ï¼ŒåŒ…å«äº† 60000 å¼  32x32 çš„å°å›¾ç‰‡ï¼Œå›¾ç‰‡æœ‰åä¸ªåˆ†ç±» (é£æœºï¼Œæ±½è½¦ï¼Œé¸Ÿï¼ŒçŒ«ï¼Œé¹¿ï¼Œç‹—ï¼Œé’è›™ï¼Œé©¬ï¼Œèˆ¹ï¼Œè´§è½¦)ï¼Œå®˜æ–¹ä¸‹è½½åœ°å€åœ¨[è¿™é‡Œ](https://www.cs.toronto.edu/~kriz/cifar.html)ã€‚

![cifar-10](./cifar-10.png)

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œå®˜æ–¹ä¸‹è½½åœ°å€åªåŒ…å«äºŒè¿›åˆ¶æ•°æ®ï¼Œé€šå¸¸å¾ˆå¤šæ–‡ç« æˆ–è€…æ•™ç¨‹éƒ½ä¼šè®©æˆ‘ä»¬ä½¿ç”¨ `torchvision.datasets.CIFAR10` ç­‰ç°æˆçš„åŠ è½½å™¨æ¥åŠ è½½è¿™ä¸ªæ•°æ®é›†ï¼Œä½†æˆ‘ä¸æ¨èä½¿ç”¨è¿™ç§æ–¹æ³•ï¼Œå› ä¸ºå¦‚æœæˆ‘ä»¬éœ€è¦è®­ç»ƒå®é™…ä¸šåŠ¡ä¸Šçš„æ•°æ®ï¼Œé‚£ä¹ˆè‚¯å®šä¸ä¼šæœ‰ç°æˆçš„åŠ è½½å™¨å¯ä»¥ç”¨ï¼Œè¿˜æ˜¯å¾—ä¸€å¼ å¼ å›¾ç‰‡çš„åŠ è½½å’Œè½¬æ¢ã€‚æ‰€ä»¥è¿™é‡Œæˆ‘ä½¿ç”¨äº† cifar-10 çš„[åŸå§‹å›¾ç‰‡åº“](https://pjreddie.com/projects/cifar-10-dataset-mirror/)ï¼Œç„¶åæ¼”ç¤ºæ€æ ·ä»ä»£ç åŠ è½½å›¾ç‰‡å’Œæ ‡ç­¾ï¼Œç„¶åè½¬æ¢åˆ°è®­ç»ƒä½¿ç”¨çš„ tensor å¯¹è±¡ã€‚

ä»¥ä¸‹çš„ä»£ç ä½¿ç”¨äº† [LeNet æ¨¡å‹](https://en.wikipedia.org/wiki/LeNet)ï¼Œè¿™æ˜¯ 30 å¹´å‰å°±å·²ç»è¢«æå‡ºçš„æ¨¡å‹ï¼Œç»“æ„å’Œæœ¬æ–‡ç¬¬ä¸€ä¸ªå›¾ç‰‡ä»‹ç»çš„ä¸€æ ·ã€‚æ­¤å¤–è¿˜æœ‰ä¸€äº›éœ€è¦æ³¨æ„çš„åœ°æ–¹ï¼š

- cifar-10 å®˜æ–¹é»˜è®¤åˆ’åˆ†äº† 50000 å¼ å›¾ç‰‡ä½œä¸ºè®­ç»ƒé›†ï¼Œ10000 å¼ å›¾ç‰‡ä½œä¸ºéªŒè¯é›†ï¼›è€Œæˆ‘çš„ä»£ç åˆ’åˆ†äº† 48000 å¼ å›¾ç‰‡ä½œä¸ºè®­ç»ƒé›†ï¼Œ6000 å¼ å›¾ç‰‡ä½œä¸ºéªŒè¯é›†ï¼Œ6000 å¼ å›¾ç‰‡ä½œä¸ºæµ‹è¯•é›†ï¼Œæ‰€ä»¥æ­£ç¡®ç‡ç­‰æ•°æ®ä¼šå’Œå…¶ä»–æ–‡ç« æˆ–è€…è®ºæ–‡ä¸ä¸€è‡´
- è®­ç»ƒæ—¶çš„æŸå¤±è®¡ç®—å™¨ä½¿ç”¨äº† `CrossEntropyLoss`, è¿™ä¸ªè®¡ç®—å™¨çš„ç‰¹å¾æ˜¯è¦æ±‚é¢„æµ‹è¾“å‡ºæ˜¯ onehotï¼Œå®é™…è¾“å‡ºæ˜¯ç´¢å¼•å€¼ (åªæœ‰ä¸€ä¸ªåˆ†ç±»æ˜¯æ­£ç¡®è¾“å‡º)ï¼Œä¾‹å¦‚å›¾ç‰‡åˆ†ç±»ä¸º `é¸Ÿ` æ—¶ï¼Œé¢„æµ‹è¾“å‡ºåº”è¯¥ä¸º `[0, 0, 1, 0, 0, 0, 0, 0, 0, 0]` å®é™…è¾“å‡ºåº”è¯¥ä¸º `2`
- è½¬æ¢å„ä¸ªåˆ†ç±»çš„æ•°å€¼åˆ°æ¦‚ç‡ä½¿ç”¨äº† [Softmax å‡½æ•°](https://en.wikipedia.org/wiki/Softmax_function), è¿™ä¸ªå‡½æ•°å¿…é¡»æ”¾åœ¨æ¨¡å‹ä¹‹å¤–ï¼Œå¦‚æœæ”¾åœ¨æ¨¡å‹å†…éƒ¨ä¼šå¯¼è‡´è®­ç»ƒæ•ˆæœå˜å·®ï¼Œå› ä¸º `CrossEntropyLoss` æŸå¤±è®¡ç®—å™¨ä¼šå°½é‡è®©æ­£ç¡®è¾“å‡ºçš„æ•°å€¼æ›´é«˜ï¼Œé”™è¯¯è¾“å‡ºçš„æ•°å€¼æ›´ä½ï¼Œè€Œä¸æ˜¯åˆ†åˆ«æ¥è¿‘ 1 å’Œ 0ï¼Œä½¿ç”¨ softmax ä¼šå¹²æ‰°æŸå¤±çš„è®¡ç®—

``` python
import os
import sys
import torch
import gzip
import itertools
import random
import numpy
import json
from PIL import Image
from torch import nn
from matplotlib import pyplot

# åˆ†æç›®æ ‡çš„å›¾ç‰‡å¤§å°ï¼Œå…¨éƒ¨å›¾ç‰‡éƒ½ä¼šå…ˆç¼©æ”¾åˆ°è¿™ä¸ªå¤§å°
IMAGE_SIZE = (32, 32)
# åˆ†æç›®æ ‡çš„å›¾ç‰‡æ‰€åœ¨çš„æ–‡ä»¶å¤¹
IMAGE_DIR = "./cifar"
# åŒ…å«æ‰€æœ‰å›¾ç‰‡æ ‡ç­¾çš„æ–‡æœ¬æ–‡ä»¶
IMAGE_LABELS_PATH = "./cifar/labels.txt"

class MyModel(nn.Module):
    """å›¾ç‰‡åˆ†ç±» (LeNet)"""
    def __init__(self, num_labels):
        super().__init__()
        # å·ç§¯å±‚å’Œæ± åŒ–å±‚
        self.cnn_model = nn.Sequential(
            nn.Conv2d(3, 6, kernel_size=5), # ç»´åº¦: B,3,32,32 => B,6,28,28
            nn.ReLU(),
            nn.MaxPool2d(2, stride=2), # ç»´åº¦: B,6,14,14
            nn.Conv2d(6, 16, kernel_size=5), # ç»´åº¦: B,16,10,10
            nn.ReLU(),
            nn.MaxPool2d(2, stride=2) # ç»´åº¦: B,16,5,5
        )
        # å…¨è¿æ¥å±‚
        self.fc_model = nn.Sequential(
            nn.Linear(16 * 5 * 5, 120), # ç»´åº¦: B,120
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(120, 60), # ç»´åº¦: B,60
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(60, num_labels), # ç»´åº¦: B,num_labels
        )

    def forward(self, x):
        # åº”ç”¨å·ç§¯å±‚å’Œæ± åŒ–å±‚
        cnn_features = self.cnn_model(x)
        # æ‰å¹³åŒ–è¾“å‡ºçš„ç‰¹å¾
        cnn_features_flatten = cnn_features.view(cnn_features.shape[0], -1)
        # åº”ç”¨å…¨è¿æ¥å±‚
        y = self.fc_model(cnn_features_flatten)
        return y

def save_tensor(tensor, path):
    """ä¿å­˜ tensor å¯¹è±¡åˆ°æ–‡ä»¶"""
    torch.save(tensor, gzip.GzipFile(path, "wb"))

def load_tensor(path):
    """ä»æ–‡ä»¶è¯»å– tensor å¯¹è±¡"""
    return torch.load(gzip.GzipFile(path, "rb"))

def image_to_tensor(img):
    """è½¬æ¢å›¾ç‰‡å¯¹è±¡åˆ° tensor å¯¹è±¡"""
    in_img = img.resize(IMAGE_SIZE)
    arr = numpy.asarray(in_img)
    t = torch.from_numpy(arr)
    t = t.transpose(0, 2) # è½¬æ¢ç»´åº¦ H,W,C åˆ° C,W,H
    t = t / 255.0 # æ­£è§„åŒ–æ•°å€¼ä½¿å¾—èŒƒå›´åœ¨ 0 ~ 1
    return t

def load_image_labels():
    """è¯»å–å›¾ç‰‡åˆ†ç±»åˆ—è¡¨"""
    return list(filter(None, open(IMAGE_LABELS_PATH).read().split()))

def prepare_save_batch(batch, tensor_in, tensor_out):
    """å‡†å¤‡è®­ç»ƒ - ä¿å­˜å•ä¸ªæ‰¹æ¬¡çš„æ•°æ®"""
    # åˆ‡åˆ†è®­ç»ƒé›† (80%)ï¼ŒéªŒè¯é›† (10%) å’Œæµ‹è¯•é›† (10%)
    random_indices = torch.randperm(tensor_in.shape[0])
    training_indices = random_indices[:int(len(random_indices)*0.8)]
    validating_indices = random_indices[int(len(random_indices)*0.8):int(len(random_indices)*0.9):]
    testing_indices = random_indices[int(len(random_indices)*0.9):]
    training_set = (tensor_in[training_indices], tensor_out[training_indices])
    validating_set = (tensor_in[validating_indices], tensor_out[validating_indices])
    testing_set = (tensor_in[testing_indices], tensor_out[testing_indices])

    # ä¿å­˜åˆ°ç¡¬ç›˜
    save_tensor(training_set, f"data/training_set.{batch}.pt")
    save_tensor(validating_set, f"data/validating_set.{batch}.pt")
    save_tensor(testing_set, f"data/testing_set.{batch}.pt")
    print(f"batch {batch} saved")

def prepare():
    """å‡†å¤‡è®­ç»ƒ"""
    # æ•°æ®é›†è½¬æ¢åˆ° tensor ä»¥åä¼šä¿å­˜åœ¨ data æ–‡ä»¶å¤¹ä¸‹
    if not os.path.isdir("data"):
        os.makedirs("data")

    # å‡†å¤‡å›¾ç‰‡åˆ†ç±»åˆ°åºå·çš„ç´¢å¼•
    labels_to_index = { label: index for index, label in enumerate(load_image_labels()) }

    # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡
    image_paths = []
    for root, dirs, files in os.walk(IMAGE_DIR):
        for filename in files:
            path = os.path.join(root, filename)
            if not path.endswith(".png"):
                continue
            # åˆ†ç±»åç§°åœ¨æ–‡ä»¶åä¸­ï¼Œä¾‹å¦‚
            # 2598_cat.png => cat
            label = filename.split(".")[0].split("_")[1]
            label_index = labels_to_index.get(label)
            if label_index is None:
                continue
            image_paths.append((path, label_index))

    # æ‰“ä¹±å›¾ç‰‡é¡ºåº
    random.shuffle(image_paths)

    # åˆ†æ‰¹è¯»å–å’Œä¿å­˜å›¾ç‰‡
    batch_size = 1000
    for batch in range(0, len(image_paths) // batch_size):
        image_tensors = []
        image_labels = []
        for path, label_index in image_paths[batch*batch_size:(batch+1)*batch_size]:
            with Image.open(path) as img:
                t = image_to_tensor(img)
                image_tensors.append(t)
            image_labels.append(label_index)
        tensor_in = torch.stack(image_tensors) # ç»´åº¦: B,C,W,H
        tensor_out = torch.tensor(image_labels) # ç»´åº¦: B
        prepare_save_batch(batch, tensor_in, tensor_out)

def train():
    """å¼€å§‹è®­ç»ƒ"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    num_labels = len(load_image_labels())
    model = MyModel(num_labels)

    # åˆ›å»ºæŸå¤±è®¡ç®—å™¨
    # è®¡ç®—å•åˆ†ç±»è¾“å‡ºæœ€å¥½ä½¿ç”¨ CrossEntropyLoss, å¤šåˆ†ç±»è¾“å‡ºæœ€å¥½ä½¿ç”¨ BCELoss
    # ä½¿ç”¨ CrossEntropyLoss æ—¶å®é™…è¾“å‡ºåº”è¯¥ä¸ºæ ‡ç­¾ç´¢å¼•å€¼ï¼Œä¸éœ€è¦è½¬æ¢ä¸º onehot
    loss_function = torch.nn.CrossEntropyLoss()

    # åˆ›å»ºå‚æ•°è°ƒæ•´å™¨
    optimizer = torch.optim.Adam(model.parameters())

    # è®°å½•è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    training_accuracy_history = []
    validating_accuracy_history = []

    # è®°å½•æœ€é«˜çš„éªŒè¯é›†æ­£ç¡®ç‡
    validating_accuracy_highest = -1
    validating_accuracy_highest_epoch = 0

    # è¯»å–æ‰¹æ¬¡çš„å·¥å…·å‡½æ•°
    def read_batches(base_path):
        for batch in itertools.count():
            path = f"{base_path}.{batch}.pt"
            if not os.path.isfile(path):
                break
            yield load_tensor(path)

    # è®¡ç®—æ­£ç¡®ç‡çš„å·¥å…·å‡½æ•°
    def calc_accuracy(actual, predicted):
        # æŠŠæœ€å¤§çš„å€¼å½“ä½œæ­£ç¡®åˆ†ç±»ï¼Œç„¶åæ¯”å¯¹æœ‰å¤šå°‘ä¸ªåˆ†ç±»ç›¸ç­‰
        predicted_labels = predicted.argmax(dim=1)
        acc = (actual == predicted_labels).sum().item() / actual.shape[0]
        return acc

    # åˆ’åˆ†è¾“å…¥å’Œè¾“å‡ºçš„å·¥å…·å‡½æ•°
    def split_batch_xy(batch, begin=None, end=None):
        # shape = batch_size, channels, width, height
        batch_x = batch[0][begin:end]
        # shape = batch_size
        batch_y = batch[1][begin:end]
        return batch_x, batch_y

    # å¼€å§‹è®­ç»ƒè¿‡ç¨‹
    for epoch in range(1, 10000):
        print(f"epoch: {epoch}")

        # æ ¹æ®è®­ç»ƒé›†è®­ç»ƒå¹¶ä¿®æ”¹å‚æ•°
        # åˆ‡æ¢æ¨¡å‹åˆ°è®­ç»ƒæ¨¡å¼ï¼Œå°†ä¼šå¯ç”¨è‡ªåŠ¨å¾®åˆ†ï¼Œæ‰¹æ¬¡æ­£è§„åŒ– (BatchNorm) ä¸ Dropout
        model.train()
        training_accuracy_list = []
        for batch_index, batch in enumerate(read_batches("data/training_set")):
            # åˆ‡åˆ†å°æ‰¹æ¬¡ï¼Œæœ‰åŠ©äºæ³›åŒ–æ¨¡å‹
            training_batch_accuracy_list = []
            for index in range(0, batch[0].shape[0], 100):
                # åˆ’åˆ†è¾“å…¥å’Œè¾“å‡º
                batch_x, batch_y = split_batch_xy(batch, index, index+100)
                # è®¡ç®—é¢„æµ‹å€¼
                predicted = model(batch_x)
                # è®¡ç®—æŸå¤±
                loss = loss_function(predicted, batch_y)
                # ä»æŸå¤±è‡ªåŠ¨å¾®åˆ†æ±‚å¯¼å‡½æ•°å€¼
                loss.backward()
                # ä½¿ç”¨å‚æ•°è°ƒæ•´å™¨è°ƒæ•´å‚æ•°
                optimizer.step()
                # æ¸…ç©ºå¯¼å‡½æ•°å€¼
                optimizer.zero_grad()
                # è®°å½•è¿™ä¸€ä¸ªæ‰¹æ¬¡çš„æ­£ç¡®ç‡ï¼Œtorch.no_grad ä»£è¡¨ä¸´æ—¶ç¦ç”¨è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½
                with torch.no_grad():
                    training_batch_accuracy_list.append(calc_accuracy(batch_y, predicted))
            # è¾“å‡ºæ‰¹æ¬¡æ­£ç¡®ç‡
            training_batch_accuracy = sum(training_batch_accuracy_list) / len(training_batch_accuracy_list)
            training_accuracy_list.append(training_batch_accuracy)
            print(f"epoch: {epoch}, batch: {batch_index}: batch accuracy: {training_batch_accuracy}")
        training_accuracy = sum(training_accuracy_list) / len(training_accuracy_list)
        training_accuracy_history.append(training_accuracy)
        print(f"training accuracy: {training_accuracy}")

        # æ£€æŸ¥éªŒè¯é›†
        # åˆ‡æ¢æ¨¡å‹åˆ°éªŒè¯æ¨¡å¼ï¼Œå°†ä¼šç¦ç”¨è‡ªåŠ¨å¾®åˆ†ï¼Œæ‰¹æ¬¡æ­£è§„åŒ– (BatchNorm) ä¸ Dropout
        model.eval()
        validating_accuracy_list = []
        for batch in read_batches("data/validating_set"):
            batch_x, batch_y = split_batch_xy(batch)
            predicted = model(batch_x)
            validating_accuracy_list.append(calc_accuracy(batch_y, predicted))
        validating_accuracy = sum(validating_accuracy_list) / len(validating_accuracy_list)
        validating_accuracy_history.append(validating_accuracy)
        print(f"validating accuracy: {validating_accuracy}")

        # è®°å½•æœ€é«˜çš„éªŒè¯é›†æ­£ç¡®ç‡ä¸å½“æ—¶çš„æ¨¡å‹çŠ¶æ€ï¼Œåˆ¤æ–­æ˜¯å¦åœ¨ 20 æ¬¡è®­ç»ƒåä»ç„¶æ²¡æœ‰åˆ·æ–°è®°å½•
        if validating_accuracy > validating_accuracy_highest:
            validating_accuracy_highest = validating_accuracy
            validating_accuracy_highest_epoch = epoch
            save_tensor(model.state_dict(), "model.pt")
            print("highest validating accuracy updated")
        elif epoch - validating_accuracy_highest_epoch > 20:
            # åœ¨ 20 æ¬¡è®­ç»ƒåä»ç„¶æ²¡æœ‰åˆ·æ–°è®°å½•ï¼Œç»“æŸè®­ç»ƒ
            print("stop training because highest validating accuracy not updated in 20 epoches")
            break

    # ä½¿ç”¨è¾¾åˆ°æœ€é«˜æ­£ç¡®ç‡æ—¶çš„æ¨¡å‹çŠ¶æ€
    print(f"highest validating accuracy: {validating_accuracy_highest}",
        f"from epoch {validating_accuracy_highest_epoch}")
    model.load_state_dict(load_tensor("model.pt"))

    # æ£€æŸ¥æµ‹è¯•é›†
    testing_accuracy_list = []
    for batch in read_batches("data/testing_set"):
        batch_x, batch_y = split_batch_xy(batch)
        predicted = model(batch_x)
        testing_accuracy_list.append(calc_accuracy(batch_y, predicted))
    testing_accuracy = sum(testing_accuracy_list) / len(testing_accuracy_list)
    print(f"testing accuracy: {testing_accuracy}")

    # æ˜¾ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    pyplot.plot(training_accuracy_history, label="training")
    pyplot.plot(validating_accuracy_history, label="validing")
    pyplot.ylim(0, 1)
    pyplot.legend()
    pyplot.show()

def eval_model():
    """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ŒåŠ è½½è®­ç»ƒå¥½çš„çŠ¶æ€ï¼Œç„¶ååˆ‡æ¢åˆ°éªŒè¯æ¨¡å¼
    labels = load_image_labels()
    num_labels = len(labels)
    model = MyModel(num_labels)
    model.load_state_dict(load_tensor("model.pt"))
    model.eval()

    # è¯¢é—®å›¾ç‰‡è·¯å¾„ï¼Œå¹¶æ˜¾ç¤ºå¯èƒ½çš„åˆ†ç±»ä¸€è§ˆ
    while True:
        try:
            # æ„å»ºè¾“å…¥
            image_path = input("Image path: ")
            if not image_path:
                continue
            with Image.open(image_path) as img:
                tensor_in = image_to_tensor(img).unsqueeze(0) # ç»´åº¦ C,W,H => 1,C,W,H
            # é¢„æµ‹è¾“å‡º
            tensor_out = model(tensor_in)
            # è½¬æ¢åˆ°å„ä¸ªåˆ†ç±»å¯¹åº”çš„æ¦‚ç‡
            tensor_out = nn.functional.softmax(tensor_out, dim=1)
            # æ˜¾ç¤ºæŒ‰æ¦‚ç‡æ’åºåçš„åˆ†ç±»ä¸€è§ˆ
            rates = (t.item() for t in tensor_out[0])
            label_with_rates = list(zip(labels, rates))
            label_with_rates.sort(key=lambda p:-p[1])
            for label, rate in label_with_rates[:5]:
                rate = rate * 100
                print(f"{label}: {rate:0.2f}%")
            print()
        except Exception as e:
            print("error:", e)

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print(f"Please run: {sys.argv[0]} prepare|train|eval")
        exit()

    # ç»™éšæœºæ•°ç”Ÿæˆå™¨åˆ†é…ä¸€ä¸ªåˆå§‹å€¼ï¼Œä½¿å¾—æ¯æ¬¡è¿è¡Œéƒ½å¯ä»¥ç”Ÿæˆç›¸åŒçš„éšæœºæ•°
    # è¿™æ˜¯ä¸ºäº†è®©è¿‡ç¨‹å¯é‡ç°ï¼Œä½ ä¹Ÿå¯ä»¥é€‰æ‹©ä¸è¿™æ ·åš
    random.seed(0)
    torch.random.manual_seed(0)

    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ“ä½œ
    operation = sys.argv[1]
    if operation == "prepare":
        prepare()
    elif operation == "train":
        train()
    elif operation == "eval":
        eval_model()
    else:
        raise ValueError(f"Unsupported operation: {operation}")

if __name__ == "__main__":
    main()
```

å‡†å¤‡è®­ç»ƒä½¿ç”¨çš„æ•°æ®å’Œå¼€å§‹è®­ç»ƒéœ€è¦åˆ†åˆ«æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

``` text
python3 example.py prepare
python3 example.py train
```

æœ€ç»ˆè¾“å‡ºç»“æœå¦‚ä¸‹ï¼Œå¯ä»¥çœ‹åˆ°è®­ç»ƒé›†æ­£ç¡®ç‡è¾¾åˆ°äº† 71%ï¼ŒéªŒè¯é›†å’Œæµ‹è¯•é›†æ­£ç¡®ç‡è¾¾åˆ°äº† 61%ï¼Œè¿™ä¸ªæ­£ç¡®ç‡ä»£è¡¨å¯ä»¥ç²¾å‡†è¯´å‡ºå›¾ç‰‡æ‰€å±çš„åˆ†ç±»ï¼Œä¹Ÿç§° top 1 æ­£ç¡®ç‡ï¼›æ­¤å¤–è®¡ç®—æ­£ç¡®åˆ†ç±»åœ¨æ¦‚ç‡æ’å‰ä¸‰çš„åˆ†ç±»ä¹‹ä¸­çš„æ¯”ç‡ç§°ä¸º top 3 æ­£ç¡®ç‡ï¼Œå¦‚æœæ˜¯ç”µå•†ä¸Šä¼ å›¾ç‰‡ä»¥åç»™å‡ºä¸‰ä¸ªå¯èƒ½çš„å•†å“åˆ†ç±»è®©å•†å®¶é€‰æ‹©ï¼Œé‚£ä¹ˆè®¡ç®— top 3 æ­£ç¡®ç‡å°±æœ‰æ„ä¹‰äº†ã€‚

``` text
training accuracy: 0.7162083333333331
validating accuracy: 0.6134999999999998
stop training because highest validating accuracy not updated in 20 epoches
highest validating accuracy: 0.6183333333333333 from epoch 40
testing accuracy: 0.6168333333333332
```

è®­ç»ƒé›†ä¸éªŒè¯é›†æ­£ç¡®ç‡å˜åŒ–å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![07](./07.png)

å®é™…ä½¿ç”¨æ¨¡å‹çš„ä¾‹å­å¦‚ä¸‹ï¼Œè¾“å‡ºä»£è¡¨é¢„æµ‹å›¾ç‰‡æœ‰ 79.23% çš„æ¦‚ç‡æ˜¯é£æœºï¼Œä½ ä¹Ÿå¯ä»¥è¯•è¯•åœ¨äº’è”ç½‘ä¸Šéšä¾¿æ‰¾ä¸€å¼ å›¾ç‰‡è®©è¿™ä¸ªæ¨¡å‹è¯†åˆ«ï¼š

``` text
$ python3 example.py eval
Image path: ./cifar/test/2257_airplane.png
airplane: 79.23%
deer: 6.06%
automobile: 4.04%
cat: 2.89%
frog: 2.11%
```

## ä½¿ç”¨ CNN å®ç°å›¾ç‰‡åˆ†ç±» (ResNet)

ä¸Šè¿°çš„æ¨¡å‹ top 1 æ­£ç¡®ç‡åªè¾¾åˆ°äº† 61%, æ¯•ç«Ÿæ˜¯ 30 å¹´å‰çš„è€æ¨¡å‹äº†ğŸ§”ï¼Œè¿™é‡Œæˆ‘å†ä»‹ç»ä¸€ä¸ªç›¸å¯¹æ¯”è¾ƒæ–°çš„æ¨¡å‹ï¼ŒResNet æ˜¯åœ¨ 2015 å¹´ä¸­æå‡ºçš„æ¨¡å‹ï¼Œè®ºæ–‡åœ°å€åœ¨[è¿™é‡Œ](https://arxiv.org/abs/1512.03385)ï¼Œç‰¹å¾æ˜¯ä¼šæŠŠè¾“å…¥å’Œè¾“å‡ºç»“åˆåœ¨ä¸€å—ï¼Œä¾‹å¦‚åŸæ¥è®¡ç®— `y = f(x)` ä¼šå˜ä¸º `y = f(x) + x`ï¼Œä»è€ŒæŠµæ¶ˆå±‚æ•°å˜å¤šå¸¦æ¥çš„æ¢¯åº¦æ¶ˆå¤±é—®é¢˜ (å‚è€ƒæˆ‘ä¹‹å‰å†™çš„[è®­ç»ƒè¿‡ç¨‹ä¸­å¸¸ç”¨çš„æŠ€å·§](https://www.cnblogs.com/zkweb/p/12843741.html))ã€‚

ä¸‹å›¾æ˜¯ ResNet-18 æ¨¡å‹çš„ç»“æ„ï¼Œå†…éƒ¨å¯ä»¥åˆ†ä¸º 4 ç»„ï¼Œæ¯ä¸ªç»„éƒ½åŒ…æ‹¬ 2 ä¸ªåŸºç¡€å—å’Œ 4 ä¸ªå·ç§¯å±‚ï¼Œå¹¶ä¸”æ¯ä¸ªåŸºç¡€å—ä¼šæŠŠè¾“å…¥å’Œè¾“å‡ºç»“åˆåœ¨ä¸€èµ·ï¼Œå±‚æ•°åˆè®¡ä¸€å…±æœ‰ 16ï¼ŒåŠ ä¸Šæœ€å¼€å§‹è½¬æ¢è¾“å…¥çš„å±‚å’Œå…¨è¿æ¥å±‚ä¸€å…±æœ‰ 18 å±‚ï¼Œæ‰€ä»¥ç§°ä¸º ResNet-18ï¼Œé™¤æ­¤ä¹‹å¤–è¿˜æœ‰ ResNet-34ï¼ŒResNet-50 ç­‰ç­‰å˜ç§ï¼Œå¦‚æœæœ‰å…´è¶£å¯ä»¥å‚è€ƒæœ¬èŠ‚æœ«å°¾ç»™å‡ºçš„ `torchvision` çš„å®ç°ä»£ç ã€‚

![08](./08.png)

ä»å›¾ä¸­å¯ä»¥çœ‹åˆ°ï¼Œä»ç¬¬äºŒç»„å¼€å§‹ä¼šæŠŠé•¿å®½å˜ä¸ºä¸€åŠï¼ŒåŒæ—¶é€šé“æ•°å¢åŠ ä¸€å€ï¼Œç„¶åç»´æŒé€šé“æ•°å’Œé•¿å®½ä¸å˜ï¼Œæ‰€æœ‰ç»„ç»“æŸåä½¿ç”¨ä¸€ä¸ª `AvgPool2d` æ¥è®©é•¿å®½å¼ºåˆ¶å˜ä¸º `1x1`ï¼Œæœ€åäº¤ç»™å…¨è¿æ¥å±‚ã€‚è®¡ç®—å·ç§¯å±‚è¾“å‡ºé•¿å®½çš„å…¬å¼æ˜¯ `(é•¿åº¦ - å†…æ ¸å¤§å° + å¡«å……é‡*2) / å¤„ç†é—´éš” + 1`ï¼Œè®©é•¿å®½å˜ä¸ºä¸€åŠä¼šä½¿ç”¨å†…æ ¸å¤§å° 3ï¼Œå¡«å……é‡ 1ï¼Œå¤„ç†é—´éš” 2 ï¼Œä¾‹å¦‚é•¿åº¦ä¸º 32 å¯ä»¥è®¡ç®—å¾—å‡º `(32 - 3 + 2) / 2 + 1 == 16`ï¼›è€Œç»´æŒé•¿å®½çš„åˆ™ä¼šä½¿ç”¨å†…æ ¸å¤§å° 3ï¼Œå¡«å……é‡ 1ï¼Œå¤„ç†é—´éš” 1ï¼Œä¾‹å¦‚é•¿åº¦ä¸º 32 å¯ä»¥è®¡ç®—å¾—å‡º `(32 - 3 + 2) / 1 + 1 == 32`ã€‚

ä»¥ä¸‹æ˜¯ä½¿ç”¨ ResNet-18 è¿›è¡Œè®­ç»ƒçš„ä»£ç ï¼š

``` python
import os
import sys
import torch
import gzip
import itertools
import random
import numpy
import json
from PIL import Image
from torch import nn
from matplotlib import pyplot

# åˆ†æç›®æ ‡çš„å›¾ç‰‡å¤§å°ï¼Œå…¨éƒ¨å›¾ç‰‡éƒ½ä¼šå…ˆç¼©æ”¾åˆ°è¿™ä¸ªå¤§å°
IMAGE_SIZE = (32, 32)
# åˆ†æç›®æ ‡çš„å›¾ç‰‡æ‰€åœ¨çš„æ–‡ä»¶å¤¹
IMAGE_DIR = "./cifar"
# åŒ…å«æ‰€æœ‰å›¾ç‰‡æ ‡ç­¾çš„æ–‡æœ¬æ–‡ä»¶
IMAGE_LABELS_PATH = "./cifar/labels.txt"

class BasicBlock(nn.Module):
    """ResNet ä½¿ç”¨çš„åŸºç¡€å—"""
    expansion = 1 # å®šä¹‰è¿™ä¸ªå—çš„å®é™…å‡ºé€šé“æ˜¯ channels_out çš„å‡ å€ï¼Œè¿™é‡Œçš„å®ç°å›ºå®šæ˜¯ä¸€å€
    def __init__(self, channels_in, channels_out, stride):
        super().__init__()
        # ç”Ÿæˆ 3x3 çš„å·ç§¯å±‚
        # å¤„ç†é—´éš” stride = 1 æ—¶ï¼Œè¾“å‡ºçš„é•¿å®½ä¼šç­‰äºè¾“å…¥çš„é•¿å®½ï¼Œä¾‹å¦‚ (32-3+2)//1+1 == 32
        # å¤„ç†é—´éš” stride = 2 æ—¶ï¼Œè¾“å‡ºçš„é•¿å®½ä¼šç­‰äºè¾“å…¥çš„é•¿å®½çš„ä¸€åŠï¼Œä¾‹å¦‚ (32-3+2)//2+1 == 16
        # æ­¤å¤– resnet çš„ 3x3 å·ç§¯å±‚ä¸ä½¿ç”¨åç§»å€¼ bias
        self.conv1 = nn.Sequential(
            nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(channels_out))
        # å†å®šä¹‰ä¸€ä¸ªè®©è¾“å‡ºå’Œè¾“å…¥ç»´åº¦ç›¸åŒçš„ 3x3 å·ç§¯å±‚
        self.conv2 = nn.Sequential(
            nn.Conv2d(channels_out, channels_out, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(channels_out))
        # è®©åŸå§‹è¾“å…¥å’Œè¾“å‡ºç›¸åŠ çš„æ—¶å€™ï¼Œéœ€è¦ç»´åº¦ä¸€è‡´ï¼Œå¦‚æœç»´åº¦ä¸ä¸€è‡´åˆ™éœ€è¦æ•´åˆ
        self.identity = nn.Sequential()
        if stride != 1 or channels_in != channels_out * self.expansion:
            self.identity = nn.Sequential(
                nn.Conv2d(channels_in, channels_out * self.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(channels_out * self.expansion))

    def forward(self, x):
        # x => conv1 => relu => conv2 => + => relu
        # |                              ^
        # |==============================|
        tmp = self.conv1(x)
        tmp = nn.functional.relu(tmp)
        tmp = self.conv2(tmp)
        tmp += self.identity(x)
        y = nn.functional.relu(tmp)
        return y

class MyModel(nn.Module):
    """å›¾ç‰‡åˆ†ç±» (ResNet-18)"""
    def __init__(self, num_labels, block_type = BasicBlock):
        super().__init__()
        # è®°å½•ä¸Šä¸€å±‚çš„å‡ºé€šé“æ•°é‡
        self.previous_channels_out = 64
        # æŠŠ 3 é€šé“è½¬æ¢åˆ° 64 é€šé“ï¼Œé•¿å®½ä¸å˜
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, self.previous_channels_out, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(self.previous_channels_out))
        # ResNet ä½¿ç”¨çš„å„ä¸ªå±‚
        self.layer1 = self._make_layer(block_type, channels_out=64, num_blocks=2, stride=1)
        self.layer2 = self._make_layer(block_type, channels_out=128, num_blocks=2, stride=2)
        self.layer3 = self._make_layer(block_type, channels_out=256, num_blocks=2, stride=2)
        self.layer4 = self._make_layer(block_type, channels_out=512, num_blocks=2, stride=2)
        # æŠŠæœ€åä¸€å±‚çš„é•¿å®½è½¬æ¢ä¸º 1x1 çš„æ± åŒ–å±‚ï¼ŒAdaptive è¡¨ç¤ºä¼šè‡ªåŠ¨æ£€æµ‹åŸæœ‰é•¿å®½
        # ä¾‹å¦‚ B,512,4,4 çš„çŸ©é˜µä¼šè½¬æ¢ä¸º B,512,1,1ï¼Œæ¯ä¸ªé€šé“çš„å•ä¸ªå€¼ä¼šæ˜¯åŸæœ‰ 16 ä¸ªå€¼çš„å¹³å‡
        self.avgPool = nn.AdaptiveAvgPool2d((1, 1))
        # å…¨è¿æ¥å±‚ï¼Œåªä½¿ç”¨å•å±‚çº¿æ€§æ¨¡å‹
        self.fc_model = nn.Linear(512 * block_type.expansion, num_labels)

    def _make_layer(self, block_type, channels_out, num_blocks, stride):
        blocks = []
        # æ·»åŠ ç¬¬ä¸€ä¸ªå—
        blocks.append(block_type(self.previous_channels_out, channels_out, stride))
        self.previous_channels_out = channels_out * block_type.expansion
        # æ·»åŠ å‰©ä½™çš„å—ï¼Œå‰©ä½™çš„å—å›ºå®šå¤„ç†é—´éš”ä¸º 1ï¼Œä¸ä¼šæ”¹å˜é•¿å®½
        for _ in range(num_blocks-1):
            blocks.append(block_type(self.previous_channels_out, self.previous_channels_out, 1))
            self.previous_channels_out *= block_type.expansion
        return nn.Sequential(*blocks)

    def forward(self, x):
        # è½¬æ¢å‡ºé€šé“åˆ° 64
        tmp = self.conv1(x)
        tmp = nn.functional.relu(tmp)
        # åº”ç”¨ ResNet çš„å„ä¸ªå±‚
        tmp = self.layer1(tmp)
        tmp = self.layer2(tmp)
        tmp = self.layer3(tmp)
        tmp = self.layer4(tmp)
        # è½¬æ¢é•¿å®½åˆ° 1x1
        tmp = self.avgPool(tmp)
        # æ‰å¹³åŒ–ï¼Œç»´åº¦ä¼šå˜ä¸º B,512
        tmp = tmp.view(tmp.shape[0], -1)
        # åº”ç”¨å…¨è¿æ¥å±‚
        y = self.fc_model(tmp)
        return y

def save_tensor(tensor, path):
    """ä¿å­˜ tensor å¯¹è±¡åˆ°æ–‡ä»¶"""
    torch.save(tensor, gzip.GzipFile(path, "wb"))

def load_tensor(path):
    """ä»æ–‡ä»¶è¯»å– tensor å¯¹è±¡"""
    return torch.load(gzip.GzipFile(path, "rb"))

def image_to_tensor(img):
    """è½¬æ¢å›¾ç‰‡å¯¹è±¡åˆ° tensor å¯¹è±¡"""
    in_img = img.resize(IMAGE_SIZE)
    arr = numpy.asarray(in_img)
    t = torch.from_numpy(arr)
    t = t.transpose(0, 2) # è½¬æ¢ç»´åº¦ H,W,C åˆ° C,W,H
    t = t / 255.0 # æ­£è§„åŒ–æ•°å€¼ä½¿å¾—èŒƒå›´åœ¨ 0 ~ 1
    return t

def load_image_labels():
    """è¯»å–å›¾ç‰‡åˆ†ç±»åˆ—è¡¨"""
    return list(filter(None, open(IMAGE_LABELS_PATH).read().split()))

def prepare_save_batch(batch, tensor_in, tensor_out):
    """å‡†å¤‡è®­ç»ƒ - ä¿å­˜å•ä¸ªæ‰¹æ¬¡çš„æ•°æ®"""
    # åˆ‡åˆ†è®­ç»ƒé›† (80%)ï¼ŒéªŒè¯é›† (10%) å’Œæµ‹è¯•é›† (10%)
    random_indices = torch.randperm(tensor_in.shape[0])
    training_indices = random_indices[:int(len(random_indices)*0.8)]
    validating_indices = random_indices[int(len(random_indices)*0.8):int(len(random_indices)*0.9):]
    testing_indices = random_indices[int(len(random_indices)*0.9):]
    training_set = (tensor_in[training_indices], tensor_out[training_indices])
    validating_set = (tensor_in[validating_indices], tensor_out[validating_indices])
    testing_set = (tensor_in[testing_indices], tensor_out[testing_indices])

    # ä¿å­˜åˆ°ç¡¬ç›˜
    save_tensor(training_set, f"data/training_set.{batch}.pt")
    save_tensor(validating_set, f"data/validating_set.{batch}.pt")
    save_tensor(testing_set, f"data/testing_set.{batch}.pt")
    print(f"batch {batch} saved")

def prepare():
    """å‡†å¤‡è®­ç»ƒ"""
    # æ•°æ®é›†è½¬æ¢åˆ° tensor ä»¥åä¼šä¿å­˜åœ¨ data æ–‡ä»¶å¤¹ä¸‹
    if not os.path.isdir("data"):
        os.makedirs("data")

    # å‡†å¤‡å›¾ç‰‡åˆ†ç±»åˆ°åºå·çš„ç´¢å¼•
    labels_to_index = { label: index for index, label in enumerate(load_image_labels()) }

    # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡
    image_paths = []
    for root, dirs, files in os.walk(IMAGE_DIR):
        for filename in files:
            path = os.path.join(root, filename)
            if not path.endswith(".png"):
                continue
            # åˆ†ç±»åç§°åœ¨æ–‡ä»¶åä¸­ï¼Œä¾‹å¦‚
            # 2598_cat.png => cat
            label = filename.split(".")[0].split("_")[1]
            label_index = labels_to_index.get(label)
            if label_index is None:
                continue
            image_paths.append((path, label_index))

    # æ‰“ä¹±å›¾ç‰‡é¡ºåº
    random.shuffle(image_paths)

    # åˆ†æ‰¹è¯»å–å’Œä¿å­˜å›¾ç‰‡
    batch_size = 1000
    for batch in range(0, len(image_paths) // batch_size):
        image_tensors = []
        image_labels = []
        for path, label_index in image_paths[batch*batch_size:(batch+1)*batch_size]:
            with Image.open(path) as img:
                t = image_to_tensor(img)
                image_tensors.append(t)
            image_labels.append(label_index)
        tensor_in = torch.stack(image_tensors) # ç»´åº¦: B,C,W,H
        tensor_out = torch.tensor(image_labels) # ç»´åº¦: B
        prepare_save_batch(batch, tensor_in, tensor_out)

def train():
    """å¼€å§‹è®­ç»ƒ"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    num_labels = len(load_image_labels())
    model = MyModel(num_labels)

    # åˆ›å»ºæŸå¤±è®¡ç®—å™¨
    # è®¡ç®—å•åˆ†ç±»è¾“å‡ºæœ€å¥½ä½¿ç”¨ CrossEntropyLoss, å¤šåˆ†ç±»è¾“å‡ºæœ€å¥½ä½¿ç”¨ BCELoss
    # ä½¿ç”¨ CrossEntropyLoss æ—¶å®é™…è¾“å‡ºåº”è¯¥ä¸ºæ ‡ç­¾ç´¢å¼•å€¼ï¼Œä¸éœ€è¦è½¬æ¢ä¸º onehot
    loss_function = torch.nn.CrossEntropyLoss()

    # åˆ›å»ºå‚æ•°è°ƒæ•´å™¨
    optimizer = torch.optim.Adam(model.parameters())

    # è®°å½•è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    training_accuracy_history = []
    validating_accuracy_history = []

    # è®°å½•æœ€é«˜çš„éªŒè¯é›†æ­£ç¡®ç‡
    validating_accuracy_highest = -1
    validating_accuracy_highest_epoch = 0

    # è¯»å–æ‰¹æ¬¡çš„å·¥å…·å‡½æ•°
    def read_batches(base_path):
        for batch in itertools.count():
            path = f"{base_path}.{batch}.pt"
            if not os.path.isfile(path):
                break
            yield load_tensor(path)

    # è®¡ç®—æ­£ç¡®ç‡çš„å·¥å…·å‡½æ•°
    def calc_accuracy(actual, predicted):
        # æŠŠæœ€å¤§çš„å€¼å½“ä½œæ­£ç¡®åˆ†ç±»ï¼Œç„¶åæ¯”å¯¹æœ‰å¤šå°‘ä¸ªåˆ†ç±»ç›¸ç­‰
        predicted_labels = predicted.argmax(dim=1)
        acc = (actual == predicted_labels).sum().item() / actual.shape[0]
        return acc

    # åˆ’åˆ†è¾“å…¥å’Œè¾“å‡ºçš„å·¥å…·å‡½æ•°
    def split_batch_xy(batch, begin=None, end=None):
        # shape = batch_size, channels, width, height
        batch_x = batch[0][begin:end]
        # shape = batch_size
        batch_y = batch[1][begin:end]
        return batch_x, batch_y

    # å¼€å§‹è®­ç»ƒè¿‡ç¨‹
    for epoch in range(1, 10000):
        print(f"epoch: {epoch}")

        # æ ¹æ®è®­ç»ƒé›†è®­ç»ƒå¹¶ä¿®æ”¹å‚æ•°
        # åˆ‡æ¢æ¨¡å‹åˆ°è®­ç»ƒæ¨¡å¼ï¼Œå°†ä¼šå¯ç”¨è‡ªåŠ¨å¾®åˆ†ï¼Œæ‰¹æ¬¡æ­£è§„åŒ– (BatchNorm) ä¸ Dropout
        model.train()
        training_accuracy_list = []
        for batch_index, batch in enumerate(read_batches("data/training_set")):
            # åˆ‡åˆ†å°æ‰¹æ¬¡ï¼Œæœ‰åŠ©äºæ³›åŒ–æ¨¡å‹
            training_batch_accuracy_list = []
            for index in range(0, batch[0].shape[0], 100):
                # åˆ’åˆ†è¾“å…¥å’Œè¾“å‡º
                batch_x, batch_y = split_batch_xy(batch, index, index+100)
                # è®¡ç®—é¢„æµ‹å€¼
                predicted = model(batch_x)
                # è®¡ç®—æŸå¤±
                loss = loss_function(predicted, batch_y)
                # ä»æŸå¤±è‡ªåŠ¨å¾®åˆ†æ±‚å¯¼å‡½æ•°å€¼
                loss.backward()
                # ä½¿ç”¨å‚æ•°è°ƒæ•´å™¨è°ƒæ•´å‚æ•°
                optimizer.step()
                # æ¸…ç©ºå¯¼å‡½æ•°å€¼
                optimizer.zero_grad()
                # è®°å½•è¿™ä¸€ä¸ªæ‰¹æ¬¡çš„æ­£ç¡®ç‡ï¼Œtorch.no_grad ä»£è¡¨ä¸´æ—¶ç¦ç”¨è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½
                with torch.no_grad():
                    training_batch_accuracy_list.append(calc_accuracy(batch_y, predicted))
            # è¾“å‡ºæ‰¹æ¬¡æ­£ç¡®ç‡
            training_batch_accuracy = sum(training_batch_accuracy_list) / len(training_batch_accuracy_list)
            training_accuracy_list.append(training_batch_accuracy)
            print(f"epoch: {epoch}, batch: {batch_index}: batch accuracy: {training_batch_accuracy}")
        training_accuracy = sum(training_accuracy_list) / len(training_accuracy_list)
        training_accuracy_history.append(training_accuracy)
        print(f"training accuracy: {training_accuracy}")

        # æ£€æŸ¥éªŒè¯é›†
        # åˆ‡æ¢æ¨¡å‹åˆ°éªŒè¯æ¨¡å¼ï¼Œå°†ä¼šç¦ç”¨è‡ªåŠ¨å¾®åˆ†ï¼Œæ‰¹æ¬¡æ­£è§„åŒ– (BatchNorm) ä¸ Dropout
        model.eval()
        validating_accuracy_list = []
        for batch in read_batches("data/validating_set"):
            batch_x, batch_y = split_batch_xy(batch)
            predicted = model(batch_x)
            validating_accuracy_list.append(calc_accuracy(batch_y, predicted))
        validating_accuracy = sum(validating_accuracy_list) / len(validating_accuracy_list)
        validating_accuracy_history.append(validating_accuracy)
        print(f"validating accuracy: {validating_accuracy}")

        # è®°å½•æœ€é«˜çš„éªŒè¯é›†æ­£ç¡®ç‡ä¸å½“æ—¶çš„æ¨¡å‹çŠ¶æ€ï¼Œåˆ¤æ–­æ˜¯å¦åœ¨ 20 æ¬¡è®­ç»ƒåä»ç„¶æ²¡æœ‰åˆ·æ–°è®°å½•
        if validating_accuracy > validating_accuracy_highest:
            validating_accuracy_highest = validating_accuracy
            validating_accuracy_highest_epoch = epoch
            save_tensor(model.state_dict(), "model.pt")
            print("highest validating accuracy updated")
        elif epoch - validating_accuracy_highest_epoch > 20:
            # åœ¨ 20 æ¬¡è®­ç»ƒåä»ç„¶æ²¡æœ‰åˆ·æ–°è®°å½•ï¼Œç»“æŸè®­ç»ƒ
            print("stop training because highest validating accuracy not updated in 20 epoches")
            break

    # ä½¿ç”¨è¾¾åˆ°æœ€é«˜æ­£ç¡®ç‡æ—¶çš„æ¨¡å‹çŠ¶æ€
    print(f"highest validating accuracy: {validating_accuracy_highest}",
        f"from epoch {validating_accuracy_highest_epoch}")
    model.load_state_dict(load_tensor("model.pt"))

    # æ£€æŸ¥æµ‹è¯•é›†
    testing_accuracy_list = []
    for batch in read_batches("data/testing_set"):
        batch_x, batch_y = split_batch_xy(batch)
        predicted = model(batch_x)
        testing_accuracy_list.append(calc_accuracy(batch_y, predicted))
    testing_accuracy = sum(testing_accuracy_list) / len(testing_accuracy_list)
    print(f"testing accuracy: {testing_accuracy}")

    # æ˜¾ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    pyplot.plot(training_accuracy_history, label="training")
    pyplot.plot(validating_accuracy_history, label="validing")
    pyplot.ylim(0, 1)
    pyplot.legend()
    pyplot.show()

def eval_model():
    """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ŒåŠ è½½è®­ç»ƒå¥½çš„çŠ¶æ€ï¼Œç„¶ååˆ‡æ¢åˆ°éªŒè¯æ¨¡å¼
    labels = load_image_labels()
    num_labels = len(labels)
    model = MyModel(num_labels)
    model.load_state_dict(load_tensor("model.pt"))
    model.eval()

    # è¯¢é—®å›¾ç‰‡è·¯å¾„ï¼Œå¹¶æ˜¾ç¤ºå¯èƒ½çš„åˆ†ç±»ä¸€è§ˆ
    while True:
        try:
            # æ„å»ºè¾“å…¥
            image_path = input("Image path: ")
            if not image_path:
                continue
            with Image.open(image_path) as img:
                tensor_in = image_to_tensor(img).unsqueeze(0) # ç»´åº¦ C,W,H => 1,C,W,H
            # é¢„æµ‹è¾“å‡º
            tensor_out = model(tensor_in)
            # è½¬æ¢åˆ°å„ä¸ªåˆ†ç±»å¯¹åº”çš„æ¦‚ç‡
            tensor_out = nn.functional.softmax(tensor_out, dim=1)
            # æ˜¾ç¤ºæŒ‰æ¦‚ç‡æ’åºåçš„åˆ†ç±»ä¸€è§ˆ
            rates = (t.item() for t in tensor_out[0])
            label_with_rates = list(zip(labels, rates))
            label_with_rates.sort(key=lambda p:-p[1])
            for label, rate in label_with_rates[:5]:
                rate = rate * 100
                print(f"{label}: {rate:0.2f}%")
            print()
        except Exception as e:
            print("error:", e)

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print(f"Please run: {sys.argv[0]} prepare|train|eval")
        exit()

    # ç»™éšæœºæ•°ç”Ÿæˆå™¨åˆ†é…ä¸€ä¸ªåˆå§‹å€¼ï¼Œä½¿å¾—æ¯æ¬¡è¿è¡Œéƒ½å¯ä»¥ç”Ÿæˆç›¸åŒçš„éšæœºæ•°
    # è¿™æ˜¯ä¸ºäº†è®©è¿‡ç¨‹å¯é‡ç°ï¼Œä½ ä¹Ÿå¯ä»¥é€‰æ‹©ä¸è¿™æ ·åš
    random.seed(0)
    torch.random.manual_seed(0)

    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ“ä½œ
    operation = sys.argv[1]
    if operation == "prepare":
        prepare()
    elif operation == "train":
        train()
    elif operation == "eval":
        eval_model()
    else:
        raise ValueError(f"Unsupported operation: {operation}")

if __name__ == "__main__":
    main()
```

æœ€ç»ˆè¾“å‡ºç»“æœå¦‚ä¸‹ï¼Œå¯ä»¥çœ‹åˆ°è®­ç»ƒé›†æ­£ç¡®ç‡è¾¾åˆ°äº† 99%ï¼ŒéªŒè¯é›†æ­£ç¡®ç‡è¾¾åˆ°äº† 85%ï¼Œæµ‹è¯•é›†æ­£ç¡®ç‡è¾¾åˆ°äº† 84%ï¼Œæ¯”èµ·ä¸Šé¢çš„ LeNet æ¨¡å‹æ”¹è¿›äº†å¾ˆå¤šå§ğŸ¤—ã€‚

``` text
training accuracy: 0.9972708333333337
validating accuracy: 0.8373333333333337
stop training because highest validating accuracy not updated in 20 epoches
highest validating accuracy: 0.8521666666666667 from epoch 38
testing accuracy: 0.8464999999999996
```

éšä¾¿åœ¨ç½‘ä¸Šæ‰¾çš„çŒ«ç‹—å›¾ç‰‡ï¼š

![cat](./cat.jpg)

![dog](./dog.jpg)

è¾“å‡ºç»“æœå¦‚ä¸‹ï¼Œä¸é”™å§ï¼š

``` text
Image path: BlogArchive/ml-08/cat.jpg
cat: 100.00%
dog: 0.00%
frog: 0.00%
deer: 0.00%
horse: 0.00%

Image path: BlogArchive/ml-08/dog.jpg
dog: 100.00%
bird: 0.00%
deer: 0.00%
frog: 0.00%
horse: 0.00%
```

pytorch æœ‰ä¸“é—¨ç”¨äºå¤„ç†è§†è§‰ä¿¡æ¯çš„ [torchvision](https://pytorch.org/docs/stable/torchvision/index.html)ï¼Œå…¶ä¸­åŒ…å«äº† ResNet çš„å®ç°ï¼Œä¹Ÿå°±æ˜¯è¯´å…¶å®æˆ‘ä»¬ä¸ç”¨è‡ªå·±å»å†™ğŸ¤’ï¼Œå¦‚æœä½ æœ‰å…´è¶£å¯ä»¥å‚è€ƒé‡Œé¢çš„[å®ç°ä»£ç ](https://github.com/pytorch/vision/blob/master/torchvision/models/resnet.py)ï¼Œå†è¯•è¯• ResNet-50 ç­‰å±‚æ•°æ›´å¤šçš„æ¨¡å‹æ˜¯å¦å¯ä»¥å¸¦æ¥æ›´å¥½çš„æ•ˆæœã€‚

## AI é‰´é»„

ç›¸ä¿¡å¾ˆå¤šäººéƒ½çœ‹è¿‡ AI é‰´é»„çš„æ–°é—»ğŸ¥´ğŸ¤­ğŸ¥ºï¼Œå¦‚æœä½ æƒ³è‡ªå·±å®ç°ä¸€ä¸ªï¼Œå¯ä»¥ä» [nsfw_data_scraper](https://github.com/alex000kim/nsfw_data_scraper) ä¸‹è½½å›¾ç‰‡èµ„æºç„¶åä½¿ç”¨ä¸Šé¢ä»‹ç»çš„æ–¹æ³•è®­ç»ƒï¼Œè¯†åˆ«èµ·æ¥ä¼šæ¯” cifar ç®€å•å¾ˆå¤šã€‚å› ä¸ºå®é™…åªéœ€è¦ä¸¤ä¸ªæ ‡ç­¾ï¼ˆ1 é»„è‰²å›¾ç‰‡ï¼Œ0 æ­£å¸¸å›¾ç‰‡ï¼‰ï¼Œæ‰€ä»¥ä¹Ÿå¯ä»¥ä½¿ç”¨å•ä¸ªå€¼ä»£è¡¨ç»“æœï¼Œç„¶åç”¨ sigmoid ä»£æ›¿ softmaxã€‚æ­¤å¤–ä½ ä¹Ÿå¯ä»¥åœ¨ github ä¸Šæœç´¢ nsfw æ‰¾åˆ°ç°æˆçš„æ¨¡å‹ï¼Œ

## ä½¿ç”¨ CNN å®ç°éªŒè¯ç è¯†åˆ« (ResNet-18)

æœ€åå†ç»™å‡ºä¸€ä¸ªå®ç”¨çš„ä¾‹å­ã€‚å¾ˆå¤šç½‘ç«™ä¸ºäº†é˜²æœºå™¨äººæ“ä½œä¼šä½¿ç”¨éªŒè¯ç æœºåˆ¶ï¼Œä¼ ç»Ÿçš„éªŒè¯ç ä¼šæ˜¾ç¤ºä¸€å¼ åŒ…å«æ•°å­—å­—æ¯çš„å›¾ç‰‡ï¼Œç„¶åè®©ç”¨æˆ·å¡«å†™é‡Œé¢çš„å†…å®¹å†å¯¹æ¯”æ˜¯å¦æ­£ç¡®ï¼Œæ¥åˆ¤æ–­ç”¨æˆ·æ˜¯æ™®é€šäººè¿˜æ˜¯æœºå™¨äººï¼Œè¿™æ ·çš„éªŒè¯ç å¯ä»¥ç”¨æœ¬ç¯‡ä»‹ç»çš„ CNN æ¨¡å‹è¯†åˆ«å‡ºæ¥ğŸ˜ˆã€‚

é¦–å…ˆæˆ‘ä»¬æ¥é€‰ä¸€ä¸ªç”ŸæˆéªŒè¯ç çš„ç±»åº“ï¼Œgithub ä¸Šæœç´¢ captcha c# é‡Œé¢éš¾åº¦ç›¸å¯¹æ¯”è¾ƒé«˜çš„æ˜¯ [Hei.Captcha](https://github.com/gebiWangshushu/Hei.Captcha)ï¼Œè¿™ç¯‡å°±ä½¿ç”¨ CNN æ¨¡å‹è¯†åˆ«è¿™ä¸ªç±»åº“ç”Ÿæˆçš„éªŒè¯ç ã€‚(æˆ‘çš„ zkweb é‡Œé¢ä¹Ÿæœ‰[ç”ŸæˆéªŒè¯ç çš„æ¨¡å—](https://github.com/zkweb-framework/ZKWeb.Plugins/blob/master/src/ZKWeb.Plugins/Common.Captcha/src/Domain/Services/CaptchaManager.cs)ï¼Œä½†éš¾åº¦æ¯”è¾ƒä½æ‰€ä»¥å°±ä¸ç”¨äº†)

ä»¥ä¸‹æ­¥éª¤å’Œä»£ç ä¼šç”Ÿæˆåä¸‡å¼ ç”¨äºè®­ç»ƒå’Œæµ‹è¯•ä½¿ç”¨çš„éªŒè¯ç å›¾ç‰‡ï¼š

``` text
mkdir generate-captcha
cd generate-captcha
dotnet new console
dotnet add package Hei.Captcha
mkdir output
mkdir fonts
cd fonts
curl -L 'https://github.com/gebiWangshushu/Hei.Captcha/blob/master/Demo/fonts/Candara.ttf?raw=true' -o Candara.ttf
curl -L 'https://github.com/gebiWangshushu/Hei.Captcha/blob/master/Demo/fonts/STCAIYUN.ttf?raw=true' -o STCAIYUN.ttf
curl -L 'https://github.com/gebiWangshushu/Hei.Captcha/blob/master/Demo/fonts/impact.ttf?raw=true' -o impact.ttf
curl -L 'https://github.com/gebiWangshushu/Hei.Captcha/blob/master/Demo/fonts/monbaiti.ttf?raw=true' -o monbaiti.ttf
cd ..
# æ·»åŠ ç¨‹åºä»£ç 
dotnet run -c Release
```

``` csharp
using System;
using System.IO;
using Hei.Captcha;

namespace generate_captcha
{
    class Program
    {
        static void Main(string[] args)
        {
            var helper = new SecurityCodeHelper();
            var iterations = 100000;
            for (var x = 0; x < iterations; ++x)
            {
                var code = helper.GetRandomEnDigitalText(4);
                var bytes = helper.GetEnDigitalCodeByte(code);
                File.WriteAllBytes($"output/{x:D5}-{code}.png", bytes);
                if (x % 100 == 0)
                    Console.WriteLine($"{x}/{iterations}");
            }
        }
    }
}
```

ä»¥ä¸‹æ˜¯ç”Ÿæˆçš„éªŒè¯ç å›¾ç‰‡ä¾‹å­ï¼Œå˜å½¢æ—‹è½¬å¹²æ‰°çº¿åŠ¨æ€èƒŒæ™¯è‰²è¯¥æœ‰çš„éƒ½æœ‰ğŸ˜ ï¼š

![captcha-1](./captcha-1.png)
![captcha-2](./captcha-2.png)
![captcha-3](./captcha-3.png)

æ¥ä¸‹æ¥æˆ‘ä»¬æƒ³æƒ³åº”è¯¥ç”¨ä»€ä¹ˆæ•°æ®ç»“æ„æ¥è¡¨è¾¾éªŒè¯ç ã€‚åœ¨å›¾ç‰‡è¯†åˆ«çš„ä¾‹å­ä¸­æœ‰åä¸ªåˆ†ç±»ï¼Œæˆ‘ä»¬ç”¨äº† onehot ç¼–ç ï¼Œå³ä½¿ç”¨é•¿åº¦ä¸º 10 çš„ tensor å¯¹è±¡æ¥è¡¨ç¤ºç»“æœï¼Œæ­£ç¡®çš„åˆ†ç±»ä¸º 1ï¼Œä¸æ­£ç¡®çš„åˆ†ç±»ä¸º 0ã€‚æ¢æˆéªŒè¯ç ä»¥åï¼Œå¯ä»¥ç”¨é•¿åº¦ä¸º 36 çš„ tensor å¯¹è±¡æ¥è¡¨ç¤º 1 ä½éªŒè¯ç  (26 ä¸ªè‹±æ–‡æ•°å­— + 10 ä¸ªå­—æ¯ï¼Œå‡è®¾éªŒè¯ç ä¸åˆ†å¤§å°å†™)ï¼Œå¦‚æœæœ‰å¤šä½åˆ™å¯ä»¥ 36 * ä½æ•°çš„ tensor å¯¹è±¡æ¥è¡¨è¾¾å¤šä½éªŒè¯ç ã€‚ä»¥ä¸‹å‡½æ•°å¯ä»¥æŠŠéªŒè¯ç è½¬æ¢ä¸ºå¯¹åº”çš„ tensor å¯¹è±¡ï¼š

``` python
# å­—æ¯æ•°å­—åˆ—è¡¨
ALPHA_NUMS = "abcdefghijklmnopqrstuvwxyz0123456789"
ALPHA_NUMS_MAP = { c: index for index, c in enumerate(ALPHA_NUMS) }
# éªŒè¯ç ä½æ•°
DIGITS = 4
# æ ‡ç­¾æ•°é‡ï¼Œå­—æ¯æ•°å­—æ··åˆ*ä½æ•°
NUM_LABELS = len(ALPHA_NUMS)*DIGITS

def code_to_tensor(code):
    """è½¬æ¢éªŒè¯ç åˆ° tensor å¯¹è±¡ï¼Œä½¿ç”¨ onehot ç¼–ç """
    t = torch.zeros((NUM_LABELS,))
    code = code.lower() # éªŒè¯ç ä¸åˆ†å¤§å°å†™
    for index, c in enumerate(code):
        p = ALPHA_NUMS_MAP[c]
        t[index*len(ALPHA_NUMS)+p] = 1
    return t
```

è½¬æ¢ä¾‹å­å¦‚ä¸‹ï¼š

``` python
>>> code_to_tensor("abcd")
tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
>>> code_to_tensor("a123")
tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.])
```

åè¿‡æ¥ä¹Ÿä¸€æ ·ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠ tensor çš„é•¿åº¦æŒ‰ 36 åˆ†ä¸ºå¤šç»„ï¼Œç„¶åæ±‚æ¯ä¸€ç»„æœ€å¤§çš„å€¼æ‰€åœ¨çš„ç´¢å¼•ï¼Œå†æ ¹æ®è¯¥ç´¢å¼•æ‰¾åˆ°å¯¹åº”çš„å­—æ¯æˆ–è€…æ•°å­—ï¼Œå°±å¯ä»¥æŠŠ tensor å¯¹è±¡è½¬æ¢å›éªŒè¯ç ï¼š

``` python
def tensor_to_code(tensor):
    """è½¬æ¢ tensor å¯¹è±¡åˆ°éªŒè¯ç """
    tensor = tensor.reshape(DIGITS, len(ALPHA_NUMS))
    indices = tensor.max(dim=1).indices
    code = "".join(ALPHA_NUMS[index] for index in indices)
    return code
```

æ¥ä¸‹æ¥å°±å¯ä»¥ç”¨å‰é¢ä»‹ç»è¿‡çš„ ResNet-18 æ¨¡å‹è¿›è¡Œè®­ç»ƒäº†ğŸ˜ï¼Œç›¸æ¯”å‰é¢çš„å›¾ç‰‡åˆ†ç±»ï¼Œè¿™ä»½ä»£ç æœ‰ä»¥ä¸‹å‡ ç‚¹ä¸åŒï¼š

- å› ä¸ºæ˜¯å¤šåˆ†ç±»ï¼ŒæŸå¤±è®¡ç®—å™¨åº”è¯¥ä½¿ç”¨ `BCELoss` ä»£æ›¿ `CrossEntropyLoss`
- `BCELoss` è¦æ±‚æ¨¡å‹è¾“å‡ºå€¼èŒƒå›´åœ¨ 0 ~ 1 ä¹‹é—´ï¼Œæ‰€ä»¥éœ€è¦åœ¨æ¨¡å‹å†…éƒ¨æ·»åŠ æ§åˆ¶å‡½æ•° (`CrossEntropyLoss` è¿™ä¹ˆåšä¼šå½±å“è®­ç»ƒæ•ˆæœï¼Œä½† `BCELoss` ä¸ä¼š)
- å› ä¸ºæ¯ä¸€ç»„éƒ½åªæœ‰ä¸€ä¸ªå€¼æ˜¯æ­£ç¡®çš„ï¼Œç”¨ `softmax` æ•ˆæœä¼šæ¯” `sigmoid` è¦å¥½ (æ™®é€šçš„å¤šåˆ†ç±»é—®é¢˜ä¼šä½¿ç”¨ `sigmoid`)

``` python
import os
import sys
import torch
import gzip
import itertools
import random
import numpy
import json
from PIL import Image
from torch import nn
from matplotlib import pyplot

# åˆ†æç›®æ ‡çš„å›¾ç‰‡å¤§å°ï¼Œå…¨éƒ¨å›¾ç‰‡éƒ½ä¼šå…ˆç¼©æ”¾åˆ°è¿™ä¸ªå¤§å°
# éªŒè¯ç åŸå›¾æ˜¯ 120x50
IMAGE_SIZE = (56, 24)
# åˆ†æç›®æ ‡çš„å›¾ç‰‡æ‰€åœ¨çš„æ–‡ä»¶å¤¹
IMAGE_DIR = "./generate-captcha/output/"
# å­—æ¯æ•°å­—åˆ—è¡¨
ALPHA_NUMS = "abcdefghijklmnopqrstuvwxyz0123456789"
ALPHA_NUMS_MAP = { c: index for index, c in enumerate(ALPHA_NUMS) }
# éªŒè¯ç ä½æ•°
DIGITS = 4
# æ ‡ç­¾æ•°é‡ï¼Œå­—æ¯æ•°å­—æ··åˆ*ä½æ•°
NUM_LABELS = len(ALPHA_NUMS)*DIGITS

class BasicBlock(nn.Module):
    """ResNet ä½¿ç”¨çš„åŸºç¡€å—"""
    expansion = 1 # å®šä¹‰è¿™ä¸ªå—çš„å®é™…å‡ºé€šé“æ˜¯ channels_out çš„å‡ å€ï¼Œè¿™é‡Œçš„å®ç°å›ºå®šæ˜¯ä¸€å€
    def __init__(self, channels_in, channels_out, stride):
        super().__init__()
        # ç”Ÿæˆ 3x3 çš„å·ç§¯å±‚
        # å¤„ç†é—´éš” stride = 1 æ—¶ï¼Œè¾“å‡ºçš„é•¿å®½ä¼šç­‰äºè¾“å…¥çš„é•¿å®½ï¼Œä¾‹å¦‚ (32-3+2)//1+1 == 32
        # å¤„ç†é—´éš” stride = 2 æ—¶ï¼Œè¾“å‡ºçš„é•¿å®½ä¼šç­‰äºè¾“å…¥çš„é•¿å®½çš„ä¸€åŠï¼Œä¾‹å¦‚ (32-3+2)//2+1 == 16
        # æ­¤å¤– resnet çš„ 3x3 å·ç§¯å±‚ä¸ä½¿ç”¨åç§»å€¼ bias
        self.conv1 = nn.Sequential(
            nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(channels_out))
        # å†å®šä¹‰ä¸€ä¸ªè®©è¾“å‡ºå’Œè¾“å…¥ç»´åº¦ç›¸åŒçš„ 3x3 å·ç§¯å±‚
        self.conv2 = nn.Sequential(
            nn.Conv2d(channels_out, channels_out, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(channels_out))
        # è®©åŸå§‹è¾“å…¥å’Œè¾“å‡ºç›¸åŠ çš„æ—¶å€™ï¼Œéœ€è¦ç»´åº¦ä¸€è‡´ï¼Œå¦‚æœç»´åº¦ä¸ä¸€è‡´åˆ™éœ€è¦æ•´åˆ
        self.identity = nn.Sequential()
        if stride != 1 or channels_in != channels_out * self.expansion:
            self.identity = nn.Sequential(
                nn.Conv2d(channels_in, channels_out * self.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(channels_out * self.expansion))

    def forward(self, x):
        # x => conv1 => relu => conv2 => + => relu
        # |                              ^
        # |==============================|
        tmp = self.conv1(x)
        tmp = nn.functional.relu(tmp)
        tmp = self.conv2(tmp)
        tmp += self.identity(x)
        y = nn.functional.relu(tmp)
        return y

class MyModel(nn.Module):
    """è¯†åˆ«éªŒè¯ç  (ResNet-18)"""
    def __init__(self, block_type = BasicBlock):
        super().__init__()
        # è®°å½•ä¸Šä¸€å±‚çš„å‡ºé€šé“æ•°é‡
        self.previous_channels_out = 64
        # æŠŠ 3 é€šé“è½¬æ¢åˆ° 64 é€šé“ï¼Œé•¿å®½ä¸å˜
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, self.previous_channels_out, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(self.previous_channels_out))
        # ResNet ä½¿ç”¨çš„å„ä¸ªå±‚
        self.layer1 = self._make_layer(block_type, channels_out=64, num_blocks=2, stride=1)
        self.layer2 = self._make_layer(block_type, channels_out=128, num_blocks=2, stride=2)
        self.layer3 = self._make_layer(block_type, channels_out=256, num_blocks=2, stride=2)
        self.layer4 = self._make_layer(block_type, channels_out=512, num_blocks=2, stride=2)
        # æŠŠæœ€åä¸€å±‚çš„é•¿å®½è½¬æ¢ä¸º 1x1 çš„æ± åŒ–å±‚ï¼ŒAdaptive è¡¨ç¤ºä¼šè‡ªåŠ¨æ£€æµ‹åŸæœ‰é•¿å®½
        # ä¾‹å¦‚ B,512,4,4 çš„çŸ©é˜µä¼šè½¬æ¢ä¸º B,512,1,1ï¼Œæ¯ä¸ªé€šé“çš„å•ä¸ªå€¼ä¼šæ˜¯åŸæœ‰ 16 ä¸ªå€¼çš„å¹³å‡
        self.avgPool = nn.AdaptiveAvgPool2d((1, 1))
        # å…¨è¿æ¥å±‚ï¼Œåªä½¿ç”¨å•å±‚çº¿æ€§æ¨¡å‹
        self.fc_model = nn.Linear(512 * block_type.expansion, NUM_LABELS)
        # æ§åˆ¶è¾“å‡ºåœ¨ 0 ~ 1 ä¹‹é—´ï¼ŒBCELoss éœ€è¦
        # å› ä¸ºæ¯ç»„åªåº”è¯¥æœ‰ä¸€ä¸ªå€¼ä¸ºçœŸï¼Œä½¿ç”¨ softmax æ•ˆæœä¼šæ¯” sigmoid å¥½
        self.softmax = nn.Softmax(dim=2)

    def _make_layer(self, block_type, channels_out, num_blocks, stride):
        blocks = []
        # æ·»åŠ ç¬¬ä¸€ä¸ªå—
        blocks.append(block_type(self.previous_channels_out, channels_out, stride))
        self.previous_channels_out = channels_out * block_type.expansion
        # æ·»åŠ å‰©ä½™çš„å—ï¼Œå‰©ä½™çš„å—å›ºå®šå¤„ç†é—´éš”ä¸º 1ï¼Œä¸ä¼šæ”¹å˜é•¿å®½
        for _ in range(num_blocks-1):
            blocks.append(block_type(self.previous_channels_out, self.previous_channels_out, 1))
            self.previous_channels_out *= block_type.expansion
        return nn.Sequential(*blocks)

    def forward(self, x):
        # è½¬æ¢å‡ºé€šé“åˆ° 64
        tmp = self.conv1(x)
        tmp = nn.functional.relu(tmp)
        # åº”ç”¨ ResNet çš„å„ä¸ªå±‚
        tmp = self.layer1(tmp)
        tmp = self.layer2(tmp)
        tmp = self.layer3(tmp)
        tmp = self.layer4(tmp)
        # è½¬æ¢é•¿å®½åˆ° 1x1
        tmp = self.avgPool(tmp)
        # æ‰å¹³åŒ–ï¼Œç»´åº¦ä¼šå˜ä¸º B,512
        tmp = tmp.view(tmp.shape[0], -1)
        # åº”ç”¨å…¨è¿æ¥å±‚
        tmp = self.fc_model(tmp)
        # åˆ’åˆ†æ¯ä¸ªå­—ç¬¦å¯¹åº”çš„ç»„ï¼Œä¹‹åç»´åº¦ä¸º batch_size, digits, alpha_nums
        tmp = tmp.reshape(tmp.shape[0], DIGITS, len(ALPHA_NUMS))
        # åº”ç”¨ softmax åˆ°æ¯ä¸€ç»„
        tmp = self.softmax(tmp)
        # é‡æ–°æ‰å¹³åŒ–ï¼Œä¹‹åç»´åº¦ä¸º batch_size, num_labels
        y = tmp.reshape(tmp.shape[0], NUM_LABELS)
        return y

def save_tensor(tensor, path):
    """ä¿å­˜ tensor å¯¹è±¡åˆ°æ–‡ä»¶"""
    torch.save(tensor, gzip.GzipFile(path, "wb"))

def load_tensor(path):
    """ä»æ–‡ä»¶è¯»å– tensor å¯¹è±¡"""
    return torch.load(gzip.GzipFile(path, "rb"))

def image_to_tensor(img):
    """è½¬æ¢å›¾ç‰‡å¯¹è±¡åˆ° tensor å¯¹è±¡"""
    in_img = img.resize(IMAGE_SIZE)
    in_img = in_img.convert("RGB") # è½¬æ¢å›¾ç‰‡æ¨¡å¼åˆ° RGB
    arr = numpy.asarray(in_img)
    t = torch.from_numpy(arr)
    t = t.transpose(0, 2) # è½¬æ¢ç»´åº¦ H,W,C åˆ° C,W,H
    t = t / 255.0 # æ­£è§„åŒ–æ•°å€¼ä½¿å¾—èŒƒå›´åœ¨ 0 ~ 1
    return t

def code_to_tensor(code):
    """è½¬æ¢éªŒè¯ç åˆ° tensor å¯¹è±¡ï¼Œä½¿ç”¨ onehot ç¼–ç """
    t = torch.zeros((NUM_LABELS,))
    code = code.lower() # éªŒè¯ç ä¸åˆ†å¤§å°å†™
    for index, c in enumerate(code):
        p = ALPHA_NUMS_MAP[c]
        t[index*len(ALPHA_NUMS)+p] = 1
    return t

def tensor_to_code(tensor):
    """è½¬æ¢ tensor å¯¹è±¡åˆ°éªŒè¯ç """
    tensor = tensor.reshape(DIGITS, len(ALPHA_NUMS))
    indices = tensor.max(dim=1).indices
    code = "".join(ALPHA_NUMS[index] for index in indices)
    return code

def prepare_save_batch(batch, tensor_in, tensor_out):
    """å‡†å¤‡è®­ç»ƒ - ä¿å­˜å•ä¸ªæ‰¹æ¬¡çš„æ•°æ®"""
    # åˆ‡åˆ†è®­ç»ƒé›† (80%)ï¼ŒéªŒè¯é›† (10%) å’Œæµ‹è¯•é›† (10%)
    random_indices = torch.randperm(tensor_in.shape[0])
    training_indices = random_indices[:int(len(random_indices)*0.8)]
    validating_indices = random_indices[int(len(random_indices)*0.8):int(len(random_indices)*0.9):]
    testing_indices = random_indices[int(len(random_indices)*0.9):]
    training_set = (tensor_in[training_indices], tensor_out[training_indices])
    validating_set = (tensor_in[validating_indices], tensor_out[validating_indices])
    testing_set = (tensor_in[testing_indices], tensor_out[testing_indices])

    # ä¿å­˜åˆ°ç¡¬ç›˜
    save_tensor(training_set, f"data/training_set.{batch}.pt")
    save_tensor(validating_set, f"data/validating_set.{batch}.pt")
    save_tensor(testing_set, f"data/testing_set.{batch}.pt")
    print(f"batch {batch} saved")

def prepare():
    """å‡†å¤‡è®­ç»ƒ"""
    # æ•°æ®é›†è½¬æ¢åˆ° tensor ä»¥åä¼šä¿å­˜åœ¨ data æ–‡ä»¶å¤¹ä¸‹
    if not os.path.isdir("data"):
        os.makedirs("data")

    # æŸ¥æ‰¾æ‰€æœ‰å›¾ç‰‡
    image_paths = []
    for root, dirs, files in os.walk(IMAGE_DIR):
        for filename in files:
            path = os.path.join(root, filename)
            if not path.endswith(".png"):
                continue
            # éªŒè¯ç åœ¨æ–‡ä»¶åä¸­ï¼Œä¾‹å¦‚
            # 00000-R865.png => R865
            code = filename.split(".")[0].split("-")[1]
            image_paths.append((path, code))

    # æ‰“ä¹±å›¾ç‰‡é¡ºåº
    random.shuffle(image_paths)

    # åˆ†æ‰¹è¯»å–å’Œä¿å­˜å›¾ç‰‡
    batch_size = 1000
    for batch in range(0, len(image_paths) // batch_size):
        image_tensors = []
        image_labels = []
        for path, code in image_paths[batch*batch_size:(batch+1)*batch_size]:
            with Image.open(path) as img:
                image_tensors.append(image_to_tensor(img))
            image_labels.append(code_to_tensor(code))
        tensor_in = torch.stack(image_tensors) # ç»´åº¦: B,C,W,H
        tensor_out = torch.stack(image_labels) # ç»´åº¦: B,N
        prepare_save_batch(batch, tensor_in, tensor_out)

def train():
    """å¼€å§‹è®­ç»ƒ"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = MyModel()

    # åˆ›å»ºæŸå¤±è®¡ç®—å™¨
    # è®¡ç®—å¤šåˆ†ç±»è¾“å‡ºæœ€å¥½ä½¿ç”¨ BCELoss
    loss_function = torch.nn.BCELoss()

    # åˆ›å»ºå‚æ•°è°ƒæ•´å™¨
    optimizer = torch.optim.Adam(model.parameters())

    # è®°å½•è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    training_accuracy_history = []
    validating_accuracy_history = []

    # è®°å½•æœ€é«˜çš„éªŒè¯é›†æ­£ç¡®ç‡
    validating_accuracy_highest = -1
    validating_accuracy_highest_epoch = 0

    # è¯»å–æ‰¹æ¬¡çš„å·¥å…·å‡½æ•°
    def read_batches(base_path):
        for batch in itertools.count():
            path = f"{base_path}.{batch}.pt"
            if not os.path.isfile(path):
                break
            yield load_tensor(path)

    # è®¡ç®—æ­£ç¡®ç‡çš„å·¥å…·å‡½æ•°
    def calc_accuracy(actual, predicted):
        # æŠŠæ¯ä¸€ä½çš„æœ€å¤§å€¼å½“ä½œæ­£ç¡®å­—ç¬¦ï¼Œç„¶åæ¯”å¯¹æœ‰å¤šå°‘ä¸ªå­—ç¬¦ç›¸ç­‰
        actual_indices = actual.reshape(actual.shape[0], DIGITS, len(ALPHA_NUMS)).max(dim=2).indices
        predicted_indices = predicted.reshape(predicted.shape[0], DIGITS, len(ALPHA_NUMS)).max(dim=2).indices
        matched = (actual_indices - predicted_indices).abs().sum(dim=1) == 0
        acc = matched.sum().item() / actual.shape[0]
        return acc
 
    # åˆ’åˆ†è¾“å…¥å’Œè¾“å‡ºçš„å·¥å…·å‡½æ•°
    def split_batch_xy(batch, begin=None, end=None):
        # shape = batch_size, channels, width, height
        batch_x = batch[0][begin:end]
        # shape = batch_size, num_labels
        batch_y = batch[1][begin:end]
        return batch_x, batch_y

    # å¼€å§‹è®­ç»ƒè¿‡ç¨‹
    for epoch in range(1, 10000):
        print(f"epoch: {epoch}")

        # æ ¹æ®è®­ç»ƒé›†è®­ç»ƒå¹¶ä¿®æ”¹å‚æ•°
        # åˆ‡æ¢æ¨¡å‹åˆ°è®­ç»ƒæ¨¡å¼ï¼Œå°†ä¼šå¯ç”¨è‡ªåŠ¨å¾®åˆ†ï¼Œæ‰¹æ¬¡æ­£è§„åŒ– (BatchNorm) ä¸ Dropout
        model.train()
        training_accuracy_list = []
        for batch_index, batch in enumerate(read_batches("data/training_set")):
            # åˆ‡åˆ†å°æ‰¹æ¬¡ï¼Œæœ‰åŠ©äºæ³›åŒ–æ¨¡å‹
            training_batch_accuracy_list = []
            for index in range(0, batch[0].shape[0], 100):
                # åˆ’åˆ†è¾“å…¥å’Œè¾“å‡º
                batch_x, batch_y = split_batch_xy(batch, index, index+100)
                # è®¡ç®—é¢„æµ‹å€¼
                predicted = model(batch_x)
                # è®¡ç®—æŸå¤±
                loss = loss_function(predicted, batch_y)
                # ä»æŸå¤±è‡ªåŠ¨å¾®åˆ†æ±‚å¯¼å‡½æ•°å€¼
                loss.backward()
                # ä½¿ç”¨å‚æ•°è°ƒæ•´å™¨è°ƒæ•´å‚æ•°
                optimizer.step()
                # æ¸…ç©ºå¯¼å‡½æ•°å€¼
                optimizer.zero_grad()
                # è®°å½•è¿™ä¸€ä¸ªæ‰¹æ¬¡çš„æ­£ç¡®ç‡ï¼Œtorch.no_grad ä»£è¡¨ä¸´æ—¶ç¦ç”¨è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½
                with torch.no_grad():
                    training_batch_accuracy_list.append(calc_accuracy(batch_y, predicted))
            # è¾“å‡ºæ‰¹æ¬¡æ­£ç¡®ç‡
            training_batch_accuracy = sum(training_batch_accuracy_list) / len(training_batch_accuracy_list)
            training_accuracy_list.append(training_batch_accuracy)
            print(f"epoch: {epoch}, batch: {batch_index}: batch accuracy: {training_batch_accuracy}")
        training_accuracy = sum(training_accuracy_list) / len(training_accuracy_list)
        training_accuracy_history.append(training_accuracy)
        print(f"training accuracy: {training_accuracy}")

        # æ£€æŸ¥éªŒè¯é›†
        # åˆ‡æ¢æ¨¡å‹åˆ°éªŒè¯æ¨¡å¼ï¼Œå°†ä¼šç¦ç”¨è‡ªåŠ¨å¾®åˆ†ï¼Œæ‰¹æ¬¡æ­£è§„åŒ– (BatchNorm) ä¸ Dropout
        model.eval()
        validating_accuracy_list = []
        for batch in read_batches("data/validating_set"):
            batch_x, batch_y = split_batch_xy(batch)
            predicted = model(batch_x)
            validating_accuracy_list.append(calc_accuracy(batch_y, predicted))
        validating_accuracy = sum(validating_accuracy_list) / len(validating_accuracy_list)
        validating_accuracy_history.append(validating_accuracy)
        print(f"validating accuracy: {validating_accuracy}")

        # è®°å½•æœ€é«˜çš„éªŒè¯é›†æ­£ç¡®ç‡ä¸å½“æ—¶çš„æ¨¡å‹çŠ¶æ€ï¼Œåˆ¤æ–­æ˜¯å¦åœ¨ 20 æ¬¡è®­ç»ƒåä»ç„¶æ²¡æœ‰åˆ·æ–°è®°å½•
        if validating_accuracy > validating_accuracy_highest:
            validating_accuracy_highest = validating_accuracy
            validating_accuracy_highest_epoch = epoch
            save_tensor(model.state_dict(), "model.pt")
            print("highest validating accuracy updated")
        elif epoch - validating_accuracy_highest_epoch > 20:
            # åœ¨ 20 æ¬¡è®­ç»ƒåä»ç„¶æ²¡æœ‰åˆ·æ–°è®°å½•ï¼Œç»“æŸè®­ç»ƒ
            print("stop training because highest validating accuracy not updated in 20 epoches")
            break

    # ä½¿ç”¨è¾¾åˆ°æœ€é«˜æ­£ç¡®ç‡æ—¶çš„æ¨¡å‹çŠ¶æ€
    print(f"highest validating accuracy: {validating_accuracy_highest}",
        f"from epoch {validating_accuracy_highest_epoch}")
    model.load_state_dict(load_tensor("model.pt"))

    # æ£€æŸ¥æµ‹è¯•é›†
    testing_accuracy_list = []
    for batch in read_batches("data/testing_set"):
        batch_x, batch_y = split_batch_xy(batch)
        predicted = model(batch_x)
        testing_accuracy_list.append(calc_accuracy(batch_y, predicted))
    testing_accuracy = sum(testing_accuracy_list) / len(testing_accuracy_list)
    print(f"testing accuracy: {testing_accuracy}")

    # æ˜¾ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    pyplot.plot(training_accuracy_history, label="training")
    pyplot.plot(validating_accuracy_history, label="validing")
    pyplot.ylim(0, 1)
    pyplot.legend()
    pyplot.show()

def eval_model():
    """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ŒåŠ è½½è®­ç»ƒå¥½çš„çŠ¶æ€ï¼Œç„¶ååˆ‡æ¢åˆ°éªŒè¯æ¨¡å¼
    model = MyModel()
    model.load_state_dict(load_tensor("model.pt"))
    model.eval()

    # è¯¢é—®å›¾ç‰‡è·¯å¾„ï¼Œå¹¶æ˜¾ç¤ºå¯èƒ½çš„åˆ†ç±»ä¸€è§ˆ
    while True:
        try:
            # æ„å»ºè¾“å…¥
            image_path = input("Image path: ")
            if not image_path:
                continue
            with Image.open(image_path) as img:
                tensor_in = image_to_tensor(img).unsqueeze(0) # ç»´åº¦ C,W,H => 1,C,W,H
            # é¢„æµ‹è¾“å‡º
            tensor_out = model(tensor_in)
            # è½¬æ¢åˆ°éªŒè¯ç 
            code = tensor_to_code(tensor_out[0])
            print(f"code: {code}")
            print()
        except Exception as e:
            print("error:", e)

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print(f"Please run: {sys.argv[0]} prepare|train|eval")
        exit()

    # ç»™éšæœºæ•°ç”Ÿæˆå™¨åˆ†é…ä¸€ä¸ªåˆå§‹å€¼ï¼Œä½¿å¾—æ¯æ¬¡è¿è¡Œéƒ½å¯ä»¥ç”Ÿæˆç›¸åŒçš„éšæœºæ•°
    # è¿™æ˜¯ä¸ºäº†è®©è¿‡ç¨‹å¯é‡ç°ï¼Œä½ ä¹Ÿå¯ä»¥é€‰æ‹©ä¸è¿™æ ·åš
    random.seed(0)
    torch.random.manual_seed(0)

    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ“ä½œ
    operation = sys.argv[1]
    if operation == "prepare":
        prepare()
    elif operation == "train":
        train()
    elif operation == "eval":
        eval_model()
    else:
        raise ValueError(f"Unsupported operation: {operation}")

if __name__ == "__main__":
    main()
```

å› ä¸ºè®­ç»ƒéœ€è¦å¤§é‡æ—¶é—´è€Œæˆ‘æœºå™¨åªæœ‰ CPU å¯ä»¥ç”¨ï¼Œæ‰€ä»¥è¿™æ¬¡æˆ‘å°±åªè®­ç»ƒåˆ° epoch 23 ğŸ¤¢ï¼Œè®­ç»ƒç»“æœå¦‚ä¸‹ã€‚å¯ä»¥çœ‹åˆ°è®­ç»ƒé›†æ­£ç¡®ç‡è¾¾åˆ°äº† 98%ï¼ŒéªŒè¯é›†æ­£ç¡®ç‡è¾¾åˆ°äº† 91%ï¼Œå·²ç»æ˜¯å®ç”¨çš„çº§åˆ«äº†ã€‚

``` text
epoch: 23, batch: 98: batch accuracy: 0.99125
epoch: 23, batch: 99: batch accuracy: 0.9862500000000001
training accuracy: 0.9849874999999997
validating accuracy: 0.9103000000000003
highest validating accuracy updated
```

ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹è¯†åˆ«éªŒè¯ç ï¼Œä½ å¯ä»¥å¯¹æ¯”ä¸Šé¢çš„å›¾ç‰‡çœ‹çœ‹æ˜¯ä¸æ˜¯è¯†åˆ«å¯¹äº† (ç¬¬äºŒå¼ çš„ P çœ‹èµ·æ¥å¾ˆåƒ D ğŸ¤’)ï¼š

``` text
$ python3 example.py eval
Image path: BlogArchive/ml-08/captcha-1.png
code: 8ca6

Image path: BlogArchive/ml-08/captcha-2.png
code: tp8s

Image path: BlogArchive/ml-08/captcha-3.png
code: k225
```

æ³¨æ„è¿™é‡Œä»‹ç»å‡ºæ¥çš„æ¨¡å‹åªèƒ½è¯†åˆ«è¿™ä¸€ç§éªŒè¯ç ï¼Œå…¶ä»–ä¸åŒç§ç±»çš„éªŒè¯ç éœ€è¦åˆ†åˆ«è®­ç»ƒå’Œç”Ÿæˆæ¨¡å‹ï¼Œåšæ‰“ç å¹³å°çš„è¯ä¼šå…ˆè¯†åˆ«éªŒè¯ç ç§ç±»å†ä½¿ç”¨è¯¥ç§ç±»å¯¹åº”çš„æ¨¡å‹è¯†åˆ«éªŒè¯ç å†…å®¹ã€‚å¦‚æœä½ çš„ç›®æ ‡åªæ˜¯å•ç§éªŒè¯ç ï¼Œé‚£ä¹ˆç”¨è¿™ç¯‡æ–‡ç« ä»‹ç»çš„æ–¹æ³•åº”è¯¥å¯ä»¥å¸®ä½ èŠ‚çœè°ƒæ‰“ç å¹³å°çš„é’± ğŸ¤ ã€‚å¦‚æœä½ æœºå™¨æœ‰å¥½æ˜¾å¡ï¼Œä¹Ÿå¯ä»¥è¯•è¯•ç”¨æ›´é«˜çº§çš„æ¨¡å‹æå‡æ­£ç¡®ç‡ã€‚

æ­¤å¤–ï¼Œæœ‰å¾ˆå¤šäººé—®æˆ‘ç°åœ¨æµè¡Œçš„æ»‘åŠ¨éªŒè¯ç å¦‚ä½•ç ´è§£ï¼Œå…¶å®ç ´è§£è¿™ç§éªŒè¯ç åªéœ€è¦åšç®€å•çš„å›¾ç‰‡åˆ†æï¼Œä¾‹å¦‚[è¿™é‡Œ](https://github.com/Python3WebSpider/CrackWeiboSlide)å’Œ[è¿™é‡Œ](https://github.com/chxj1992/slide_captcha_cracker)éƒ½æ²¡æœ‰ä½¿ç”¨æœºå™¨å­¦ä¹ ã€‚ä½†æ»‘åŠ¨éªŒè¯ç ä¸€èˆ¬ä¼šé…åˆæµè§ˆå™¨æŒ‡çº¹å’Œé¼ æ ‡è½¨è¿¹é‡‡é›†ä¸€èµ·ä½¿ç”¨ï¼Œåå°ä¼šæ ¹æ®å¤§é‡æ•°æ®åˆ†æç”¨æˆ·æ˜¯æ™®é€šäººè¿˜æ˜¯æœºå™¨äººï¼Œæ‰€ä»¥ç ´è§£å‡ æ¬¡å¾ˆç®€å•ï¼Œä½†ä¸€ç›´ç ´è§£ä¸‹å»åˆ™ä¼šæœ‰å¾ˆå¤§å‡ ç‡è¢«æ£€æµ‹å‡ºæ¥ã€‚

## ä½¿ç”¨ torchvision é‡Œé¢çš„ resnet æ¨¡å‹

åœ¨å‰æ–‡æˆ‘ä»¬çœ‹åˆ°äº†æ€ä¹ˆç»„åˆå·ç§¯å±‚å’Œæ± åŒ–å±‚è‡ªå·±å®ç° LeNet å’Œ ResNet-18ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨ torchvision ä¸­ç°æˆçš„æ¨¡å‹ï¼Œä»¥ä¸‹æ˜¯ä¿®æ”¹è¯†åˆ«éªŒè¯ç çš„æ¨¡å‹åˆ° torchvision æä¾›çš„ ResNet å®ç°çš„ä»£ç ï¼š

``` python
# æ–‡ä»¶å¼€å¤´å¼•ç”¨ torchvision åº“
import torchvision

# æ›¿æ¢åŸæœ‰ä»£ç ä¸­çš„ MyModel ç±»ï¼ŒBasicBlock å¯ä»¥åˆ æ‰
class MyModel(nn.Module):
    """è¯†åˆ«éªŒè¯ç  (ResNet-18)"""
    def __init__(self):
        super().__init__()
        # Resnet çš„å®ç°
        self.resnet = torchvision.models.resnet18(num_classes=NUM_LABELS)
        # æ§åˆ¶è¾“å‡ºåœ¨ 0 ~ 1 ä¹‹é—´ï¼ŒBCELoss éœ€è¦
        # å› ä¸ºæ¯ç»„åªåº”è¯¥æœ‰ä¸€ä¸ªå€¼ä¸ºçœŸï¼Œä½¿ç”¨ softmax æ•ˆæœä¼šæ¯” sigmoid å¥½
        self.softmax = nn.Softmax(dim=2)

    def forward(self, x):
        # åº”ç”¨ ResNet
        tmp = self.resnet(x)
        # åˆ’åˆ†æ¯ä¸ªå­—ç¬¦å¯¹åº”çš„ç»„ï¼Œä¹‹åç»´åº¦ä¸º batch_size, digits, alpha_nums
        tmp = tmp.reshape(tmp.shape[0], DIGITS, len(ALPHA_NUMS))
        # åº”ç”¨ softmax åˆ°æ¯ä¸€ç»„
        tmp = self.softmax(tmp)
        # é‡æ–°æ‰å¹³åŒ–ï¼Œä¹‹åç»´åº¦ä¸º batch_size, num_labels
        y = tmp.reshape(tmp.shape[0], NUM_LABELS)
        return y
```

æ˜¯ä¸æ˜¯ç®€å•äº†å¾ˆå¤šï¼Ÿå¦‚æœæˆ‘ä»¬æƒ³ä½¿ç”¨ ResNet-50 å¯ä»¥æŠŠ `resnet18` æ”¹ä¸º `resnet50` å³å¯åˆ‡æ¢ã€‚è™½ç„¶ä½¿ç”¨ç°æˆçš„æ¨¡å‹æ–¹ä¾¿ï¼Œä½†äº†è§£ä¸‹å®ƒä»¬çš„åŸç†å’Œè®¡ç®—æ–¹å¼æ€»æ˜¯æœ‰å¥½å¤„çš„ğŸ˜‡ã€‚

## å†™åœ¨æœ€å

è¿™ä¸ªç³»åˆ—ä¸­é¢„å®šè¦å†™çš„å†…å®¹å·²ç»å…¨éƒ¨å†™å‡ºæ¥äº†ï¼Œæ¥ä¸‹æ¥è¦å†™ä»€ä¹ˆè¿˜ä¸ç¡®å®šï¼Œæœ‰æ—¶é—´å¯èƒ½ä¼šé‡æ–°ç»´æŠ¤é‚£äº›æ”¾äº†åŠå¹´ä»¥ä¸Šçš„é¡¹ç›®ï¼Œä¹Ÿå¯èƒ½ä¼šæƒ³åŠæ³•æå¥½é¥­åº—çš„ç”Ÿæ„ï¼Œæœ€è¿‘ç”Ÿæ„å®åœ¨ä¸å¥½å•ŠğŸ¤’ã€‚
