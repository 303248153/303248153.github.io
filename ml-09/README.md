# å†™ç»™ç¨‹åºå‘˜çš„æœºå™¨å­¦ä¹ å…¥é—¨ (ä¹) - å¯¹è±¡è¯†åˆ« RCNN ä¸ Fast-RCNN

å› ä¸ºè¿™å‡ ä¸ªæœˆé¥­åº—ç”Ÿæ„æ¢å¤ï¼ŒåŠ ä¸Šç ”ç©¶ Faster-RCNN ç”¨æ‰äº†å¾ˆå¤šæ—¶é—´ï¼Œå°±æ²¡æœ‰æ›´æ–°åšå®¢äº†ğŸ¶ã€‚è¿™ç¯‡å¼€å§‹ä¼šä»‹ç»å¯¹è±¡è¯†åˆ«çš„æ¨¡å‹ä¸å®ç°æ–¹æ³•ï¼Œé¦–å…ˆä¼šä»‹ç»æœ€ç®€å•çš„ RCNN ä¸ Fast-RCNN æ¨¡å‹ï¼Œä¸‹ä¸€ç¯‡ä¼šä»‹ç» Faster-RCNN æ¨¡å‹ï¼Œå†ä¸‹ä¸€ç¯‡ä¼šä»‹ç» YOLO æ¨¡å‹ã€‚

## å›¾ç‰‡åˆ†ç±»ä¸å¯¹è±¡è¯†åˆ«

åœ¨å‰é¢çš„æ–‡ç« ä¸­æˆ‘ä»¬çœ‹åˆ°äº†å¦‚ä½•ä½¿ç”¨ CNN æ¨¡å‹è¯†åˆ«å›¾ç‰‡é‡Œé¢çš„ç‰©ä½“æ˜¯ä»€ä¹ˆç±»å‹ï¼Œæˆ–è€…è¯†åˆ«å›¾ç‰‡ä¸­å›ºå®šçš„æ–‡å­— (å³éªŒè¯ç )ï¼Œå› ä¸ºæ¨¡å‹ä¼šæŠŠæ•´ä¸ªå›¾ç‰‡å½“ä½œè¾“å…¥å¹¶è¾“å‡ºå›ºå®šçš„ç»“æœï¼Œæ‰€ä»¥å›¾ç‰‡ä¸­åªèƒ½æœ‰ä¸€ä¸ªä¸»è¦çš„ç‰©ä½“æˆ–è€…å›ºå®šæ•°é‡çš„æ–‡å­—ã€‚

å¦‚æœå›¾ç‰‡åŒ…å«äº†å¤šä¸ªç‰©ä½“ï¼Œæˆ‘ä»¬æƒ³è¯†åˆ«æœ‰å“ªäº›ç‰©ä½“ï¼Œå„ä¸ªç‰©ä½“åœ¨ä»€ä¹ˆä½ç½®ï¼Œé‚£ä¹ˆåªç”¨ CNN æ¨¡å‹æ˜¯æ— æ³•å®ç°çš„ã€‚æˆ‘ä»¬éœ€è¦å¯ä»¥æ‰¾å‡ºå›¾ç‰‡å“ªäº›åŒºåŸŸåŒ…å«ç‰©ä½“å¹¶ä¸”åˆ¤æ–­æ¯ä¸ªåŒºåŸŸåŒ…å«ä»€ä¹ˆç‰©ä½“çš„æ¨¡å‹ï¼Œè¿™æ ·çš„æ¨¡å‹ç§°ä¸ºå¯¹è±¡è¯†åˆ«æ¨¡å‹ (Object Detection Model)ï¼Œæœ€æ—©æœŸçš„å¯¹è±¡è¯†åˆ«æ¨¡å‹æ˜¯ RCNN æ¨¡å‹ï¼Œåæ¥åˆå‘å±•å‡º Fast-RCNN (SPPnet)ï¼ŒFaster-RCNN ï¼Œå’Œ YOLO ç­‰æ¨¡å‹ã€‚å› ä¸ºå¯¹è±¡è¯†åˆ«éœ€è¦å¤„ç†çš„æ•°æ®é‡å¤šï¼Œé€Ÿåº¦ä¼šæ¯”è¾ƒæ…¢ (ä¾‹å¦‚ RCNN æ£€æµ‹å•å¼ å›¾ç‰‡åŒ…å«çš„ç‰©ä½“å¯èƒ½éœ€è¦å‡ åç§’)ï¼Œè€Œå¯¹è±¡è¯†åˆ«é€šå¸¸åˆè¦æ±‚å®æ—¶æ€§ (ä¾‹å¦‚æ¥æºæ˜¯æ‘„åƒå¤´æä¾›çš„è§†é¢‘)ï¼Œæ‰€ä»¥å¦‚ä½•æå‡å¯¹è±¡è¯†åˆ«çš„é€Ÿåº¦æ˜¯ä¸€ä¸ªä¸»è¦çš„å‘½é¢˜ï¼Œåé¢å‘å±•å‡ºçš„ Faster-RCNN ä¸ YOLO éƒ½å¯ä»¥åœ¨ä¸€ç§’é’Ÿæ£€æµ‹å‡ åå¼ å›¾ç‰‡ã€‚

![01](./01.png)

å¯¹è±¡è¯†åˆ«çš„åº”ç”¨èŒƒå›´æ¯”è¾ƒå¹¿ï¼Œä¾‹å¦‚äººè„¸è¯†åˆ«ï¼Œè½¦ç‰Œè¯†åˆ«ï¼Œè‡ªåŠ¨é©¾é©¶ç­‰ç­‰éƒ½ç”¨åˆ°äº†å¯¹è±¡è¯†åˆ«çš„æŠ€æœ¯ã€‚å¯¹è±¡è¯†åˆ«æ˜¯å½“ä»Šæœºå™¨å­¦ä¹ é¢†åŸŸçš„ä¸€ä¸ªå‰æ²¿ï¼Œ2017 å¹´ç ”å‘å‡ºæ¥çš„ Mask-RCNN æ¨¡å‹è¿˜å¯ä»¥æ£€æµ‹å¯¹è±¡çš„è½®å»“ã€‚

![02](./02.png)

å› ä¸ºçœ‹ä¸Šå»è¶Šç¥å¥‡çš„ä¸œè¥¿å®ç°èµ·æ¥è¶Šéš¾ï¼Œå¯¹è±¡è¯†åˆ«æ¨¡å‹ç›¸å¯¹äºä¹‹å‰ä»‹ç»çš„æ¨¡å‹éš¾åº¦ä¼šé«˜å¾ˆå¤šï¼Œè¯·åšå¥½å¿ƒç†å‡†å¤‡ğŸ˜±ã€‚

## å¯¹è±¡è¯†åˆ«æ¨¡å‹éœ€è¦çš„è®­ç»ƒæ•°æ®

åœ¨ä»‹ç»å…·ä½“çš„æ¨¡å‹ä¹‹å‰ï¼Œæˆ‘ä»¬é¦–å…ˆçœ‹çœ‹å¯¹è±¡è¯†åˆ«æ¨¡å‹éœ€è¦ä»€ä¹ˆæ ·çš„è®­ç»ƒæ•°æ®ï¼š

![03](./03.png)

å¯¹è±¡è¯†åˆ«æ¨¡å‹éœ€è¦ç»™æ¯ä¸ªå›¾ç‰‡æ ‡è®°æœ‰å“ªäº›åŒºåŸŸï¼Œä¸æ¯ä¸ªåŒºåŸŸå¯¹åº”çš„æ ‡ç­¾ï¼Œä¹Ÿå°±æ˜¯è®­ç»ƒæ•°æ®éœ€è¦æ˜¯åˆ—è¡¨å½¢å¼çš„ã€‚åŒºåŸŸçš„æ ¼å¼é€šå¸¸æœ‰ä¸¤ç§ï¼Œ(x, y, w, h) => å·¦ä¸Šè§’çš„åæ ‡ä¸é•¿å®½ï¼Œä¸ (x1, y1, x2, y2) => å·¦ä¸Šè§’ä¸å³ä¸‹è§’çš„åæ ‡ï¼Œè¿™ä¸¤ç§æ ¼å¼å¯ä»¥äº’ç›¸è½¬æ¢ï¼Œå¤„ç†çš„æ—¶å€™åªéœ€è¦æ³¨æ„æ˜¯å“ªç§æ ¼å¼å³å¯ã€‚æ ‡ç­¾é™¤äº†éœ€è¦è¯†åˆ«çš„å„ä¸ªåˆ†ç±»ä¹‹å¤–ï¼Œè¿˜éœ€è¦æœ‰ä¸€ä¸ªç‰¹æ®Šçš„éå¯¹è±¡ (èƒŒæ™¯) æ ‡ç­¾ï¼Œè¡¨ç¤ºè¿™ä¸ªåŒºåŸŸä¸åŒ…å«ä»»ä½•å¯ä»¥è¯†åˆ«çš„å¯¹è±¡ï¼Œå› ä¸ºéå¯¹è±¡åŒºåŸŸé€šå¸¸å¯ä»¥è‡ªåŠ¨ç”Ÿæˆï¼Œæ‰€ä»¥è®­ç»ƒæ•°æ®ä¸éœ€è¦åŒ…å«éå¯¹è±¡åŒºåŸŸä¸æ ‡ç­¾ã€‚

## RCNN

RCNN (Region Based Convolutional Neural Network) æ˜¯æœ€æ—©æœŸçš„å¯¹è±¡è¯†åˆ«æ¨¡å‹ï¼Œå®ç°æ¯”è¾ƒç®€å•ï¼Œå¯ä»¥åˆ†ä¸ºä»¥ä¸‹æ­¥éª¤ï¼š

- ç”¨æŸç§ç®—æ³•åœ¨å›¾ç‰‡ä¸­é€‰å– 2000 ä¸ª**å¯èƒ½**å‡ºç°å¯¹è±¡çš„åŒºåŸŸ
- æˆªå–è¿™ 2000 ä¸ªåŒºåŸŸåˆ° 2000 ä¸ªå­å›¾ç‰‡ï¼Œç„¶åç¼©æ”¾å®ƒä»¬åˆ°ä¸€ä¸ªå›ºå®šçš„å¤§å°
- ç”¨æ™®é€šçš„ CNN æ¨¡å‹åˆ†åˆ«è¯†åˆ«è¿™ 2000 ä¸ªå­å›¾ç‰‡ï¼Œå¾—å‡ºå®ƒä»¬çš„åˆ†ç±»
- æ’é™¤æ ‡è®°ä¸º "éå¯¹è±¡" åˆ†ç±»çš„åŒºåŸŸ
- æŠŠå‰©ä½™çš„åŒºåŸŸä½œä¸ºè¾“å‡ºç»“æœ

![04](./04.png)

ä½ å¯èƒ½å·²ç»ä»æ­¥éª¤é‡Œçœ‹å‡ºï¼ŒRCNN æœ‰å‡ ä¸ªå¤§é—®é¢˜ğŸ˜ ï¼š

- ç»“æœçš„ç²¾åº¦å¾ˆå¤§ç¨‹åº¦å–å†³äºé€‰å–åŒºåŸŸä½¿ç”¨çš„ç®—æ³•
- é€‰å–åŒºåŸŸä½¿ç”¨çš„ç®—æ³•æ˜¯å›ºå®šçš„ï¼Œä¸å‚ä¸å­¦ä¹ ï¼Œå¦‚æœç®—æ³•æ²¡æœ‰é€‰å‡ºæŸä¸ªåŒ…å«å¯¹è±¡åŒºåŸŸé‚£ä¹ˆæ€ä¹ˆå­¦ä¹ éƒ½æ— æ³•è¯†åˆ«è¿™ä¸ªåŒºåŸŸå‡ºæ¥
- æ…¢ï¼Œè´¼æ…¢ğŸ¢ï¼Œè¯†åˆ« 1 å¼ å›¾ç‰‡å®é™…ç­‰äºè¯†åˆ« 2000 å¼ å›¾ç‰‡

åé¢ä»‹ç»æ¨¡å‹ç»“æœä¼šè§£å†³è¿™äº›é—®é¢˜ï¼Œä½†é¦–å…ˆæˆ‘ä»¬éœ€è¦ç†è§£æœ€ç®€å•çš„ RCNN æ¨¡å‹ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬ç»†çœ‹ä¸€ä¸‹ RCNN å®ç°ä¸­å‡ ä¸ªé‡è¦çš„éƒ¨åˆ†å§ã€‚

### é€‰å–å¯èƒ½å‡ºç°å¯¹è±¡çš„åŒºåŸŸ

é€‰å–å¯èƒ½å‡ºç°å¯¹è±¡çš„åŒºåŸŸçš„ç®—æ³•æœ‰å¾ˆå¤šç§ï¼Œä¾‹å¦‚æ»‘åŠ¨çª—å£æ³• (Sliding Window) å’Œé€‰æ‹©æ€§æœç´¢æ³• (Selective Search)ã€‚æ»‘åŠ¨çª—å£æ³•éå¸¸ç®€å•ï¼Œå†³å®šä¸€ä¸ªå›ºå®šå¤§å°çš„åŒºåŸŸï¼Œç„¶åæŒ‰ä¸€å®šè·ç¦»æ»‘åŠ¨å¾—å‡ºä¸‹ä¸€ä¸ªåŒºåŸŸå³å¯ã€‚æ»‘åŠ¨çª—å£æ³•å®ç°ç®€å•ä½†é€‰å–å‡ºæ¥çš„åŒºåŸŸæ•°é‡éå¸¸åºå¤§å¹¶ä¸”ç²¾åº¦å¾ˆä½ï¼Œæ‰€ä»¥é€šå¸¸ä¸ä¼šä½¿ç”¨è¿™ç§æ–¹æ³•ï¼Œé™¤éç‰©ä½“å¤§å°å›ºå®šå¹¶ä¸”å‡ºç°çš„ä½ç½®æœ‰ä¸€å®šè§„å¾‹ã€‚

![05](./05.png)

é€‰æ‹©æ€§æœç´¢æ³•åˆ™æ¯”è¾ƒé«˜çº§ï¼Œä»¥ä¸‹æ˜¯ç®€å•çš„è¯´æ˜ï¼Œæ‘˜è‡ª [opencv çš„æ–‡ç« ](https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/)ï¼š

![06](./06.png)

ä½ è¿˜å¯ä»¥å‚è€ƒ [è¿™ç¯‡æ–‡ç« ](https://www.jianshu.com/p/351a1afc0d52) æˆ– [åŸå§‹è®ºæ–‡](http://www.huppelen.nl/publications/selectiveSearchDraft.pdf) äº†è§£å…·ä½“çš„è®¡ç®—æ–¹æ³•ã€‚

å¦‚æœä½ è§‰å¾—éš¾ä»¥ç†è§£å¯ä»¥è·³è¿‡ï¼Œå› ä¸ºæ¥ä¸‹æ¥æˆ‘ä»¬ä¼šç›´æ¥ä½¿ç”¨ opencv ç±»åº“ä¸­æä¾›çš„é€‰æ‹©æœç´¢å‡½æ•°ã€‚è€Œä¸”é€‰æ‹©æœç´¢æ³•ç²¾åº¦ä¹Ÿä¸é«˜ï¼Œåé¢ä»‹ç»çš„æ¨¡å‹å°†ä¼šä½¿ç”¨æ›´å¥½çš„æ–¹æ³•ã€‚

``` python
# ä½¿ç”¨ opencv ç±»åº“ä¸­æä¾›çš„é€‰æ‹©æœç´¢å‡½æ•°çš„ä»£ç ä¾‹å­
import cv2

img = cv2.imread("å›¾ç‰‡è·¯å¾„")
s = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
s.setBaseImage(img)
s.switchToSelectiveSearchFast()
boxes = s.process() # å¯èƒ½å‡ºç°å¯¹è±¡çš„æ‰€æœ‰åŒºåŸŸï¼Œä¼šæŒ‰å¯èƒ½æ€§æ’åº
candidate_boxes = boxes[:2000] # é€‰å–å¤´ 2000 ä¸ªåŒºåŸŸ
```

### æŒ‰é‡å ç‡ (IOU) åˆ¤æ–­æ¯ä¸ªåŒºåŸŸæ˜¯å¦åŒ…å«å¯¹è±¡

ä½¿ç”¨ç®—æ³•é€‰å–å‡ºæ¥çš„åŒºåŸŸä¸å®é™…åŒºåŸŸé€šå¸¸ä¸ä¼šå®Œå…¨é‡å ï¼Œåªä¼šé‡å ä¸€éƒ¨åˆ†ï¼Œåœ¨å­¦ä¹ çš„è¿‡ç¨‹ä¸­æˆ‘ä»¬éœ€è¦æ ¹æ®æ‰‹å¤´ä¸Šçš„çœŸå®åŒºåŸŸé¢„å…ˆåˆ¤æ–­é€‰å–å‡ºæ¥çš„åŒºåŸŸæ˜¯å¦åŒ…å«å¯¹è±¡ï¼Œå†å‘Šè¯‰æ¨¡å‹é¢„æµ‹ç»“æœæ˜¯å¦æ­£ç¡®ã€‚åˆ¤æ–­é€‰å–åŒºåŸŸæ˜¯å¦åŒ…å«å¯¹è±¡ä¼šä¾æ®é‡å ç‡ (IOU - Intersection Over Union)ï¼Œæ‰€è°“é‡å ç‡å°±æ˜¯ä¸¤ä¸ªåŒºåŸŸé‡å çš„é¢ç§¯å ä¸¤ä¸ªåŒºåŸŸåˆå¹¶çš„é¢ç§¯çš„æ¯”ç‡ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºã€‚

![07](./07.png)

æˆ‘ä»¬å¯ä»¥è§„å®šé‡å ç‡å¤§äº 70% çš„å€™é€‰åŒºåŸŸåŒ…å«å¯¹è±¡ï¼Œé‡å ç‡å°äº 30% çš„åŒºåŸŸä¸åŒ…å«å¯¹è±¡ï¼Œè€Œé‡å ç‡ä»‹äº 30% ~ 70% çš„åŒºåŸŸä¸åº”è¯¥å‚ä¸å­¦ä¹ ï¼Œè¿™æ˜¯ä¸ºäº†ç»™æ¨¡å‹æä¾›æ¯”è¾ƒæ˜ç¡®çš„æ•°æ®ï¼Œä½¿å¾—å­¦ä¹ æ•ˆæœæ›´å¥½ã€‚

è®¡ç®—é‡å ç‡çš„ä»£ç å¦‚ä¸‹ï¼Œå¦‚æœä¸¤ä¸ªåŒºåŸŸæ²¡æœ‰é‡å åˆ™é‡å ç‡ä¼šä¸º 0ï¼š

``` python
def calc_iou(rect1, rect2):
    """è®¡ç®—ä¸¤ä¸ªåŒºåŸŸé‡å éƒ¨åˆ† / åˆå¹¶éƒ¨åˆ†çš„æ¯”ç‡ (intersection over union)"""
    x1, y1, w1, h1 = rect1
    x2, y2, w2, h2 = rect2
    xi = max(x1, x2)
    yi = max(y1, y2)
    wi = min(x1+w1, x2+w2) - xi
    hi = min(y1+h1, y2+h2) - yi
    if wi > 0 and hi > 0: # æœ‰é‡å éƒ¨åˆ†
        area_overlap = wi*hi
        area_all = w1*h1 + w2*h2 - area_overlap
        iou = area_overlap / area_all
    else: # æ²¡æœ‰é‡å éƒ¨åˆ†
        iou = 0
    return iou
```

### åŸå§‹è®ºæ–‡

å¦‚æœä½ æƒ³çœ‹ RCNN çš„åŸå§‹è®ºæ–‡å¯ä»¥åˆ°ä»¥ä¸‹çš„åœ°å€ï¼š

https://arxiv.org/pdf/1311.2524.pdf

## ä½¿ç”¨ RCNN è¯†åˆ«å›¾ç‰‡ä¸­çš„äººè„¸

å¥½äº†ï¼Œåˆ°è¿™é‡Œä½ åº”è¯¥å¤§è‡´äº†è§£ RCNN çš„å®ç°åŸç†ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬è¯•ç€ç”¨ RCNN å­¦ä¹ è¯†åˆ«ä¸€äº›å›¾ç‰‡ã€‚

å› ä¸ºæ”¶é›†å›¾ç‰‡å’Œæ ‡è®°å›¾ç‰‡éå¸¸ç´¯äººğŸ¤•ï¼Œä¸ºäº†å·æ‡’è¿™ç¯‡æˆ‘è¿˜æ˜¯ä½¿ç”¨ç°æˆçš„æ•°æ®é›†ã€‚ä»¥ä¸‹æ˜¯åŒ…å«äººè„¸å›¾ç‰‡çš„æ•°æ®é›†ï¼Œå¹¶ä¸”å¸¦äº†å„ä¸ªäººè„¸æ‰€åœ¨çš„åŒºåŸŸçš„æ ‡è®°ï¼Œæ ¼å¼æ˜¯ (x1, y1, x2, y2)ã€‚ä¸‹è½½éœ€è¦æ³¨å†Œå¸å·ï¼Œä½†ä¸éœ€è¦äº¤é’±ğŸ¤’ã€‚

https://www.kaggle.com/vin1234/count-the-number-of-faces-present-in-an-image

ä¸‹è½½è§£å‹åå¯ä»¥çœ‹åˆ°å›¾ç‰‡åœ¨ train/image_data ä¸‹ï¼Œæ ‡è®°åœ¨ bbox_train.csv ä¸­ã€‚

ä¾‹å¦‚ä»¥ä¸‹çš„å›¾ç‰‡ï¼š

![10001](./10001.jpg)

å¯¹åº” csv ä¸­çš„ä»¥ä¸‹æ ‡è®°ï¼š

``` text
Name,width,height,xmin,ymin,xmax,ymax
10001.jpg,612,408,192,199,230,235
10001.jpg,612,408,247,168,291,211
10001.jpg,612,408,321,176,366,222
10001.jpg,612,408,355,183,387,214
```

æ•°æ®çš„æ„ä¹‰å¦‚ä¸‹ï¼š

- Name: æ–‡ä»¶å
- width: å›¾ç‰‡æ•´ä½“å®½åº¦
- height: å›¾ç‰‡æ•´ä½“é«˜åº¦
- xmin: äººè„¸åŒºåŸŸçš„å·¦ä¸Šè§’çš„ x åæ ‡
- ymin: äººè„¸åŒºåŸŸçš„å·¦ä¸Šè§’çš„ y åæ ‡
- xmax: äººè„¸åŒºåŸŸçš„å³ä¸‹è§’çš„ x åæ ‡
- ymax: äººè„¸åŒºåŸŸçš„å³ä¸‹è§’çš„ y åæ ‡

ä½¿ç”¨ RCNN å­¦ä¹ ä¸è¯†åˆ«è¿™äº›å›¾ç‰‡ä¸­çš„äººè„¸åŒºåŸŸçš„ä»£ç å¦‚ä¸‹ï¼š

``` python
import os
import sys
import torch
import gzip
import itertools
import random
import numpy
import pandas
import torchvision
import cv2
from torch import nn
from matplotlib import pyplot
from collections import defaultdict

# å„ä¸ªåŒºåŸŸç¼©æ”¾åˆ°çš„å›¾ç‰‡å¤§å°
REGION_IMAGE_SIZE = (32, 32)
# åˆ†æç›®æ ‡çš„å›¾ç‰‡æ‰€åœ¨çš„æ–‡ä»¶å¤¹
IMAGE_DIR = "./784145_1347673_bundle_archive/train/image_data"
# å®šä¹‰å„ä¸ªå›¾ç‰‡ä¸­äººè„¸åŒºåŸŸçš„ CSV æ–‡ä»¶
BOX_CSV_PATH = "./784145_1347673_bundle_archive/train/bbox_train.csv"

# ç”¨äºå¯ç”¨ GPU æ”¯æŒ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class MyModel(nn.Module):
    """è¯†åˆ«æ˜¯å¦äººè„¸ (ResNet-18)"""
    def __init__(self):
        super().__init__()
        # Resnet çš„å®ç°
        # è¾“å‡ºä¸¤ä¸ªåˆ†ç±» [éäººè„¸, äººè„¸]
        self.resnet = torchvision.models.resnet18(num_classes=2)

    def forward(self, x):
        # åº”ç”¨ ResNet
        y = self.resnet(x)
        return y

def save_tensor(tensor, path):
    """ä¿å­˜ tensor å¯¹è±¡åˆ°æ–‡ä»¶"""
    torch.save(tensor, gzip.GzipFile(path, "wb"))

def load_tensor(path):
    """ä»æ–‡ä»¶è¯»å– tensor å¯¹è±¡"""
    return torch.load(gzip.GzipFile(path, "rb"))

def image_to_tensor(img):
    """è½¬æ¢ opencv å›¾ç‰‡å¯¹è±¡åˆ° tensor å¯¹è±¡"""
    # æ³¨æ„ opencv æ˜¯ BGRï¼Œä½†å¯¹è®­ç»ƒæ²¡æœ‰å½±å“æ‰€ä»¥ä¸ç”¨è½¬ä¸º RGB
    img = cv2.resize(img, dsize=REGION_IMAGE_SIZE)
    arr = numpy.asarray(img)
    t = torch.from_numpy(arr)
    t = t.transpose(0, 2) # è½¬æ¢ç»´åº¦ H,W,C åˆ° C,W,H
    t = t / 255.0 # æ­£è§„åŒ–æ•°å€¼ä½¿å¾—èŒƒå›´åœ¨ 0 ~ 1
    return t

def calc_iou(rect1, rect2):
    """è®¡ç®—ä¸¤ä¸ªåŒºåŸŸé‡å éƒ¨åˆ† / åˆå¹¶éƒ¨åˆ†çš„æ¯”ç‡ (intersection over union)"""
    x1, y1, w1, h1 = rect1
    x2, y2, w2, h2 = rect2
    xi = max(x1, x2)
    yi = max(y1, y2)
    wi = min(x1+w1, x2+w2) - xi
    hi = min(y1+h1, y2+h2) - yi
    if wi > 0 and hi > 0: # æœ‰é‡å éƒ¨åˆ†
        area_overlap = wi*hi
        area_all = w1*h1 + w2*h2 - area_overlap
        iou = area_overlap / area_all
    else: # æ²¡æœ‰é‡å éƒ¨åˆ†
        iou = 0
    return iou

def selective_search(img):
    """è®¡ç®— opencv å›¾ç‰‡ä¸­å¯èƒ½å‡ºç°å¯¹è±¡çš„åŒºåŸŸï¼Œåªè¿”å›å¤´ 2000 ä¸ªåŒºåŸŸ"""
    # ç®—æ³•å‚è€ƒ https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/
    s = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    s.setBaseImage(img)
    s.switchToSelectiveSearchFast()
    boxes = s.process()
    return boxes[:2000]

def prepare_save_batch(batch, image_tensors, image_labels):
    """å‡†å¤‡è®­ç»ƒ - ä¿å­˜å•ä¸ªæ‰¹æ¬¡çš„æ•°æ®"""
    # ç”Ÿæˆè¾“å…¥å’Œè¾“å‡º tensor å¯¹è±¡
    tensor_in = torch.stack(image_tensors) # ç»´åº¦: B,C,W,H
    tensor_out = torch.tensor(image_labels, dtype=torch.long) # ç»´åº¦: B

    # åˆ‡åˆ†è®­ç»ƒé›† (80%)ï¼ŒéªŒè¯é›† (10%) å’Œæµ‹è¯•é›† (10%)
    random_indices = torch.randperm(tensor_in.shape[0])
    training_indices = random_indices[:int(len(random_indices)*0.8)]
    validating_indices = random_indices[int(len(random_indices)*0.8):int(len(random_indices)*0.9):]
    testing_indices = random_indices[int(len(random_indices)*0.9):]
    training_set = (tensor_in[training_indices], tensor_out[training_indices])
    validating_set = (tensor_in[validating_indices], tensor_out[validating_indices])
    testing_set = (tensor_in[testing_indices], tensor_out[testing_indices])

    # ä¿å­˜åˆ°ç¡¬ç›˜
    save_tensor(training_set, f"data/training_set.{batch}.pt")
    save_tensor(validating_set, f"data/validating_set.{batch}.pt")
    save_tensor(testing_set, f"data/testing_set.{batch}.pt")
    print(f"batch {batch} saved")

def prepare():
    """å‡†å¤‡è®­ç»ƒ"""
    # æ•°æ®é›†è½¬æ¢åˆ° tensor ä»¥åä¼šä¿å­˜åœ¨ data æ–‡ä»¶å¤¹ä¸‹
    if not os.path.isdir("data"):
        os.makedirs("data")

    # åŠ è½½ csv æ–‡ä»¶ï¼Œæ„å»ºå›¾ç‰‡åˆ°åŒºåŸŸåˆ—è¡¨çš„ç´¢å¼• { å›¾ç‰‡å: [ åŒºåŸŸ, åŒºåŸŸ, .. ] }
    box_map = defaultdict(lambda: [])
    df = pandas.read_csv(BOX_CSV_PATH)
    for row in df.values:
        filename, width, height, x1, y1, x2, y2 = row[:7]
        box_map[filename].append((x1, y1, x2-x1, y2-y1))

    # ä»å›¾ç‰‡é‡Œé¢æå–äººè„¸ (æ­£æ ·æœ¬) å’Œéäººè„¸ (è´Ÿæ ·æœ¬) çš„å›¾ç‰‡
    batch_size = 1000
    batch = 0
    image_tensors = []
    image_labels = []
    for filename, true_boxes in box_map.items():
        path = os.path.join(IMAGE_DIR, filename)
        img = cv2.imread(path) # åŠ è½½åŸå§‹å›¾ç‰‡
        candidate_boxes = selective_search(img) # æŸ¥æ‰¾å€™é€‰åŒºåŸŸ
        positive_samples = 0
        negative_samples = 0
        for candidate_box in candidate_boxes:
            # å¦‚æœå€™é€‰åŒºåŸŸå’Œä»»æ„ä¸€ä¸ªå®é™…åŒºåŸŸé‡å ç‡å¤§äº 70%ï¼Œåˆ™è®¤ä¸ºæ˜¯æ­£æ ·æœ¬
            # å¦‚æœå€™é€‰åŒºåŸŸå’Œæ‰€æœ‰å®é™…åŒºåŸŸé‡å ç‡éƒ½å°äº 30%ï¼Œåˆ™è®¤ä¸ºæ˜¯è´Ÿæ ·æœ¬
            # æ¯ä¸ªå›¾ç‰‡æœ€å¤šæ·»åŠ æ­£æ ·æœ¬æ•°é‡ + 10 ä¸ªè´Ÿæ ·æœ¬ï¼Œéœ€è¦æä¾›è¶³å¤Ÿå¤šè´Ÿæ ·æœ¬é¿å…ä¼ªé˜³æ€§åˆ¤æ–­
            iou_list = [ calc_iou(candidate_box, true_box) for true_box in true_boxes ]
            positive_index = next((index for index, iou in enumerate(iou_list) if iou > 0.70), None)
            is_negative = all(iou < 0.30 for iou in iou_list)
            result = None
            if positive_index is not None:
                result = True
                positive_samples += 1
            elif is_negative and negative_samples < positive_samples + 10:
                result = False
                negative_samples += 1
            if result is not None:
                x, y, w, h = candidate_box
                child_img = img[y:y+h, x:x+w].copy()
                # æ£€éªŒè®¡ç®—æ˜¯å¦æœ‰é—®é¢˜
                # cv2.imwrite(f"{filename}_{x}_{y}_{w}_{h}_{int(result)}.png", child_img)
                image_tensors.append(image_to_tensor(child_img))
                image_labels.append(int(result))
                if len(image_tensors) >= batch_size:
                    # ä¿å­˜æ‰¹æ¬¡
                    prepare_save_batch(batch, image_tensors, image_labels)
                    image_tensors.clear()
                    image_labels.clear()
                    batch += 1
    # ä¿å­˜å‰©ä½™çš„æ‰¹æ¬¡
    if len(image_tensors) > 10:
        prepare_save_batch(batch, image_tensors, image_labels)

def train():
    """å¼€å§‹è®­ç»ƒ"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = MyModel().to(device)

    # åˆ›å»ºæŸå¤±è®¡ç®—å™¨
    loss_function = torch.nn.CrossEntropyLoss()

    # åˆ›å»ºå‚æ•°è°ƒæ•´å™¨
    optimizer = torch.optim.Adam(model.parameters())

    # è®°å½•è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    training_accuracy_history = []
    validating_accuracy_history = []

    # è®°å½•æœ€é«˜çš„éªŒè¯é›†æ­£ç¡®ç‡
    validating_accuracy_highest = -1
    validating_accuracy_highest_epoch = 0

    # è¯»å–æ‰¹æ¬¡çš„å·¥å…·å‡½æ•°
    def read_batches(base_path):
        for batch in itertools.count():
            path = f"{base_path}.{batch}.pt"
            if not os.path.isfile(path):
                break
            yield [ t.to(device) for t in load_tensor(path) ]

    # è®¡ç®—æ­£ç¡®ç‡çš„å·¥å…·å‡½æ•°ï¼Œæ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬çš„æ­£ç¡®ç‡åˆ†åˆ«è®¡ç®—å†å¹³å‡
    def calc_accuracy(actual, predicted):
        predicted = torch.max(predicted, 1).indices
        acc_positive = ((actual > 0.5) & (predicted > 0.5)).sum().item() / ((actual > 0.5).sum().item() + 0.00001)
        acc_negative = ((actual <= 0.5) & (predicted <= 0.5)).sum().item() / ((actual <= 0.5).sum().item() + 0.00001)
        acc = (acc_positive + acc_negative) / 2
        return acc
 
    # åˆ’åˆ†è¾“å…¥å’Œè¾“å‡ºçš„å·¥å…·å‡½æ•°
    def split_batch_xy(batch, begin=None, end=None):
        # shape = batch_size, channels, width, height
        batch_x = batch[0][begin:end]
        # shape = batch_size, num_labels
        batch_y = batch[1][begin:end]
        return batch_x, batch_y

    # å¼€å§‹è®­ç»ƒè¿‡ç¨‹
    for epoch in range(1, 10000):
        print(f"epoch: {epoch}")

        # æ ¹æ®è®­ç»ƒé›†è®­ç»ƒå¹¶ä¿®æ”¹å‚æ•°
        model.train()
        training_accuracy_list = []
        for batch_index, batch in enumerate(read_batches("data/training_set")):
            # åˆ‡åˆ†å°æ‰¹æ¬¡ï¼Œæœ‰åŠ©äºæ³›åŒ–æ¨¡å‹
            training_batch_accuracy_list = []
            for index in range(0, batch[0].shape[0], 100):
                # åˆ’åˆ†è¾“å…¥å’Œè¾“å‡º
                batch_x, batch_y = split_batch_xy(batch, index, index+100)
                # è®¡ç®—é¢„æµ‹å€¼
                predicted = model(batch_x)
                # è®¡ç®—æŸå¤±
                loss = loss_function(predicted, batch_y)
                # ä»æŸå¤±è‡ªåŠ¨å¾®åˆ†æ±‚å¯¼å‡½æ•°å€¼
                loss.backward()
                # ä½¿ç”¨å‚æ•°è°ƒæ•´å™¨è°ƒæ•´å‚æ•°
                optimizer.step()
                # æ¸…ç©ºå¯¼å‡½æ•°å€¼
                optimizer.zero_grad()
                # è®°å½•è¿™ä¸€ä¸ªæ‰¹æ¬¡çš„æ­£ç¡®ç‡ï¼Œtorch.no_grad ä»£è¡¨ä¸´æ—¶ç¦ç”¨è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½
                with torch.no_grad():
                    training_batch_accuracy_list.append(calc_accuracy(batch_y, predicted))
            # è¾“å‡ºæ‰¹æ¬¡æ­£ç¡®ç‡
            training_batch_accuracy = sum(training_batch_accuracy_list) / len(training_batch_accuracy_list)
            training_accuracy_list.append(training_batch_accuracy)
            print(f"epoch: {epoch}, batch: {batch_index}: batch accuracy: {training_batch_accuracy}")
        training_accuracy = sum(training_accuracy_list) / len(training_accuracy_list)
        training_accuracy_history.append(training_accuracy)
        print(f"training accuracy: {training_accuracy}")

        # æ£€æŸ¥éªŒè¯é›†
        model.eval()
        validating_accuracy_list = []
        for batch in read_batches("data/validating_set"):
            batch_x, batch_y = split_batch_xy(batch)
            predicted = model(batch_x)
            validating_accuracy_list.append(calc_accuracy(batch_y, predicted))
        validating_accuracy = sum(validating_accuracy_list) / len(validating_accuracy_list)
        validating_accuracy_history.append(validating_accuracy)
        print(f"validating accuracy: {validating_accuracy}")

        # è®°å½•æœ€é«˜çš„éªŒè¯é›†æ­£ç¡®ç‡ä¸å½“æ—¶çš„æ¨¡å‹çŠ¶æ€ï¼Œåˆ¤æ–­æ˜¯å¦åœ¨ 20 æ¬¡è®­ç»ƒåä»ç„¶æ²¡æœ‰åˆ·æ–°è®°å½•
        if validating_accuracy > validating_accuracy_highest:
            validating_accuracy_highest = validating_accuracy
            validating_accuracy_highest_epoch = epoch
            save_tensor(model.state_dict(), "model.pt")
            print("highest validating accuracy updated")
        elif epoch - validating_accuracy_highest_epoch > 20:
            # åœ¨ 20 æ¬¡è®­ç»ƒåä»ç„¶æ²¡æœ‰åˆ·æ–°è®°å½•ï¼Œç»“æŸè®­ç»ƒ
            print("stop training because highest validating accuracy not updated in 20 epoches")
            break

    # ä½¿ç”¨è¾¾åˆ°æœ€é«˜æ­£ç¡®ç‡æ—¶çš„æ¨¡å‹çŠ¶æ€
    print(f"highest validating accuracy: {validating_accuracy_highest}",
        f"from epoch {validating_accuracy_highest_epoch}")
    model.load_state_dict(load_tensor("model.pt"))

    # æ£€æŸ¥æµ‹è¯•é›†
    testing_accuracy_list = []
    for batch in read_batches("data/testing_set"):
        batch_x, batch_y = split_batch_xy(batch)
        predicted = model(batch_x)
        testing_accuracy_list.append(calc_accuracy(batch_y, predicted))
    testing_accuracy = sum(testing_accuracy_list) / len(testing_accuracy_list)
    print(f"testing accuracy: {testing_accuracy}")

    # æ˜¾ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    pyplot.plot(training_accuracy_history, label="training")
    pyplot.plot(validating_accuracy_history, label="validing")
    pyplot.ylim(0, 1)
    pyplot.legend()
    pyplot.show()

def eval_model():
    """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ŒåŠ è½½è®­ç»ƒå¥½çš„çŠ¶æ€ï¼Œç„¶ååˆ‡æ¢åˆ°éªŒè¯æ¨¡å¼
    model = MyModel().to(device)
    model.load_state_dict(load_tensor("model.pt"))
    model.eval()

    # è¯¢é—®å›¾ç‰‡è·¯å¾„ï¼Œå¹¶æ˜¾ç¤ºæ‰€æœ‰å¯èƒ½æ˜¯äººè„¸çš„åŒºåŸŸ
    while True:
        try:
            # é€‰å–å¯èƒ½å‡ºç°å¯¹è±¡çš„åŒºåŸŸä¸€è§ˆ
            image_path = input("Image path: ")
            if not image_path:
                continue
            img = cv2.imread(image_path)
            candidate_boxes = selective_search(img)
            # æ„å»ºè¾“å…¥
            image_tensors = []
            for candidate_box in candidate_boxes:
                x, y, w, h = candidate_box
                child_img = img[y:y+h, x:x+w].copy()
                image_tensors.append(image_to_tensor(child_img))
            tensor_in = torch.stack(image_tensors).to(device)
            # é¢„æµ‹è¾“å‡º
            tensor_out = model(tensor_in)
            # ä½¿ç”¨ softmax è®¡ç®—æ˜¯äººè„¸çš„æ¦‚ç‡
            tensor_out = nn.functional.softmax(tensor_out, dim=1)
            tensor_out = tensor_out[:,1].resize(tensor_out.shape[0])
            # åˆ¤æ–­æ¦‚ç‡å¤§äº 99% çš„æ˜¯äººè„¸ï¼Œæ·»åŠ è¾¹æ¡†åˆ°å›¾ç‰‡å¹¶ä¿å­˜
            img_output = img.copy()
            indices = torch.where(tensor_out > 0.99)[0]
            result_boxes = []
            result_boxes_all = []
            for index in indices:
                box = candidate_boxes[index]
                for exists_box in result_boxes_all:
                    # å¦‚æœå’Œç°å­˜æ‰¾åˆ°çš„åŒºåŸŸé‡å åº¦å¤§äº 30% åˆ™è·³è¿‡
                    if calc_iou(exists_box, box) > 0.30:
                        break
                else:
                    result_boxes.append(box)
                result_boxes_all.append(box)
            for box in result_boxes:
                x, y, w, h = box
                print(x, y, w, h)
                cv2.rectangle(img_output, (x, y), (x+w, y+h), (0, 0, 0xff), 1)
            cv2.imwrite("img_output.png", img_output)
            print("saved to img_output.png")
            print()
        except Exception as e:
            print("error:", e)

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print(f"Please run: {sys.argv[0]} prepare|train|eval")
        exit()

    # ç»™éšæœºæ•°ç”Ÿæˆå™¨åˆ†é…ä¸€ä¸ªåˆå§‹å€¼ï¼Œä½¿å¾—æ¯æ¬¡è¿è¡Œéƒ½å¯ä»¥ç”Ÿæˆç›¸åŒçš„éšæœºæ•°
    # è¿™æ˜¯ä¸ºäº†è®©è¿‡ç¨‹å¯é‡ç°ï¼Œä½ ä¹Ÿå¯ä»¥é€‰æ‹©ä¸è¿™æ ·åš
    random.seed(0)
    torch.random.manual_seed(0)

    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ“ä½œ
    operation = sys.argv[1]
    if operation == "prepare":
        prepare()
    elif operation == "train":
        train()
    elif operation == "eval":
        eval_model()
    else:
        raise ValueError(f"Unsupported operation: {operation}")

if __name__ == "__main__":
    main()
```

å’Œä¹‹å‰æ–‡ç« ç»™å‡ºçš„ä»£ç ä¾‹å­ä¸€æ ·ï¼Œè¿™ä»½ä»£ç ä¹Ÿåˆ†ä¸ºäº† prepare, train, eval ä¸‰ä¸ªéƒ¨åˆ†ï¼Œå…¶ä¸­ prepare éƒ¨åˆ†è´Ÿè´£é€‰å–åŒºåŸŸï¼Œæå–æ­£æ ·æœ¬ (åŒ…å«äººè„¸çš„åŒºåŸŸ) å’Œè´Ÿæ ·æœ¬ (ä¸åŒ…å«äººè„¸çš„åŒºåŸŸ) çš„å­å›¾ç‰‡ï¼›train ä½¿ç”¨æ™®é€šçš„ resnet æ¨¡å‹å­¦ä¹ å­å›¾ç‰‡ï¼›eval é’ˆå¯¹ç»™å‡ºçš„å›¾ç‰‡é€‰å–åŒºåŸŸå¹¶è¯†åˆ«æ‰€æœ‰åŒºåŸŸä¸­æ˜¯å¦åŒ…å«äººè„¸ã€‚

é™¤äº†é€‰å–åŒºåŸŸå’Œæå–å­å›¾ç‰‡çš„å¤„ç†ä»¥å¤–ï¼ŒåŸºæœ¬ä¸Šå’Œä¹‹å‰ä»‹ç»çš„ CNN æ¨¡å‹ä¸€æ ·å§ğŸ¥³ã€‚

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä»¥åï¼š

``` text
python3 example.py prepare
python3 example.py train
```

çš„æœ€ç»ˆè¾“å‡ºå¦‚ä¸‹ï¼š

``` text
epoch: 101, batch: 106: batch accuracy: 0.9999996838862198
epoch: 101, batch: 107: batch accuracy: 0.999218446914751
epoch: 101, batch: 108: batch accuracy: 0.9999996211125055
training accuracy: 0.999441394076678
validating accuracy: 0.9687856357743619
stop training because highest validating accuracy not updated in 20 epoches
highest validating accuracy: 0.9766918253771755 from epoch 80
testing accuracy: 0.9729761086851993
```

è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–å¦‚ä¸‹ï¼š

![08](./08.png)

æ­£ç¡®ç‡çœ‹èµ·æ¥å¾ˆé«˜ï¼Œä½†è¿™åªæ˜¯é’ˆå¯¹é€‰å–åçš„åŒºåŸŸåˆ¤æ–­çš„æ­£ç¡®ç‡ï¼Œå› ä¸ºé€‰å–ç®—æ³•æ•ˆæœæ¯”è¾ƒä¸€èˆ¬å¹¶ä¸”æ ·æœ¬æ•°é‡æ¯”è¾ƒå°‘ï¼Œæ‰€ä»¥æœ€ç»ˆæ•ˆæœä¸èƒ½è¯´ä»¤äººæ»¡æ„ğŸ˜•ã€‚

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå†è¾“å…¥å›¾ç‰‡è·¯å¾„å¯ä»¥ä½¿ç”¨å­¦ä¹ å¥½çš„æ¨¡å‹è¯†åˆ«å›¾ç‰‡ï¼š

``` text
python3 example.py eval
```

ä»¥ä¸‹æ˜¯éƒ¨åˆ†è¯†åˆ«ç»“æœï¼š

![09](./09.png)

![10](./10.png)

ç²¾åº¦ä¸€èˆ¬èˆ¬ğŸ˜•ã€‚

## Fast-RCNN

RCNN æ…¢çš„åŸå› ä¸»è¦æ˜¯å› ä¸ºè¯†åˆ«å‡ åƒä¸ªå­å›¾ç‰‡çš„è®¡ç®—é‡éå¸¸åºå¤§ï¼Œç‰¹åˆ«æ˜¯è¿™å‡ åƒä¸ªå­å›¾ç‰‡çš„èŒƒå›´å¾ˆå¤šæ˜¯é‡åˆçš„ï¼Œå¯¼è‡´äº†å¾ˆå¤šé‡å¤çš„è®¡ç®—ã€‚Fast-RCNN ç€é‡æ”¹å–„äº†è¿™ä¸€éƒ¨åˆ†ï¼Œé¦–å…ˆä¼šé’ˆå¯¹æ•´å¼ å›¾ç‰‡ç”Ÿæˆä¸€ä¸ªä¸å›¾ç‰‡é•¿å®½ç›¸åŒ (æˆ–è€…ç­‰æ¯”ä¾‹ç¼©æ”¾) çš„ç‰¹å¾æ•°æ®ï¼Œç„¶åå†æ ¹æ®å¯èƒ½åŒ…å«å¯¹è±¡çš„åŒºåŸŸæˆªå–ç‰¹å¾æ•°æ®ï¼Œç„¶åå†æ ¹æ®æˆªå–åçš„å­ç‰¹å¾æ•°æ®è¯†åˆ«åˆ†ç±»ã€‚RCNN ä¸ Fast-RCNN çš„åŒºåˆ«å¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![11](./11.png)

é—æ†¾çš„æ˜¯ Fast-RCNN åªæ˜¯æ”¹å–„äº†é€Ÿåº¦ï¼Œå¹¶ä¸ä¼šæ”¹å–„æ­£ç¡®ç‡ã€‚ä½†ä¸‹é¢ä»‹ç»çš„ä¾‹å­ä¼šå¼•å…¥ä¸€ä¸ªæ¯”è¾ƒé‡è¦çš„å¤„ç†ï¼Œå³è°ƒæ•´åŒºåŸŸèŒƒå›´ï¼Œå®ƒå¯ä»¥è®©æ¨¡å‹ç»™å‡ºçš„åŒºåŸŸæ›´æ¥è¿‘å®é™…çš„åŒºåŸŸã€‚

ä»¥ä¸‹æ˜¯ Fast-RCNN æ¨¡å‹ä¸­çš„ä¸€äº›å¤„ç†ç»†èŠ‚ã€‚

### ç¼©æ”¾æ¥æºå›¾ç‰‡

åœ¨ RCNN ä¸­ï¼Œä¼ ç»™ CNN æ¨¡å‹çš„å›¾ç‰‡æ˜¯ç»è¿‡ç¼©æ”¾çš„å­å›¾ç‰‡ï¼Œè€Œåœ¨ Fast-RCNN ä¸­æˆ‘ä»¬éœ€è¦ä¼ åŸå›¾ç‰‡ç»™ CNN æ¨¡å‹ï¼Œé‚£ä¹ˆåŸå›¾ç‰‡ä¹Ÿéœ€è¦è¿›è¡Œç¼©æ”¾ã€‚ç¼©æ”¾ä½¿ç”¨çš„æ–¹æ³•æ˜¯å¡«å……æ³•ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![13](./13.png)

ç¼©æ”¾å›¾ç‰‡ä½¿ç”¨çš„ä»£ç å¦‚ä¸‹ (opencv ç‰ˆ)ï¼š

``` python
IMAGE_SIZE = (128, 88)

def calc_resize_parameters(sw, sh):
    """è®¡ç®—ç¼©æ”¾å›¾ç‰‡çš„å‚æ•°"""
    sw_new, sh_new = sw, sh
    dw, dh = IMAGE_SIZE
    pad_w, pad_h = 0, 0
    if sw / sh < dw / dh:
        sw_new = int(dw / dh * sh)
        pad_w = (sw_new - sw) // 2 # å¡«å……å·¦å³
    else:
        sh_new = int(dh / dw * sw)
        pad_h = (sh_new - sh) // 2 # å¡«å……ä¸Šä¸‹
    return sw_new, sh_new, pad_w, pad_h

def resize_image(img):
    """ç¼©æ”¾ opencv å›¾ç‰‡ï¼Œæ¯”ä¾‹ä¸ä¸€è‡´æ—¶å¡«å……"""
    sh, sw, _ = img.shape
    sw_new, sh_new, pad_w, pad_h = calc_resize_parameters(sw, sh)
    img = cv2.copyMakeBorder(img, pad_h, pad_h, pad_w, pad_w, cv2.BORDER_CONSTANT, (0, 0, 0))
    img = cv2.resize(img, dsize=IMAGE_SIZE)
    return img
```

ç¼©æ”¾å›¾ç‰‡ååŒºåŸŸçš„åæ ‡ä¹Ÿéœ€è¦è½¬æ¢ï¼Œè½¬æ¢çš„ä»£ç å¦‚ä¸‹ (éƒ½æ˜¯æ¯ç‡¥çš„ä»£ç ğŸ¤’)ï¼š

``` python
IMAGE_SIZE = (128, 88)

def map_box_to_resized_image(box, sw, sh):
    """æŠŠåŸå§‹åŒºåŸŸè½¬æ¢åˆ°ç¼©æ”¾åçš„å›¾ç‰‡å¯¹åº”çš„åŒºåŸŸ"""
    x, y, w, h = box
    sw_new, sh_new, pad_w, pad_h = calc_resize_parameters(sw, sh)
    scale = IMAGE_SIZE[0] / sw_new
    x = int((x + pad_w) * scale)
    y = int((y + pad_h) * scale)
    w = int(w * scale)
    h = int(h * scale)
    if x + w > IMAGE_SIZE[0] or y + h > IMAGE_SIZE[1] or w == 0 or h == 0:
        return 0, 0, 0, 0
    return x, y, w, h

def map_box_to_original_image(box, sw, sh):
    """æŠŠç¼©æ”¾åå›¾ç‰‡å¯¹åº”çš„åŒºåŸŸè½¬æ¢åˆ°ç¼©æ”¾å‰çš„åŸå§‹åŒºåŸŸ"""
    x, y, w, h = box
    sw_new, sh_new, pad_w, pad_h = calc_resize_parameters(sw, sh)
    scale = IMAGE_SIZE[0] / sw_new
    x = int(x / scale - pad_w)
    y = int(y / scale - pad_h)
    w = int(w / scale)
    h = int(h / scale)
    if x + w > sw or y + h > sh or x < 0 or y < 0 or w == 0 or h == 0:
        return 0, 0, 0, 0
    return x, y, w, h
```

### è®¡ç®—åŒºåŸŸç‰¹å¾

åœ¨å‰é¢çš„æ–‡ç« ä¸­æˆ‘ä»¬å·²ç»äº†è§£è¿‡ï¼ŒCNN æ¨¡å‹å¯ä»¥åˆ†ä¸ºå·ç§¯å±‚ï¼Œæ± åŒ–å±‚å’Œå…¨è¿æ¥å±‚ï¼Œå·ç§¯å±‚ï¼Œæ± åŒ–å±‚ç”¨äºæŠ½å–å›¾ç‰‡ä¸­å„ä¸ªåŒºåŸŸçš„ç‰¹å¾ï¼Œå…¨è¿æ¥å±‚ç”¨äºæŠŠç‰¹å¾æ‰å¹³åŒ–å¹¶äº¤ç»™çº¿æ€§æ¨¡å‹å¤„ç†ã€‚åœ¨ Fast-RCNN ä¸­ï¼Œæˆ‘ä»¬ä¸éœ€è¦ä½¿ç”¨æ•´å¼ å›¾ç‰‡çš„ç‰¹å¾ï¼Œåªéœ€è¦ä½¿ç”¨éƒ¨åˆ†åŒºåŸŸçš„ç‰¹å¾ï¼Œæ‰€ä»¥ Fast-RCNN ä½¿ç”¨çš„ CNN æ¨¡å‹åªéœ€è¦å·ç§¯å±‚å’Œæ± åŒ–å±‚ (éƒ¨åˆ†æ¨¡å‹æ± åŒ–å±‚å¯ä»¥çœç•¥)ï¼Œå·ç§¯å±‚è¾“å‡ºçš„é€šé“æ•°é‡é€šå¸¸ä¼šæ¯”å›¾ç‰‡åŸæœ‰çš„é€šé“æ•°é‡å¤šï¼Œå¹¶ä¸”é•¿å®½ä¼šæŒ‰åŸæ¥å›¾ç‰‡çš„é•¿å®½ç­‰æ¯”ä¾‹ç¼©å°ï¼Œä¾‹å¦‚åŸå›¾çš„å¤§å°æ˜¯ 3,256,256 çš„æ—¶å€™ï¼Œç»è¿‡å¤„ç†å¯èƒ½ä¼šè¾“å‡º 512,32,32ï¼Œä»£è¡¨æ¯ä¸ª 8x8 åƒç´ çš„åŒºåŸŸéƒ½å¯¹åº” 512 ä¸ªç‰¹å¾ã€‚

è¿™ç¯‡ç»™å‡ºçš„ Fast-RCN ä»£ç ä¸ºäº†æ˜“äºç†è§£ï¼Œä¼šè®© CNN æ¨¡å‹è¾“å‡ºå’ŒåŸå›¾ä¸€æ¨¡ä¸€æ ·çš„å¤§å°ï¼Œè¿™æ ·æŠ½å–åŒºåŸŸç‰¹å¾çš„æ—¶å€™åªéœ€è¦ä½¿ç”¨ `[]` æ“ä½œç¬¦å³å¯ã€‚

### æŠ½å–åŒºåŸŸç‰¹å¾ (ROI Pooling)

Fast-RCNN æ ¹æ®æ•´å¼ å›¾ç‰‡ç”Ÿæˆç‰¹å¾ä»¥åï¼Œä¸‹ä¸€æ­¥å°±æ˜¯æŠ½å–åŒºåŸŸç‰¹å¾ (Region of interest Pooling) äº†ï¼ŒæŠ½å–åŒºåŸŸç‰¹å¾ç®€å•çš„æ¥è¯´å°±æ˜¯æ ¹æ®åŒºåŸŸåœ¨å›¾ç‰‡ä¸­çš„ä½ç½®ï¼ŒæˆªåŒºåŸŸä¸­è¯¥ä½ç½®çš„æ•°æ®ï¼Œç„¶åå†ç¼©æ”¾åˆ°ç›¸åŒå¤§å°ï¼Œå¦‚ä¸‹å›¾æ‰€ç¤ºï¼š

![14](./14.png)

æŠ½å–åŒºåŸŸç‰¹å¾çš„å±‚åˆç§°ä¸º ROI å±‚ã€‚

å¦‚æœç‰¹å¾çš„é•¿å®½å’Œå›¾ç‰‡çš„é•¿å®½ç›¸åŒï¼Œé‚£ä¹ˆæˆªå–ç‰¹å¾åªéœ€è¦ç®€å•çš„ `[]` æ“ä½œï¼Œä½†å¦‚æœç‰¹å¾çš„é•¿å®½æ¯”å›¾ç‰‡çš„é•¿å®½è¦å°ï¼Œé‚£ä¹ˆå°±éœ€è¦ä½¿ç”¨è¿‘é‚»æ’å€¼æ³• (Nearest Neighbor Interpolation) æˆ–è€…åŒçº¿æ’å€¼æ³• (Bilinear Interpolation) è¿›è¡Œæˆªå–ï¼Œä½¿ç”¨åŒçº¿æ’å€¼æ³•è¿›è¡Œæˆªå–çš„ ROI å±‚åˆç§°ä½œ ROI Alignã€‚æˆªå–ä»¥åçš„ç¼©æ”¾å¯ä»¥ä½¿ç”¨ MaxPoolï¼Œè¿‘é‚»æ’å€¼æ³•æˆ–åŒçº¿æ’å€¼æ³•ç­‰ç®—æ³•ã€‚

æƒ³æ›´å¥½çš„ç†è§£ ROI Align ä¸åŒçº¿æ’å€¼æ³•å¯ä»¥å‚è€ƒ[è¿™ç¯‡æ–‡ç« ](https://chao-ji.github.io/jekyll/update/2018/07/20/ROIAlign.html)ã€‚

### è°ƒæ•´åŒºåŸŸèŒƒå›´

åœ¨å‰é¢å·²ç»æåˆ°è¿‡ï¼Œä½¿ç”¨é€‰æ‹©æœç´¢æ³•ç­‰ç®—æ³•é€‰å–å‡ºæ¥çš„åŒºåŸŸä¸å¯¹è±¡å®é™…æ‰€åœ¨çš„åŒºåŸŸå¯èƒ½æœ‰ä¸€å®šåå·®ï¼Œè¿™ä¸ªåå·®æ˜¯å¯ä»¥é€šè¿‡æ¨¡å‹æ¥è°ƒæ•´çš„ã€‚ä¸¾ä¸ªç®€å•çš„ä¾‹å­ï¼Œå¦‚æœåŒºåŸŸå†…æœ‰è„¸çš„å·¦åŠéƒ¨åˆ†ï¼Œé‚£ä¹ˆæ¨¡å‹åœ¨ç»è¿‡å­¦ä¹ ååº”è¯¥å¯ä»¥åˆ¤æ–­å‡ºåŒºåŸŸåº”è¯¥å‘å³æ‰©å±•ä¸€äº›ã€‚

åŒºåŸŸè°ƒæ•´å¯ä»¥åˆ†ä¸ºå››ä¸ªå‚æ•°ï¼š

- å¯¹å·¦ä¸Šè§’ x åæ ‡çš„è°ƒæ•´
- å¯¹å·¦ä¸Šè§’ y åæ ‡çš„è°ƒæ•´
- å¯¹é•¿åº¦çš„è°ƒæ•´
- å¯¹å®½åº¦çš„è°ƒæ•´

å› ä¸ºåæ ‡å’Œé•¿å®½çš„å€¼å¤§å°ä¸ä¸€å®šï¼Œä¾‹å¦‚åŒæ ·æ˜¯è„¸çš„å·¦åŠéƒ¨åˆ†ï¼Œå‡ºç°åœ¨å›¾ç‰‡çš„å·¦ä¸Šè§’å’Œå›¾ç‰‡çš„å³ä¸‹è§’å°±ä¼šè®© x y åæ ‡ä¸ä¸€æ ·ï¼Œå¦‚æœè¿œè¿‘ä¸åŒé‚£ä¹ˆé•¿å®½ä¹Ÿä¼šä¸ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦æŠŠè°ƒæ•´é‡ä½œæ ‡å‡†åŒ–ï¼Œæ ‡å‡†åŒ–çš„å…¬å¼å¦‚ä¸‹ï¼š

- x1, y1, w1, h1 = å€™é€‰åŒºåŸŸ
- x2, y2, w2, h2 = çœŸå®åŒºåŸŸ
- x åç§» = (x2 - x1) / w1
- y åç§» = (y2 - y1) / h1
- w åç§» = log(w2 / w1)
- h åç§» = log(h2 / h1)

ç»è¿‡æ ‡å‡†åŒ–åï¼Œåç§»çš„å€¼å°±ä¼šä½œä¸ºæ¯”ä¾‹è€Œä¸æ˜¯ç»å¯¹å€¼ï¼Œä¸ä¼šå—å…·ä½“åæ ‡å’Œé•¿å®½çš„å½±å“ã€‚æ­¤å¤–ï¼Œå…¬å¼ä¸­ä½¿ç”¨ log æ˜¯ä¸ºäº†å‡å°‘åç§»çš„å¢å¹…ï¼Œä½¿å¾—åç§»æ¯”è¾ƒå¤§çš„æ—¶å€™æ¨¡å‹ä»ç„¶å¯ä»¥è¾¾åˆ°æ¯”è¾ƒå¥½çš„å­¦ä¹ æ•ˆæœã€‚

è®¡ç®—åŒºåŸŸè°ƒæ•´åç§»å’Œæ ¹æ®åç§»è°ƒæ•´åŒºåŸŸçš„ä»£ç å¦‚ä¸‹ï¼š

``` python
def calc_box_offset(candidate_box, true_box):
    """è®¡ç®—å€™é€‰åŒºåŸŸä¸å®é™…åŒºåŸŸçš„åç§»å€¼"""
    x1, y1, w1, h1 = candidate_box
    x2, y2, w2, h2 = true_box
    x_offset = (x2 - x1) / w1
    y_offset = (y2 - y1) / h1
    w_offset = math.log(w2 / w1)
    h_offset = math.log(h2 / h1)
    return (x_offset, y_offset, w_offset, h_offset)

def adjust_box_by_offset(candidate_box, offset):
    """æ ¹æ®åç§»å€¼è°ƒæ•´å€™é€‰åŒºåŸŸ"""
    x1, y1, w1, h1 = candidate_box
    x_offset, y_offset, w_offset, h_offset = offset
    x2 = w1 * x_offset + x1
    y2 = h1 * y_offset + y1
    w2 = math.exp(w_offset) * w1
    h2 = math.exp(h_offset) * h1
    return (x2, y2, w2, h2)
```

### è®¡ç®—æŸå¤±

Fast-RCNN æ¨¡å‹ä¼šé’ˆå¯¹å„ä¸ªåŒºåŸŸè¾“å‡ºä¸¤ä¸ªç»“æœï¼Œç¬¬ä¸€ä¸ªæ˜¯åŒºåŸŸå¯¹åº”çš„æ ‡ç­¾ (äººè„¸ï¼Œéäººè„¸)ï¼Œç¬¬äºŒä¸ªæ˜¯ä¸Šé¢æåˆ°çš„åŒºåŸŸåç§»ï¼Œè°ƒæ•´å‚æ•°çš„æ—¶å€™ä¹Ÿéœ€è¦åŒæ—¶æ ¹æ®è¿™ä¸¤ä¸ªç»“æœè°ƒæ•´ã€‚å®ç°åŒæ—¶è°ƒæ•´å¤šä¸ªç»“æœå¯ä»¥æŠŠæŸå¤±ç›¸åŠ èµ·æ¥å†è®¡ç®—å„ä¸ªå‚æ•°çš„å¯¼å‡½æ•°å€¼ï¼š

``` text
å„ä¸ªåŒºåŸŸçš„ç‰¹å¾ = ROIå±‚(CNNæ¨¡å‹(å›¾ç‰‡æ•°æ®))

è®¡ç®—æ ‡ç­¾çš„çº¿æ€§æ¨¡å‹(å„ä¸ªåŒºåŸŸçš„ç‰¹å¾) - çœŸå®æ ‡ç­¾ = æ ‡ç­¾æŸå¤±
è®¡ç®—åç§»çš„çº¿æ€§æ¨¡å‹(å„ä¸ªåŒºåŸŸçš„ç‰¹å¾) - çœŸå®åç§» = åç§»æŸå¤±

æŸå¤± = æ ‡ç­¾æŸå¤± + åç§»æŸå¤±
```

æœ‰ä¸€ä¸ªéœ€è¦æ³¨æ„çš„åœ°æ–¹æ˜¯ï¼Œåœ¨è¿™ä¸ªä¾‹å­é‡Œè®¡ç®—æ ‡ç­¾æŸå¤±éœ€è¦åˆ†åˆ«æ ¹æ®æ­£è´Ÿæ ·æœ¬è®¡ç®—ï¼Œå¦åˆ™æ¨¡å‹åœ¨ç»è¿‡è°ƒæ•´ä»¥ååªä¼šè¾“å‡ºè´Ÿç»“æœã€‚è¿™æ˜¯å› ä¸ºçº¿æ€§æ¨¡å‹è®¡ç®—æŠ½å–å‡ºæ¥çš„ç‰¹å¾æ—¶æœ‰å¯èƒ½è¾“å‡ºæ­£ (äººè„¸)ï¼Œä¹Ÿæœ‰å¯èƒ½è¾“å‡ºè´Ÿ (éäººè„¸)ï¼Œè€Œ ROI å±‚æŠ½å–çš„ç‰¹å¾å¾ˆå¤šæ˜¯é‡åˆçš„ï¼Œä¹Ÿå°±æ˜¯æ¥æºç›¸åŒï¼Œå½“è´Ÿæ ·æœ¬æ¯”æ­£æ ·æœ¬è¦å¤šçš„æ—¶å€™ï¼Œç»“æœçš„æ–¹å‘å°±ä¼šæ›´åå‘äºè´Ÿï¼Œè¿™æ ·æ¯æ¬¡è°ƒæ•´å‚æ•°çš„æ—¶å€™éƒ½ä¼šå‘è¾“å‡ºè´Ÿçš„æ–¹å‘è°ƒæ•´ã€‚å¦‚æœæŠŠæŸå¤±åˆ†å¼€è®¡ç®—ï¼Œé‚£ä¹ˆä¸é‡åˆçš„ç‰¹å¾å¯ä»¥åˆ†åˆ«å‘è¾“å‡ºæ­£è´Ÿçš„æ–¹å‘è°ƒæ•´ï¼Œä»è€Œè¾¾åˆ°å­¦ä¹ çš„æ•ˆæœã€‚

æ­¤å¤–ï¼Œåç§»æŸå¤±åªåº”è¯¥æ ¹æ®æ­£æ ·æœ¬è®¡ç®—ï¼Œè´Ÿæ ·æœ¬æ²¡æœ‰å¿…è¦å­¦ä¹ åç§»ã€‚

æœ€ç»ˆçš„æŸå¤±è®¡ç®—å¤„ç†å¦‚ä¸‹ï¼š

``` text
å„ä¸ªåŒºåŸŸçš„ç‰¹å¾ = ROIå±‚(CNNæ¨¡å‹(å›¾ç‰‡æ•°æ®))

è®¡ç®—æ ‡ç­¾çš„çº¿æ€§æ¨¡å‹(å„ä¸ªåŒºåŸŸçš„ç‰¹å¾)[æ­£æ ·æœ¬] - çœŸå®æ ‡ç­¾[æ­£æ ·æœ¬] = æ­£æ ·æœ¬æ ‡ç­¾æŸå¤±
è®¡ç®—æ ‡ç­¾çš„çº¿æ€§æ¨¡å‹(å„ä¸ªåŒºåŸŸçš„ç‰¹å¾)[è´Ÿæ ·æœ¬] - çœŸå®æ ‡ç­¾[è´Ÿæ ·æœ¬] = è´Ÿæ ·æœ¬æ ‡ç­¾æŸå¤±
è®¡ç®—åç§»çš„çº¿æ€§æ¨¡å‹(å„ä¸ªåŒºåŸŸçš„ç‰¹å¾)[æ­£æ ·æœ¬] - çœŸå®åç§»[æ­£æ ·æœ¬] = æ­£æ ·æœ¬åç§»æŸå¤±

æŸå¤± = æ­£æ ·æœ¬æ ‡ç­¾æŸå¤± + è´Ÿæ ·æœ¬æ ‡ç­¾æŸå¤± + æ­£æ ·æœ¬åç§»æŸå¤±
```

### åˆå¹¶ç»“æœåŒºåŸŸ

å› ä¸ºé€‰å–åŒºåŸŸçš„ç®—æ³•æœ¬æ¥å°±ä¼šè¿”å›å¾ˆå¤šé‡åˆçš„åŒºåŸŸï¼Œå¯èƒ½ä¼šæœ‰æœ‰å¥½å‡ ä¸ªåŒºåŸŸåŒæ—¶å’ŒçœŸå®åŒºåŸŸé‡å ç‡å¤§äºä¸€å®šå€¼ (70%)ï¼Œå¯¼è‡´è¿™å‡ ä¸ªåŒºåŸŸéƒ½ä¼šè¢«è®¤ä¸ºæ˜¯åŒ…å«å¯¹è±¡çš„åŒºåŸŸï¼š

![12](./12.png)

æ¨¡å‹ç»è¿‡å­¦ä¹ åï¼Œé’ˆå¯¹å›¾ç‰‡é¢„æµ‹å¾—å‡ºç»“æœæ—¶ä¹Ÿæœ‰å¯èƒ½è¿”å›è¿™æ ·çš„é‡åˆåŒºåŸŸï¼Œåˆå¹¶è¿™æ ·çš„åŒºåŸŸæœ‰å‡ ç§æ–¹æ³•ï¼š

- ä½¿ç”¨æœ€å·¦ï¼Œæœ€å³ï¼Œæœ€ä¸Šï¼Œæˆ–è€…æœ€ä¸‹çš„åŒºåŸŸ
- ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒºåŸŸ (åŒºåŸŸé€‰å–ç®—æ³•ä¼šæŒ‰å‡ºç°å¯¹è±¡çš„å¯èƒ½æ€§æ’åº)
- ç»“åˆæ‰€æœ‰é‡åˆçš„åŒºåŸŸ (å¦‚æœåŒºåŸŸè°ƒæ•´æ•ˆæœä¸è¡Œï¼Œåˆ™å¯èƒ½å‡ºç°ç»“æœåŒºåŸŸæ¯”çœŸå®åŒºåŸŸå¤§å¾ˆå¤šçš„é—®é¢˜)

ä¸Šé¢ç»™å‡ºçš„ RCNN ä»£ç ä¾‹å­å·²ç»ä½¿ç”¨ç¬¬äºŒä¸ªæ–¹æ³•åˆå¹¶ç»“æœåŒºåŸŸï¼Œä¸‹é¢ç»™å‡ºçš„ä¾‹å­ä¹Ÿä¼šä½¿ç”¨åŒæ ·çš„æ–¹æ³•ã€‚ä½†ä¸‹ä¸€ç¯‡æ–‡ç« çš„ Faster-RCNN åˆ™ä¼šä½¿ç”¨ç¬¬ä¸‰ä¸ªæ–¹æ³•ï¼Œå› ä¸º Faster-RCNN çš„åŒºåŸŸè°ƒæ•´æ•ˆæœç›¸å¯¹æ¯”è¾ƒå¥½ã€‚

### åŸå§‹è®ºæ–‡

å¦‚æœä½ æƒ³çœ‹ Fast-RCNN çš„åŸå§‹è®ºæ–‡å¯ä»¥åˆ°ä»¥ä¸‹çš„åœ°å€ï¼š

https://arxiv.org/pdf/1504.08083.pdf

## ä½¿ç”¨ Fast-RCNN è¯†åˆ«å›¾ç‰‡ä¸­çš„äººè„¸

ä»£ç æ—¶é—´åˆ°äº†ğŸ˜±ï¼Œè¿™ä»½ä»£ç ä¼šä½¿ç”¨ Fast-RCNN æ¨¡å‹æ¥å›¾ç‰‡ä¸­çš„äººè„¸ï¼Œä½¿ç”¨çš„æ•°æ®é›†å’Œå‰é¢çš„ä¾‹å­ä¸€æ ·ã€‚

``` python
import os
import sys
import torch
import gzip
import itertools
import random
import numpy
import math
import pandas
import cv2
from torch import nn
from matplotlib import pyplot
from collections import defaultdict

# ç¼©æ”¾å›¾ç‰‡çš„å¤§å°
IMAGE_SIZE = (256, 256)
# åˆ†æç›®æ ‡çš„å›¾ç‰‡æ‰€åœ¨çš„æ–‡ä»¶å¤¹
IMAGE_DIR = "./784145_1347673_bundle_archive/train/image_data"
# å®šä¹‰å„ä¸ªå›¾ç‰‡ä¸­äººè„¸åŒºåŸŸçš„ CSV æ–‡ä»¶
BOX_CSV_PATH = "./784145_1347673_bundle_archive/train/bbox_train.csv"

# ç”¨äºå¯ç”¨ GPU æ”¯æŒ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class BasicBlock(nn.Module):
    """ResNet ä½¿ç”¨çš„åŸºç¡€å—"""
    expansion = 1 # å®šä¹‰è¿™ä¸ªå—çš„å®é™…å‡ºé€šé“æ˜¯ channels_out çš„å‡ å€ï¼Œè¿™é‡Œçš„å®ç°å›ºå®šæ˜¯ä¸€å€
    def __init__(self, channels_in, channels_out, stride):
        super().__init__()
        # ç”Ÿæˆ 3x3 çš„å·ç§¯å±‚
        # å¤„ç†é—´éš” stride = 1 æ—¶ï¼Œè¾“å‡ºçš„é•¿å®½ä¼šç­‰äºè¾“å…¥çš„é•¿å®½ï¼Œä¾‹å¦‚ (32-3+2)//1+1 == 32
        # å¤„ç†é—´éš” stride = 2 æ—¶ï¼Œè¾“å‡ºçš„é•¿å®½ä¼šç­‰äºè¾“å…¥çš„é•¿å®½çš„ä¸€åŠï¼Œä¾‹å¦‚ (32-3+2)//2+1 == 16
        # æ­¤å¤– resnet çš„ 3x3 å·ç§¯å±‚ä¸ä½¿ç”¨åç§»å€¼ bias
        self.conv1 = nn.Sequential(
            nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=stride, padding=1, bias=False),
            nn.BatchNorm2d(channels_out))
        # å†å®šä¹‰ä¸€ä¸ªè®©è¾“å‡ºå’Œè¾“å…¥ç»´åº¦ç›¸åŒçš„ 3x3 å·ç§¯å±‚
        self.conv2 = nn.Sequential(
            nn.Conv2d(channels_out, channels_out, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(channels_out))
        # è®©åŸå§‹è¾“å…¥å’Œè¾“å‡ºç›¸åŠ çš„æ—¶å€™ï¼Œéœ€è¦ç»´åº¦ä¸€è‡´ï¼Œå¦‚æœç»´åº¦ä¸ä¸€è‡´åˆ™éœ€è¦æ•´åˆ
        self.identity = nn.Sequential()
        if stride != 1 or channels_in != channels_out * self.expansion:
            self.identity = nn.Sequential(
                nn.Conv2d(channels_in, channels_out * self.expansion, kernel_size=1, stride=stride, bias=False),
                nn.BatchNorm2d(channels_out * self.expansion))

    def forward(self, x):
        # x => conv1 => relu => conv2 => + => relu
        # |                              ^
        # |==============================|
        tmp = self.conv1(x)
        tmp = nn.functional.relu(tmp, inplace=True)
        tmp = self.conv2(tmp)
        tmp += self.identity(x)
        y = nn.functional.relu(tmp, inplace=True)
        return y

class MyModel(nn.Module):
    """Fast-RCNN (åŸºäº ResNet-18 çš„å˜ç§)"""
    def __init__(self):
        super().__init__()
        # è®°å½•ä¸Šä¸€å±‚çš„å‡ºé€šé“æ•°é‡
        self.previous_channels_out = 4
        # æŠŠ 3 é€šé“è½¬æ¢åˆ° 4 é€šé“ï¼Œé•¿å®½ä¸å˜
        self.conv1 = nn.Sequential(
            nn.Conv2d(3, self.previous_channels_out, kernel_size=3, stride=1, padding=1, bias=False),
            nn.BatchNorm2d(self.previous_channels_out))
        # æŠ½å–å›¾ç‰‡å„ä¸ªåŒºåŸŸç‰¹å¾çš„ ResNet (é™¤å» AvgPool å’Œå…¨è¿æ¥å±‚)
        # å’ŒåŸå§‹çš„ Resnet ä¸ä¸€æ ·çš„æ˜¯è¾“å‡ºçš„é•¿å®½å’Œè¾“å…¥çš„é•¿å®½ä¼šç›¸ç­‰ï¼Œä»¥ä¾¿ ROI å±‚æŒ‰åŒºåŸŸæŠ½å–Rå¾
        # æ­¤å¤–ï¼Œä¸ºäº†å¯ä»¥è®©æ¨¡å‹è·‘åœ¨ 4GB æ˜¾å­˜ä¸Šï¼Œè¿™é‡Œå‡å°‘äº†æ¨¡å‹çš„é€šé“æ•°é‡
        self.layer1 = self._make_layer(BasicBlock, channels_out=4, num_blocks=2, stride=1)
        self.layer2 = self._make_layer(BasicBlock, channels_out=4, num_blocks=2, stride=1)
        self.layer3 = self._make_layer(BasicBlock, channels_out=8, num_blocks=2, stride=1)
        self.layer4 = self._make_layer(BasicBlock, channels_out=8, num_blocks=2, stride=1)
        # ROI å±‚æŠ½å–å„ä¸ªå­åŒºåŸŸç‰¹å¾åè½¬æ¢åˆ°å›ºå®šå¤§å°
        self.roi_pool = nn.AdaptiveMaxPool2d((5, 5))
        # è¾“å‡ºä¸¤ä¸ªåˆ†ç±» [éäººè„¸, äººè„¸]
        self.fc_labels_model = nn.Sequential(
            nn.Linear(8*5*5, 32),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(32, 2))
        # è®¡ç®—åŒºåŸŸåç§»ï¼Œåˆ†åˆ«è¾“å‡º x, y, w, h çš„åç§»
        self.fc_offsets_model = nn.Sequential(
            nn.Linear(8*5*5, 128),
            nn.ReLU(),
            nn.Dropout(0.1),
            nn.Linear(128, 4))

    def _make_layer(self, block_type, channels_out, num_blocks, stride):
        blocks = []
        # æ·»åŠ ç¬¬ä¸€ä¸ªå—
        blocks.append(block_type(self.previous_channels_out, channels_out, stride))
        self.previous_channels_out = channels_out * block_type.expansion
        # æ·»åŠ å‰©ä½™çš„å—ï¼Œå‰©ä½™çš„å—å›ºå®šå¤„ç†é—´éš”ä¸º 1ï¼Œä¸ä¼šæ”¹å˜é•¿å®½
        for _ in range(num_blocks-1):
            blocks.append(block_type(self.previous_channels_out, self.previous_channels_out, 1))
            self.previous_channels_out *= block_type.expansion
        return nn.Sequential(*blocks)

    def _roi_pooling(self, feature_mapping, roi_boxes):
        result = []
        for box in roi_boxes:
            image_index, x, y, w, h = map(int, box.tolist())
            feature_sub_region = feature_mapping[image_index][:,x:x+w,y:y+h]
            fixed_features = self.roi_pool(feature_sub_region).reshape(-1) # é¡ºé“æ‰å¹³åŒ–
            result.append(fixed_features)
        return torch.stack(result)

    def forward(self, x):
        images_tensor = x[0]
        candidate_boxes_tensor = x[1]
        # è½¬æ¢å‡ºé€šé“
        tmp = self.conv1(images_tensor)
        tmp = nn.functional.relu(tmp)
        # åº”ç”¨ ResNet çš„å„ä¸ªå±‚
        # ç»“æœç»´åº¦æ˜¯ B,32,W,H
        tmp = self.layer1(tmp)
        tmp = self.layer2(tmp)
        tmp = self.layer3(tmp)
        tmp = self.layer4(tmp)
        # ä½¿ç”¨ ROI å±‚æŠ½å–å„ä¸ªå­åŒºåŸŸçš„ç‰¹å¾å¹¶è½¬æ¢åˆ°å›ºå®šå¤§å°
        # ç»“æœç»´åº¦æ˜¯ B,32*9*9
        tmp = self._roi_pooling(tmp, candidate_boxes_tensor)
        # æ ¹æ®æŠ½å–å‡ºæ¥çš„å­åŒºåŸŸç‰¹å¾åˆ†åˆ«è®¡ç®—åˆ†ç±» (æ˜¯å¦äººè„¸) å’ŒåŒºåŸŸåç§»
        labels = self.fc_labels_model(tmp)
        offsets = self.fc_offsets_model(tmp)
        y = (labels, offsets)
        return y

def save_tensor(tensor, path):
    """ä¿å­˜ tensor å¯¹è±¡åˆ°æ–‡ä»¶"""
    torch.save(tensor, gzip.GzipFile(path, "wb"))

def load_tensor(path):
    """ä»æ–‡ä»¶è¯»å– tensor å¯¹è±¡"""
    return torch.load(gzip.GzipFile(path, "rb"))

def calc_resize_parameters(sw, sh):
    """è®¡ç®—ç¼©æ”¾å›¾ç‰‡çš„å‚æ•°"""
    sw_new, sh_new = sw, sh
    dw, dh = IMAGE_SIZE
    pad_w, pad_h = 0, 0
    if sw / sh < dw / dh:
        sw_new = int(dw / dh * sh)
        pad_w = (sw_new - sw) // 2 # å¡«å……å·¦å³
    else:
        sh_new = int(dh / dw * sw)
        pad_h = (sh_new - sh) // 2 # å¡«å……ä¸Šä¸‹
    return sw_new, sh_new, pad_w, pad_h

def resize_image(img):
    """ç¼©æ”¾ opencv å›¾ç‰‡ï¼Œæ¯”ä¾‹ä¸ä¸€è‡´æ—¶å¡«å……"""
    sh, sw, _ = img.shape
    sw_new, sh_new, pad_w, pad_h = calc_resize_parameters(sw, sh)
    img = cv2.copyMakeBorder(img, pad_h, pad_h, pad_w, pad_w, cv2.BORDER_CONSTANT, (0, 0, 0))
    img = cv2.resize(img, dsize=IMAGE_SIZE)
    return img

def image_to_tensor(img):
    """è½¬æ¢ opencv å›¾ç‰‡å¯¹è±¡åˆ° tensor å¯¹è±¡"""
    # æ³¨æ„ opencv æ˜¯ BGRï¼Œä½†å¯¹è®­ç»ƒæ²¡æœ‰å½±å“æ‰€ä»¥ä¸ç”¨è½¬ä¸º RGB
    arr = numpy.asarray(img)
    t = torch.from_numpy(arr)
    t = t.transpose(0, 2) # è½¬æ¢ç»´åº¦ H,W,C åˆ° C,W,H
    t = t / 255.0 # æ­£è§„åŒ–æ•°å€¼ä½¿å¾—èŒƒå›´åœ¨ 0 ~ 1
    return t

def map_box_to_resized_image(box, sw, sh):
    """æŠŠåŸå§‹åŒºåŸŸè½¬æ¢åˆ°ç¼©æ”¾åçš„å›¾ç‰‡å¯¹åº”çš„åŒºåŸŸ"""
    x, y, w, h = box
    sw_new, sh_new, pad_w, pad_h = calc_resize_parameters(sw, sh)
    scale = IMAGE_SIZE[0] / sw_new
    x = int((x + pad_w) * scale)
    y = int((y + pad_h) * scale)
    w = int(w * scale)
    h = int(h * scale)
    if x + w > IMAGE_SIZE[0] or y + h > IMAGE_SIZE[1] or w == 0 or h == 0:
        return 0, 0, 0, 0
    return x, y, w, h

def map_box_to_original_image(box, sw, sh):
    """æŠŠç¼©æ”¾åå›¾ç‰‡å¯¹åº”çš„åŒºåŸŸè½¬æ¢åˆ°ç¼©æ”¾å‰çš„åŸå§‹åŒºåŸŸ"""
    x, y, w, h = box
    sw_new, sh_new, pad_w, pad_h = calc_resize_parameters(sw, sh)
    scale = IMAGE_SIZE[0] / sw_new
    x = int(x / scale - pad_w)
    y = int(y / scale - pad_h)
    w = int(w / scale)
    h = int(h / scale)
    if x + w > sw or y + h > sh or x < 0 or y < 0 or w == 0 or h == 0:
        return 0, 0, 0, 0
    return x, y, w, h

def calc_iou(rect1, rect2):
    """è®¡ç®—ä¸¤ä¸ªåŒºåŸŸé‡å éƒ¨åˆ† / åˆå¹¶éƒ¨åˆ†çš„æ¯”ç‡ (intersection over union)"""
    x1, y1, w1, h1 = rect1
    x2, y2, w2, h2 = rect2
    xi = max(x1, x2)
    yi = max(y1, y2)
    wi = min(x1+w1, x2+w2) - xi
    hi = min(y1+h1, y2+h2) - yi
    if wi > 0 and hi > 0: # æœ‰é‡å éƒ¨åˆ†
        area_overlap = wi*hi
        area_all = w1*h1 + w2*h2 - area_overlap
        iou = area_overlap / area_all
    else: # æ²¡æœ‰é‡å éƒ¨åˆ†
        iou = 0
    return iou

def calc_box_offset(candidate_box, true_box):
    """è®¡ç®—å€™é€‰åŒºåŸŸä¸å®é™…åŒºåŸŸçš„åç§»å€¼"""
    # è¿™é‡Œè®¡ç®—å‡ºæ¥çš„åç§»å€¼åŸºäºæ¯”ä¾‹ï¼Œè€Œä¸å—å…·ä½“ä½ç½®å’Œå¤§å°å½±å“
    # w h ä½¿ç”¨ log æ˜¯ä¸ºäº†å‡å°‘è¿‡å¤§çš„å€¼çš„å½±å“
    x1, y1, w1, h1 = candidate_box
    x2, y2, w2, h2 = true_box
    x_offset = (x2 - x1) / w1
    y_offset = (y2 - y1) / h1
    w_offset = math.log(w2 / w1)
    h_offset = math.log(h2 / h1)
    return (x_offset, y_offset, w_offset, h_offset)

def adjust_box_by_offset(candidate_box, offset):
    """æ ¹æ®åç§»å€¼è°ƒæ•´å€™é€‰åŒºåŸŸ"""
    x1, y1, w1, h1 = candidate_box
    x_offset, y_offset, w_offset, h_offset = offset
    x2 = w1 * x_offset + x1
    y2 = h1 * y_offset + y1
    w2 = math.exp(w_offset) * w1
    h2 = math.exp(h_offset) * h1
    return (x2, y2, w2, h2)

def selective_search(img):
    """è®¡ç®— opencv å›¾ç‰‡ä¸­å¯èƒ½å‡ºç°å¯¹è±¡çš„åŒºåŸŸï¼Œåªè¿”å›å¤´ 2000 ä¸ªåŒºåŸŸ"""
    # ç®—æ³•å‚è€ƒ https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/
    s = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()
    s.setBaseImage(img)
    s.switchToSelectiveSearchFast()
    boxes = s.process()
    return boxes[:2000]

def prepare_save_batch(batch, image_tensors, image_candidate_boxes, image_labels, image_box_offsets):
    """å‡†å¤‡è®­ç»ƒ - ä¿å­˜å•ä¸ªæ‰¹æ¬¡çš„æ•°æ®"""
    # æŒ‰ç´¢å¼•å€¼åˆ—è¡¨ç”Ÿæˆè¾“å…¥å’Œè¾“å‡º tensor å¯¹è±¡çš„å‡½æ•°
    def split_dataset(indices):
        image_in = []
        candidate_boxes_in = []
        labels_out = []
        offsets_out = []
        for new_image_index, original_image_index in enumerate(indices):
            image_in.append(image_tensors[original_image_index])
            for box, label, offset in zip(image_candidate_boxes, image_labels, image_box_offsets):
                box_image_index, x, y, w, h = box
                if box_image_index == original_image_index:
                    candidate_boxes_in.append((new_image_index, x, y, w, h))
                    labels_out.append(label)
                    offsets_out.append(offset)
        # æ£€æŸ¥è®¡ç®—æ˜¯å¦æœ‰é—®é¢˜
        # for box, label in zip(candidate_boxes_in, labels_out):
        #    image_index, x, y, w, h = box
        #    child_img = image_in[image_index][:, x:x+w, y:y+h].transpose(0, 2) * 255
        #    cv2.imwrite(f"{image_index}_{x}_{y}_{w}_{h}_{label}.png", child_img.numpy())
        tensor_image_in = torch.stack(image_in) # ç»´åº¦: B,C,W,H
        tensor_candidate_boxes_in = torch.tensor(candidate_boxes_in, dtype=torch.float) # ç»´åº¦: N,5 (index, x, y, w, h)
        tensor_labels_out = torch.tensor(labels_out, dtype=torch.long) # ç»´åº¦: N
        tensor_box_offsets_out = torch.tensor(offsets_out, dtype=torch.float) # ç»´åº¦: N,4 (x_offset, y_offset, ..)
        return (tensor_image_in, tensor_candidate_boxes_in), (tensor_labels_out, tensor_box_offsets_out)

    # åˆ‡åˆ†è®­ç»ƒé›† (80%)ï¼ŒéªŒè¯é›† (10%) å’Œæµ‹è¯•é›† (10%)
    random_indices = torch.randperm(len(image_tensors))
    training_indices = random_indices[:int(len(random_indices)*0.8)]
    validating_indices = random_indices[int(len(random_indices)*0.8):int(len(random_indices)*0.9):]
    testing_indices = random_indices[int(len(random_indices)*0.9):]
    training_set = split_dataset(training_indices)
    validating_set = split_dataset(validating_indices)
    testing_set = split_dataset(testing_indices)

    # ä¿å­˜åˆ°ç¡¬ç›˜
    save_tensor(training_set, f"data/training_set.{batch}.pt")
    save_tensor(validating_set, f"data/validating_set.{batch}.pt")
    save_tensor(testing_set, f"data/testing_set.{batch}.pt")
    print(f"batch {batch} saved")

def prepare():
    """å‡†å¤‡è®­ç»ƒ"""
    # æ•°æ®é›†è½¬æ¢åˆ° tensor ä»¥åä¼šä¿å­˜åœ¨ data æ–‡ä»¶å¤¹ä¸‹
    if not os.path.isdir("data"):
        os.makedirs("data")

    # åŠ è½½ csv æ–‡ä»¶ï¼Œæ„å»ºå›¾ç‰‡åˆ°åŒºåŸŸåˆ—è¡¨çš„ç´¢å¼• { å›¾ç‰‡å: [ åŒºåŸŸ, åŒºåŸŸ, .. ] }
    box_map = defaultdict(lambda: [])
    df = pandas.read_csv(BOX_CSV_PATH)
    for row in df.values:
        filename, width, height, x1, y1, x2, y2 = row[:7]
        box_map[filename].append((x1, y1, x2-x1, y2-y1))

    # ä»å›¾ç‰‡é‡Œé¢æå–äººè„¸ (æ­£æ ·æœ¬) å’Œéäººè„¸ (è´Ÿæ ·æœ¬) çš„å›¾ç‰‡
    batch_size = 50
    max_samples = 10
    batch = 0
    image_tensors = [] # å›¾ç‰‡åˆ—è¡¨
    image_candidate_boxes = [] # å„ä¸ªå›¾ç‰‡çš„å€™é€‰åŒºåŸŸåˆ—è¡¨
    image_labels = [] # å„ä¸ªå›¾ç‰‡çš„å€™é€‰åŒºåŸŸå¯¹åº”çš„æ ‡ç­¾ (1 äººè„¸ 0 éäººè„¸)
    image_box_offsets = [] # å„ä¸ªå›¾ç‰‡çš„å€™é€‰åŒºåŸŸä¸çœŸå®åŒºåŸŸçš„åç§»å€¼
    for filename, true_boxes in box_map.items():
        path = os.path.join(IMAGE_DIR, filename)
        img_original = cv2.imread(path) # åŠ è½½åŸå§‹å›¾ç‰‡
        sh, sw, _ = img_original.shape # åŸå§‹å›¾ç‰‡å¤§å°
        img = resize_image(img_original) # ç¼©æ”¾å›¾ç‰‡
        candidate_boxes = selective_search(img) # æŸ¥æ‰¾å€™é€‰åŒºåŸŸ
        true_boxes = [ map_box_to_resized_image(b, sw, sh) for b in true_boxes ] # ç¼©æ”¾å®é™…åŒºåŸŸ
        image_index = len(image_tensors) # å›¾ç‰‡åœ¨æ‰¹æ¬¡ä¸­çš„ç´¢å¼•å€¼
        image_tensors.append(image_to_tensor(img.copy()))
        positive_samples = 0
        negative_samples = 0
        for candidate_box in candidate_boxes:
            # å¦‚æœå€™é€‰åŒºåŸŸå’Œä»»æ„ä¸€ä¸ªå®é™…åŒºåŸŸé‡å ç‡å¤§äº 70%ï¼Œåˆ™è®¤ä¸ºæ˜¯æ­£æ ·æœ¬
            # å¦‚æœå€™é€‰åŒºåŸŸå’Œæ‰€æœ‰å®é™…åŒºåŸŸé‡å ç‡éƒ½å°äº 30%ï¼Œåˆ™è®¤ä¸ºæ˜¯è´Ÿæ ·æœ¬
            # æ¯ä¸ªå›¾ç‰‡æœ€å¤šæ·»åŠ æ­£æ ·æœ¬æ•°é‡ + 10 ä¸ªè´Ÿæ ·æœ¬ï¼Œéœ€è¦æä¾›è¶³å¤Ÿå¤šè´Ÿæ ·æœ¬é¿å…ä¼ªé˜³æ€§åˆ¤æ–­
            iou_list = [ calc_iou(candidate_box, true_box) for true_box in true_boxes ]
            positive_index = next((index for index, iou in enumerate(iou_list) if iou > 0.70), None)
            is_negative = all(iou < 0.30 for iou in iou_list)
            result = None
            if positive_index is not None:
                result = True
                positive_samples += 1
            elif is_negative and negative_samples < positive_samples + 10:
                result = False
                negative_samples += 1
            if result is not None:
                x, y, w, h = candidate_box
                # æ£€éªŒè®¡ç®—æ˜¯å¦æœ‰é—®é¢˜
                # child_img = img[y:y+h, x:x+w].copy()
                # cv2.imwrite(f"{filename}_{x}_{y}_{w}_{h}_{int(result)}.png", child_img)
                image_candidate_boxes.append((image_index, x, y, w, h))
                image_labels.append(int(result))
                if positive_index is not None:
                    image_box_offsets.append(calc_box_offset(
                        candidate_box, true_boxes[positive_index])) # æ­£æ ·æœ¬æ·»åŠ åç§»å€¼
                else:
                    image_box_offsets.append((0, 0, 0, 0)) # è´Ÿæ ·æœ¬æ— åç§»
            if positive_samples >= max_samples:
                break
        # ä¿å­˜æ‰¹æ¬¡
        if len(image_tensors) >= batch_size:
            prepare_save_batch(batch, image_tensors, image_candidate_boxes, image_labels, image_box_offsets)
            image_tensors.clear()
            image_candidate_boxes.clear()
            image_labels.clear()
            image_box_offsets.clear()
            batch += 1
    # ä¿å­˜å‰©ä½™çš„æ‰¹æ¬¡
    if len(image_tensors) > 10:
        prepare_save_batch(batch, image_tensors, image_candidate_boxes, image_labels, image_box_offsets)

def train():
    """å¼€å§‹è®­ç»ƒ"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = MyModel().to(device)

    # åˆ›å»ºå¤šä»»åŠ¡æŸå¤±è®¡ç®—å™¨
    celoss = torch.nn.CrossEntropyLoss()
    mseloss = torch.nn.MSELoss()
    def loss_function(predicted, actual):
        # æ ‡ç­¾æŸå¤±å¿…é¡»æ ¹æ®æ­£è´Ÿæ ·æœ¬åˆ†åˆ«è®¡ç®—ï¼Œå¦åˆ™ä¼šå¯¼è‡´é¢„æµ‹ç»“æœæ€»æ˜¯ä¸ºè´Ÿçš„é—®é¢˜
        positive_indices = actual[0].nonzero(as_tuple=True)[0] # æ­£æ ·æœ¬çš„ç´¢å¼•å€¼åˆ—è¡¨
        negative_indices = (actual[0] == 0).nonzero(as_tuple=True)[0] # è´Ÿæ ·æœ¬çš„ç´¢å¼•å€¼åˆ—è¡¨
        loss1 = celoss(predicted[0][positive_indices], actual[0][positive_indices]) # æ­£æ ·æœ¬æ ‡ç­¾çš„æŸå¤±
        loss2 = celoss(predicted[0][negative_indices], actual[0][negative_indices]) # è´Ÿæ ·æœ¬æ ‡ç­¾çš„æŸå¤±
        loss3 = mseloss(predicted[1][positive_indices], actual[1][positive_indices]) # åç§»å€¼çš„æŸå¤±ï¼Œä»…é’ˆå¯¹æ­£æ ·æœ¬è®¡ç®—
        return loss1 + loss2 + loss3

    # åˆ›å»ºå‚æ•°è°ƒæ•´å™¨
    optimizer = torch.optim.Adam(model.parameters())

    # è®°å½•è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    training_label_accuracy_history = []
    training_offset_accuracy_history = []
    validating_label_accuracy_history = []
    validating_offset_accuracy_history = []

    # è®°å½•æœ€é«˜çš„éªŒè¯é›†æ­£ç¡®ç‡
    validating_label_accuracy_highest = -1
    validating_label_accuracy_highest_epoch = 0
    validating_offset_accuracy_highest = -1
    validating_offset_accuracy_highest_epoch = 0

    # è¯»å–æ‰¹æ¬¡çš„å·¥å…·å‡½æ•°
    def read_batches(base_path):
        for batch in itertools.count():
            path = f"{base_path}.{batch}.pt"
            if not os.path.isfile(path):
                break
            yield [ [ tt.to(device) for tt in t ] for t in load_tensor(path) ]

    # è®¡ç®—æ­£ç¡®ç‡çš„å·¥å…·å‡½æ•°
    def calc_accuracy(actual, predicted):
        # æ ‡ç­¾æ­£ç¡®ç‡ï¼Œæ­£æ ·æœ¬å’Œè´Ÿæ ·æœ¬çš„æ­£ç¡®ç‡åˆ†åˆ«è®¡ç®—å†å¹³å‡
        predicted_i = torch.max(predicted[0], 1).indices
        acc_positive = ((actual[0] > 0.5) & (predicted_i > 0.5)).sum().item() / ((actual[0] > 0.5).sum().item() + 0.00001)
        acc_negative = ((actual[0] <= 0.5) & (predicted_i <= 0.5)).sum().item() / ((actual[0] <= 0.5).sum().item() + 0.00001)
        acc_label = (acc_positive + acc_negative) / 2
        # print(acc_positive, acc_negative)
        # åç§»å€¼æ­£ç¡®ç‡
        valid_indices = actual[1].nonzero(as_tuple=True)[0]
        if valid_indices.shape[0] == 0:
            acc_offset = 1
        else:
            acc_offset = (1 - (predicted[1][valid_indices] - actual[1][valid_indices]).abs().mean()).item()
            acc_offset = max(acc_offset, 0)
        return acc_label, acc_offset

    # å¼€å§‹è®­ç»ƒè¿‡ç¨‹
    for epoch in range(1, 10000):
        print(f"epoch: {epoch}")

        # æ ¹æ®è®­ç»ƒé›†è®­ç»ƒå¹¶ä¿®æ”¹å‚æ•°
        model.train()
        training_label_accuracy_list = []
        training_offset_accuracy_list = []
        for batch_index, batch in enumerate(read_batches("data/training_set")):
            # åˆ’åˆ†è¾“å…¥å’Œè¾“å‡º
            batch_x, batch_y = batch
            # è®¡ç®—é¢„æµ‹å€¼
            predicted = model(batch_x)
            # è®¡ç®—æŸå¤±
            loss = loss_function(predicted, batch_y)
            # ä»æŸå¤±è‡ªåŠ¨å¾®åˆ†æ±‚å¯¼å‡½æ•°å€¼
            loss.backward()
            # ä½¿ç”¨å‚æ•°è°ƒæ•´å™¨è°ƒæ•´å‚æ•°
            optimizer.step()
            # æ¸…ç©ºå¯¼å‡½æ•°å€¼
            optimizer.zero_grad()
            # è®°å½•è¿™ä¸€ä¸ªæ‰¹æ¬¡çš„æ­£ç¡®ç‡ï¼Œtorch.no_grad ä»£è¡¨ä¸´æ—¶ç¦ç”¨è‡ªåŠ¨å¾®åˆ†åŠŸèƒ½
            with torch.no_grad():
                training_batch_label_accuracy, training_batch_offset_accuracy = calc_accuracy(batch_y, predicted)
            # è¾“å‡ºæ‰¹æ¬¡æ­£ç¡®ç‡
            training_label_accuracy_list.append(training_batch_label_accuracy)
            training_offset_accuracy_list.append(training_batch_offset_accuracy)
            print(f"epoch: {epoch}, batch: {batch_index}: " +
                f"batch label accuracy: {training_batch_label_accuracy}, offset accuracy: {training_batch_offset_accuracy}")
        training_label_accuracy = sum(training_label_accuracy_list) / len(training_label_accuracy_list)
        training_offset_accuracy = sum(training_offset_accuracy_list) / len(training_offset_accuracy_list)
        training_label_accuracy_history.append(training_label_accuracy)
        training_offset_accuracy_history.append(training_offset_accuracy)
        print(f"training label accuracy: {training_label_accuracy}, offset accuracy: {training_offset_accuracy}")

        # æ£€æŸ¥éªŒè¯é›†
        model.eval()
        validating_label_accuracy_list = []
        validating_offset_accuracy_list = []
        for batch in read_batches("data/validating_set"):
            batch_x, batch_y = batch
            predicted = model(batch_x)
            validating_batch_label_accuracy, validating_batch_offset_accuracy = calc_accuracy(batch_y, predicted)
            validating_label_accuracy_list.append(validating_batch_label_accuracy)
            validating_offset_accuracy_list.append(validating_batch_offset_accuracy)
        validating_label_accuracy = sum(validating_label_accuracy_list) / len(validating_label_accuracy_list)
        validating_offset_accuracy = sum(validating_offset_accuracy_list) / len(validating_offset_accuracy_list)
        validating_label_accuracy_history.append(validating_label_accuracy)
        validating_offset_accuracy_history.append(validating_offset_accuracy)
        print(f"validating label accuracy: {validating_label_accuracy}, offset accuracy: {validating_offset_accuracy}")

        # è®°å½•æœ€é«˜çš„éªŒè¯é›†æ­£ç¡®ç‡ä¸å½“æ—¶çš„æ¨¡å‹çŠ¶æ€ï¼Œåˆ¤æ–­æ˜¯å¦åœ¨ 20 æ¬¡è®­ç»ƒåä»ç„¶æ²¡æœ‰åˆ·æ–°è®°å½•
        if validating_label_accuracy > validating_label_accuracy_highest:
            validating_label_accuracy_highest = validating_label_accuracy
            validating_label_accuracy_highest_epoch = epoch
            save_tensor(model.state_dict(), "model.pt")
            print("highest label validating accuracy updated")
        elif validating_offset_accuracy > validating_offset_accuracy_highest:
            validating_offset_accuracy_highest = validating_offset_accuracy
            validating_offset_accuracy_highest_epoch = epoch
            save_tensor(model.state_dict(), "model.pt")
            print("highest offset validating accuracy updated")
        elif (epoch - validating_label_accuracy_highest_epoch > 20 and
            epoch - validating_offset_accuracy_highest_epoch > 20):
            # åœ¨ 20 æ¬¡è®­ç»ƒåä»ç„¶æ²¡æœ‰åˆ·æ–°è®°å½•ï¼Œç»“æŸè®­ç»ƒ
            print("stop training because highest validating accuracy not updated in 20 epoches")
            break

    # ä½¿ç”¨è¾¾åˆ°æœ€é«˜æ­£ç¡®ç‡æ—¶çš„æ¨¡å‹çŠ¶æ€
    print(f"highest label validating accuracy: {validating_label_accuracy_highest}",
        f"from epoch {validating_label_accuracy_highest_epoch}")
    print(f"highest offset validating accuracy: {validating_offset_accuracy_highest}",
        f"from epoch {validating_offset_accuracy_highest_epoch}")
    model.load_state_dict(load_tensor("model.pt"))

    # æ£€æŸ¥æµ‹è¯•é›†
    testing_label_accuracy_list = []
    testing_offset_accuracy_list = []
    for batch in read_batches("data/testing_set"):
        batch_x, batch_y = batch
        predicted = model(batch_x)
        testing_batch_label_accuracy, testing_batch_offset_accuracy = calc_accuracy(batch_y, predicted)
        testing_label_accuracy_list.append(testing_batch_label_accuracy)
        testing_offset_accuracy_list.append(testing_batch_offset_accuracy)
    testing_label_accuracy = sum(testing_label_accuracy_list) / len(testing_label_accuracy_list)
    testing_offset_accuracy = sum(testing_offset_accuracy_list) / len(testing_offset_accuracy_list)
    print(f"testing label accuracy: {testing_label_accuracy}, offset accuracy: {testing_offset_accuracy}")

    # æ˜¾ç¤ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ­£ç¡®ç‡å˜åŒ–
    pyplot.plot(training_label_accuracy_history, label="training_label_accuracy")
    pyplot.plot(training_offset_accuracy_history, label="training_offset_accuracy")
    pyplot.plot(validating_label_accuracy_history, label="validing_label_accuracy")
    pyplot.plot(validating_offset_accuracy_history, label="validing_offset_accuracy")
    pyplot.ylim(0, 1)
    pyplot.legend()
    pyplot.show()

def eval_model():
    """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹"""
    # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ŒåŠ è½½è®­ç»ƒå¥½çš„çŠ¶æ€ï¼Œç„¶ååˆ‡æ¢åˆ°éªŒè¯æ¨¡å¼
    model = MyModel().to(device)
    model.load_state_dict(load_tensor("model.pt"))
    model.eval()

    # è¯¢é—®å›¾ç‰‡è·¯å¾„ï¼Œå¹¶æ˜¾ç¤ºæ‰€æœ‰å¯èƒ½æ˜¯äººè„¸çš„åŒºåŸŸ
    while True:
        try:
            # é€‰å–å¯èƒ½å‡ºç°å¯¹è±¡çš„åŒºåŸŸä¸€è§ˆ
            image_path = input("Image path: ")
            if not image_path:
                continue
            img_original = cv2.imread(image_path) # åŠ è½½åŸå§‹å›¾ç‰‡
            sh, sw, _ = img_original.shape # åŸå§‹å›¾ç‰‡å¤§å°
            img = resize_image(img_original) # ç¼©æ”¾å›¾ç‰‡
            candidate_boxes = selective_search(img) # æŸ¥æ‰¾å€™é€‰åŒºåŸŸ
            # æ„å»ºè¾“å…¥
            image_tensor = image_to_tensor(img).unsqueeze(dim=0).to(device) # ç»´åº¦: 1,C,W,H
            candidate_boxes_tensor = torch.tensor(
                [ (0, x, y, w, h) for x, y, w, h in candidate_boxes ],
                dtype=torch.float).to(device) # ç»´åº¦: N,5
            tensor_in = (image_tensor, candidate_boxes_tensor)
            # é¢„æµ‹è¾“å‡º
            labels, offsets = model(tensor_in)
            labels = nn.functional.softmax(labels, dim=1)
            labels = labels[:,1].resize(labels.shape[0])
            # åˆ¤æ–­æ¦‚ç‡å¤§äº 90% çš„æ˜¯äººè„¸ï¼ŒæŒ‰åç§»å€¼è°ƒæ•´åŒºåŸŸï¼Œæ·»åŠ è¾¹æ¡†åˆ°å›¾ç‰‡å¹¶ä¿å­˜
            img_output = img_original.copy()
            for box, label, offset in zip(candidate_boxes, labels, offsets):
                if label.item() <= 0.99:
                    continue
                box = adjust_box_by_offset(box, offset.tolist())
                x, y, w, h = map_box_to_original_image(box, sw, sh)
                if w == 0 or h == 0:
                    continue
                print(x, y, w, h)
                cv2.rectangle(img_output, (x, y), (x+w, y+h), (0, 0, 0xff), 1)
            cv2.imwrite("img_output.png", img_output)
            print("saved to img_output.png")
            print()
        except Exception as e:
            print("error:", e)

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print(f"Please run: {sys.argv[0]} prepare|train|eval")
        exit()

    # ç»™éšæœºæ•°ç”Ÿæˆå™¨åˆ†é…ä¸€ä¸ªåˆå§‹å€¼ï¼Œä½¿å¾—æ¯æ¬¡è¿è¡Œéƒ½å¯ä»¥ç”Ÿæˆç›¸åŒçš„éšæœºæ•°
    # è¿™æ˜¯ä¸ºäº†è®©è¿‡ç¨‹å¯é‡ç°ï¼Œä½ ä¹Ÿå¯ä»¥é€‰æ‹©ä¸è¿™æ ·åš
    random.seed(0)
    torch.random.manual_seed(0)

    # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°é€‰æ‹©æ“ä½œ
    operation = sys.argv[1]
    if operation == "prepare":
        prepare()
    elif operation == "train":
        train()
    elif operation == "eval":
        eval_model()
    else:
        raise ValueError(f"Unsupported operation: {operation}")

if __name__ == "__main__":
    main()
```

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä»¥åï¼š

``` text
python3 example.py prepare
python3 example.py train
```

åœ¨ 31 è½®è®­ç»ƒä»¥åçš„è¾“å‡ºå¦‚ä¸‹ (å› ä¸ºè®­ç»ƒæ—¶é—´å®åœ¨é•¿ï¼Œè¿™é‡Œå·æ‡’äº†ğŸ¥º)ï¼š

``` text
epoch: 31, batch: 112: batch label accuracy: 0.9805490565092065, offset accuracy: 0.9293316006660461
epoch: 31, batch: 113: batch label accuracy: 0.9776784565994586, offset accuracy: 0.9191392660140991
epoch: 31, batch: 114: batch label accuracy: 0.9469732184008024, offset accuracy: 0.9101274609565735
training label accuracy: 0.9707166603858259, offset accuracy: 0.9191886570142663
validating label accuracy: 0.9306134214845806, offset accuracy: 0.9205827381299889
highest offset validating accuracy updated
```

æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œå†è¾“å…¥å›¾ç‰‡è·¯å¾„å¯ä»¥ä½¿ç”¨å­¦ä¹ å¥½çš„æ¨¡å‹è¯†åˆ«å›¾ç‰‡ï¼š

``` text
python3 example.py eval
```

ä»¥ä¸‹æ˜¯éƒ¨åˆ†è¯†åˆ«ç»“æœï¼š

è°ƒæ•´åŒºåŸŸå‰

![16](./16.png)

è°ƒæ•´åŒºåŸŸå

![17](./17.png)

è°ƒæ•´åŒºåŸŸå‰

![18](./18.png)

è°ƒæ•´åŒºåŸŸå

![19](./19.png)

ç²¾åº¦å’Œ RCNN å·®ä¸å¤šï¼Œç”šè‡³æœ‰äº›é™ä½äº† (ä¸ºäº†æ”¯æŒ 4G æ˜¾å­˜ç¼©æ”¾å›¾ç‰‡äº†)ã€‚ä¸è¿‡è¯†åˆ«é€Ÿåº¦æœ‰å¾ˆå¤§çš„æå‡ï¼Œåœ¨åŒä¸€ä¸ªç¯å¢ƒä¸‹ï¼ŒFast-RCNN å¤„ç†å•å¼ å›¾ç‰‡åªéœ€è¦ 0.4~0.5 ç§’ï¼Œè€Œ RCNN åˆ™éœ€è¦ 2 ç§’å·¦å³ã€‚

## å†™åœ¨æœ€å

è¿™ç¯‡ä»‹ç»çš„ RCNN ä¸ Fast-RCNN åªæ˜¯ç”¨äºå…¥é—¨å¯¹è±¡è¯†åˆ«çš„ï¼Œå®ç”¨ä»·å€¼å¹¶ä¸å¤§ (é€Ÿåº¦æ…¢ï¼Œè¯†åˆ«ç²¾åº¦ä½)ã€‚ä¸‹ä¸€ç¯‡ä»‹ç»çš„ Faster-RCNN åˆ™æ˜¯å¯ä»¥ç”¨äºç”Ÿäº§çš„æ¨¡å‹ï¼Œä½†å¤æ‚ç¨‹åº¦ä¹Ÿä¼šé«˜ä¸€ä¸ªç­‰çº§ğŸ¤’ã€‚

æ­¤å¤–ï¼Œè¿™ç¯‡æ–‡ç« å’Œä¸‹ä¸€ç¯‡æ–‡ç« çš„ä»£ç å®ç°å’Œè®ºæ–‡ä¸­çš„å®ç°ã€ç½‘ä¸Šçš„å…¶ä»–å®ç°ä¸å®Œå…¨ä¸€æ ·ï¼Œè¿™æ˜¯å› ä¸ºæˆ‘çš„æœºå™¨æ˜¾å­˜è¾ƒä½ï¼Œå¹¶ä¸”æˆ‘æƒ³ç”¨å°½é‡å°‘çš„ä»£ç æ¥å®ç°ç›¸åŒçš„åŸç†ï¼Œä½¿å¾—ä»£ç æ›´å®¹æ˜“ç†è§£ (ç½‘ä¸Šå¾ˆå¤šå®ç°éƒ½æ˜¯åˆ†ä¸€å †æ–‡ä»¶ï¼Œç”šè‡³æŠŠéƒ¨åˆ†é€»è¾‘ä½¿ç”¨ c/c++ æ‰©å±•å®ç°ï¼Œæ€§èƒ½ä¸Šæœ‰å¥½å¤„ä½†æ˜¯åˆå­¦è€…çœ‹äº†ä¼šå¤´å¤§)ã€‚

å¯¹äº†ï¼Œå¦‚æœæœ‰ä»€ä¹ˆé—®é¢˜æˆ–è€…æƒ³è®¨è®ºæœºå™¨å­¦ä¹ å¯ä»¥åŠ ä¸‹é¢çš„å¾®ä¿¡ç¾¤ğŸ¤—ï¼Œ7 å¤©å†…æœ‰æ•ˆã€‚